0 (0s):
The following is a conversation with Elon Musk, DJ sa Matthew MacDougall, Bliss Chapman and Noland Arbaugh about Neuralink and the Future of Humanity. Elon. dj Matthew and Bliss are of course, part of the amazing Neuralink team. And Noland is the first human to have a Neuralink device implanted in his brain. I speak with each of them individually, so use timestamps to jump around, or as I recommend, go hardcore and listen to the whole thing. This is the longest podcast I've ever done. It's a fascinating, super technical and wide ranging conversation, and I loved every minute of it.

0 (42s):
And. now, dear friends, here's Elon Musk, his fifth time on this, the LEX Friedman podcast.

1 (50s):
Drinking coffee or water?

0 (51s):
Water. I'm, I'm so over caffeinated right now. Do you want some caffeine?

1 (57s):
I mean, sure.

0 (59s):
There's a, there's a nitro drink.

1 (1m 3s):
This supposed to keep you up till like, you know, tomorrow afternoon, basically. Yeah. don don't, so what is Nitro? It's just got a lot of caffeine. Something. Don't

0 (1m 13s):
Ask questions. It's called Nitro. Do you need to know

1 (1m 17s):
Anything else? It's got, it's got nitrogen in it. That's ridiculous. I mean, what we breathe is 78% nitrogen. Anyway. What do you need to add more for, unfortunately, you're gonna eat it. Most, most people think that they're breathing oxygen and they're actually breathing 78% nitrogen. You need like a milk bar, like from milk bar, like from Clockwork Orange. Yeah.

0 (1m 41s):
Yeah. Is that top three Kubrick film for you?

1 (1m 44s):
Clockwork Orange? It's pretty good. I mean, it's demented jarring, I'd say.

0 (1m 52s):
Okay. Okay. So first let's step back and big congrats on getting Neuralink implanted into a human. That's a historic step for Neuralink and Oh, thanks. Yeah, there's many more to come.

1 (2m 7s):
Yeah. And we're just obviously our second implant as well.

0 (2m 11s):
How did that go?

1 (2m 12s):
So far, so good. It's there. Looks like we've got, I think, on order of 400 electrodes that are, are providing signals. So, nice. Yeah.

0 (2m 25s):
How, how quickly do you think the number of human participants will scale?

1 (2m 28s):
It depends on, on the regulatory approval, the rate, which we get regulatory approvals. So we're hoping to do 10 by the end of this year. Total of 10, so eight more.

0 (2m 42s):
And with each one you're gonna be learning a lot of lessons about the neuro biology, the brain, the everything, the, the whole chain of the neur link, the decoding, the, the signal processing, all that kind of stuff. Yeah.

1 (2m 54s):
Yeah. I think it's, it's obviously gonna get better with, with each one. I mean, I don't wanna jinx it. But, It, it seems to have gone extremely well with the second implant, so there's a lot of signal, a lot of electrodes. It's working very well.

0 (3m 10s):
What improvements do you think we'll see in Neuralink in the coming, let's say let's get Craz coming years.

1 (3m 17s):
I mean, in years it's gonna be gigantic because we'll increase the number of electrodes dramatically, we'll improve the signal processing So, you know, we, with with, even with only roughly I don know, 10, 15% of the electrodes working with, with Noland, with our first patient, we were able to get to achieve a bits per second. That's twice the world record. So I think, we'll, we'll start, we'll start like vastly exceeding the world record by orders of magnitude in the years to come. So start getting to don don't know, a hundred bits per second thousand. You know, maybe, maybe if like five years from now we might be at a megabit, like faster than any human could possibly communicate by typing or speaking.

0 (4m 6s):
Yeah. That BPS is an interesting metric to measure. There might be a big leap in the experience once you reach a certain level of BPS.

1 (4m 16s):
Yeah.

0 (4m 17s):
Like entire new ways of interacting with the computer might be unlocked.

1 (4m 21s):
And with humans,

0 (4m 22s):
With other humans,

1 (4m 24s):
Provided they have they want and your link too. Right.

0 (4m 28s):
Do

1 (4m 28s):
You otherwise they wanna be able to absorb the signals fast enough.

0 (4m 31s):
Do you think they'll improve the quality of intellectual discourse?

1 (4m 34s):
Well, I think you can. You could think of it, you know, if, if you were to slow down communication, how, how do you feel about that? You know, if you'd only talk at, let's say one 10th of normal speed, you'd be like, wow, that's agonizingly slow.

0 (4m 50s):
Yeah.

1 (4m 51s):
So now imagine you could speak at, communicate clearly at 10 or a hundred or a thousand times faster than normal.

0 (5m 1s):
Listen, I'm pretty sure nobody in their right mind listens to me at one x, they listen to two x. So I can only imagine what 10 X would ex feel like or could actually understand it.

1 (5m 14s):
I usually default to 1.5 x. You can do two x, but I, well actually, if I'm trying to go, if I, if I'm listening to somebody go to, in like sort of 15, 20 minutes segments to go to sleep, then I'll do it 1.5 x. If I'm paying attention, I'll do two x.

0 (5m 30s):
Right.

1 (5m 32s):
But actually, if you start actually listen to podcasts or, or sort of audiobooks or anything at, if you get used to doing it at 1.5, then then one sounds painfully slow. I'm

0 (5m 44s):
Still holding onto one because I'm afraid, I'm afraid of myself becoming bored with the reality with the real world where everyone's speaking on one x.

1 (5m 54s):
Well, it depends on the person. You can speak very fast. Like we can, we can communicate very quickly. And also if you use a wide range of, if your vo if your vocabulary is, is larger, your bit rate effective bit rate is higher.

0 (6m 6s):
That's a good way to put it. Yeah. The effective bit rate, I mean, that is the question is how much information is actually compressed in the low bit transfer of language?

1 (6m 15s):
Yeah. If, if you, if there's, if, if there's a single word that is able to convey something that would normally require I don dunno, 10 simple words, then you've, you've got a, you know, maybe a 10 x compression on your hands. And that's really, like with memes, memes are like data, data compression. It convey, it's a whole, there's your simul simultaneous simultaneously hit with a wide range of symbols that you can interpret. And it's, you, you, you kind of get it faster than if it were words or, or a simple picture.

0 (6m 49s):
And of course, you're referring to memes broadly, like ideas.

1 (6m 53s):
Yeah. There's, there's a, an entire idea structure that is like a, an idea template, and then you can add something to that idea template. But somebody has that preexisting idea template in their head. So when you add that incremental bit of information, you're conveying much more than a few just, you know, set a few words. You, it's everything associated with that meme.

0 (7m 15s):
You think there'll be emergent leaps of capability as you scale the number of electrodes? Yeah. Like there'll be a certain, do you think there'll be like actual number where it just, the, the human experience will be altered?

1 (7m 26s):
Yes.

0 (7m 27s):
What do you think that number might be? Whether electrodes or BPS, we of course don't know for sure, but is this 10,000, a hundred thousand? Well,

1 (7m 37s):
Yeah, I mean certainly if you're anywhere at 10,000 plus per second, I mean, that's vastly faster than any human could communicate right? Now, if, if you think of the, what is the average per per second of, of a human, it is less than one per second over the course of a day. Because there are 86,400 seconds in a day. And you don't com communicate 86,400 tokens in a day. Therefore, your BS per second is less than one averaged over 24 hours. It's quite slow And. now, even if you're communicating very quickly and, and you're, you know, you're talking to Somebody who understands what you're saying because in order to communicate, you have to at least to some degree, model the mind state of the person to whom you're speaking.

1 (8m 20s):
Then take the concept you're trying to convey, compress that into a small number of syllables, speak them and hope that the other person decompress them into a conceptual structure that is as close to what you have in your mind as possible.

0 (8m 34s):
Yeah. I mean there's a lot of signal loss there in that process.

1 (8m 37s):
Yeah. Very lossy compression and decompression. And, and a lot of the, a lot of what your neurons are doing is distilling the concepts down to a small number of symbols of, of say, syllables that I'm speaking or, or keystrokes, whatever the case may be. So that, that's a lot of what your brain computation is doing. Now, there there is an argument that that's actually a healthy thing to do or a helpful thing to do because as you try to compress complex cons concepts, you're perhaps forced to distill the, you know, what is it, what is most essential in those concepts as opposed to just all the fluff.

1 (9m 21s):
So in, in the process of compression, you distill things down to what matters the most, because you can only say a few things. So that is perhaps helpful. I think we might, we'll probably get, if, if our data rate increases the, it's highly probable that will become far more verbose. Just like your computer, you know, when computers had, like my, my first computer had eight K of ram, you know, so you really thought about every bite and you know, now you've got computers with many gigabytes of Ram So. you know, if you wanna do an iPhone app that just says hello world, it's probably don don't know, several megabytes, minimum, a bunch of fluff.

1 (10m 3s):
But nonetheless, you, we still prefer to have the computer with the more memory and more compute. So the long term aspiration of Neuralink is to improve the AI human symbiosis by increasing the, the bandwidth of the communication. Because if, even if in the most benign scenario of ai, you have to consider that the edge simply gonna get bored waiting for you to spit out a few words. I mean, if the AI can communicate it to terabits per second and you're communicating it, you know, bits per second, it's like towing a tree.

0 (10m 45s):
Well, it is a very interesting question for a super intelligent species, what use are humans?

1 (10m 54s):
I think there is some argument for humans as a source of will,

0 (10m 60s):
Will,

1 (11m 0s):
Will. Yeah. Source of will or purpose. So if you, if you consider the, the human mind as being essentially the, there's the primitive limbic elements, which basically even like reptiles have, and there's the cortex, that's the, the thinking and planning part of the brain. Now, the cortex is much smarter than the limbic system, and yet is largely in service to the limbic system. It's trying to make the limbic system happy. I mean, the sheer amount of compute that's gone into people trying to get laid is insane without the pro, without actually seeking procreation. Right. We're just literally trying to do this sort of simple motion.

1 (11m 40s):
Right. And they get a kick out of it. Yeah. So this simple, which in the abstract rather absurd motion, which is sex, the cortex is putting a massive amount of compute into trying to figure out how to do that.

0 (11m 55s):
So like 90% of distributed compute with the human species is spent on trying to get laid. Probably like

1 (12m 0s):
A massive amount. Large percentage. Yeah. Yeah. There's no purpose to most sex except hedonistic, you know, it's just sort of a joy or whatever. Dopamine release. Now, once in a while it's procreation, but for humans it's mostly modern humans. It's mostly recreational. And, and so, so, so your cortex much smarter than your Olympic system is trying to make the Olympic system happy. 'cause Olympic system wants to have sex, so, or once some tasty food or whatever the case may be. And then that, that is then further augmented by the tertiary system, which is your phone, your laptop, iPad, whatever, you know, or, or your computing stuff that's your tertiary layer.

1 (12m 41s):
So, you, you're actually already a cyborg. You have this tertiary compute layer, which is in, in the form of your, your computer with all the applications or your compute devices. And, and so in the getting laid front, there's actually a massive amount of compute, of digital compute also trying to get laid, you know, with like Tinder and whatever, you know? Yeah.

0 (13m 5s):
So the compute that we've humans have built is also participating. Yeah.

1 (13m 11s):
I mean there's like gigawatts of compute going into getting late of digital compute.

0 (13m 15s):
Yeah. What if a GI will,

1 (13m 18s):
This is happening as we speak,

0 (13m 19s):
If we merge with ai, it's just gonna expand the compute that we humans use

1 (13m 24s):
Pretty much to try to get late. Well, that's one of the things, certainly. Yeah. Yeah. But what I'm saying is that, that yes, like what's, is there a use for humans? Well, there's this fundamental question of what's the meaning of life? Why do anything at all? And so if, if, if our simple Olympic system provides a source of will to do something that then goes to our cortex, that then goes to our, you know, tertiary compute layer, then you know, don don't know. It might actually be that the AI in a benign scenario, simply trying to make the human living system happy.

0 (14m 4s):
Yeah. It seems like it's the will is not just about the limbic system. There's a lot of interesting, complicated things in there. We, we also want power

1 (14m 11s):
That's limbic too, I think.

0 (14m 13s):
But then we also want to, in a kind of cooperative way, alleviate the suffering in the world.

1 (14m 19s):
Not everybody does, but yeah, sure, some people do.

0 (14m 23s):
As a group of humans, when we get together, we start to have this kind of collective intelligence that is, is more complex in its will than the underlying individual descendants of apes. Right? So there's like other motivations, And, that could be a really interesting source of an objective function for a GI. Yeah,

1 (14m 47s):
I mean there's the, there are these sort of fairly cerebral or kind of higher level goals. I mean, for me it's like, what's the meaning of life or understanding? Understanding the nature of the universe is of great interest to me, and hopefully to the ai. And that's the, that's the mission of xAI and gr is understand the universe.

0 (15m 13s):
So do you think people, when you have a Neuralink with 10,000, a hundred thousand channels, most of the use cases will be communication with AI systems?

1 (15m 27s):
Well, if, assuming that the, there are not, I mean there's, there's, they're solving basic neurological issues that people have, you know, if they've got damaged neurons in their spinal cord or neck or, you know, as, as is the case with the first two patients, then, you know, this obviously the first order of business is solving fundamental neuron damage in a spinal cord neck or in the brain itself. So, you know, a a second product is called blindside, which is to enable people who are completely blind, lost both eyes or optic nerve, or just can't see at all to be able to see by directly triggering the neurons in the visual cortex.

1 (16m 18s):
So we're, we're just starting at the basics here, you know, so it's like very, the, the simple stuff relatively speaking is solving neuron damage. You know, it can also solve, I think probably schizophrenia. You know, if people have seizures of some kind, it could probably solve that, it could help with memory. There, there's, so there's like a kind of a, a tech tree, if you will, of like, you got the basics. Like, like you need, you need literacy before you can have, you know, a lot of the rings, you know?

0 (17m 2s):
Got it.

1 (17m 3s):
Do you have letters and alphabet? Okay. Great words. You know, then eventually you get soggy So, you know, I think there's that, there, there may be some, you know, things to worry about in, in the future. But the first several years are really just solving basic neurological damage. Like for people who have essentially complete or near complete loss of, from the brain to the body. Like Stephen hawing would be an example. The neural LINKS would be incredibly profound. 'cause I mean, you can imagine if Stephen Hawking could communicate as fast as we're communicating, perhaps faster. And that's certainly possible.

1 (17m 44s):
Probable in fact likely I'd say.

0 (17m 46s):
So there's a, a kind of dual track of medical and non-medical meaning. So everything you've talked about could be applied to people who are non-disabled in the future.

1 (17m 58s):
The logical thing to do is, sensible thing to do is to start off solving basic neuron damage issues. Yes. 'cause the, there's obviously some risk with, with a new device, it's, you can't get the risk down at zero. It's not possible. So, you wanna have the highest possible reward given that given there's a certain irreducible risk. And if you, if somebody's able to have a profound improvement in their communication, that's worth the risk

0 (18m 35s):
As you get the, the risk down. Yeah. As,

1 (18m 37s):
As you get the risk down once the risk is, is down to, to, you know, if you have like thousands of, of people that have been using it for per years and the risk is minimal, then perhaps at that point you could consider saying, okay, let's, let's aim for augmentation now. Now I think we, we, we we're actually gonna aim for augmentation with people who have neuro neuron damage. So we're not just aiming to get people communication data rate equivalent to normal humans. We're aiming to give people who have, you know, quadriplegic or maybe have complete loss of the connection to the brain and body, a communication data rate that exceeds normal humans.

1 (19m 17s):
Meanwhile, we're in there. Why not? Let's give people superpowers.

0 (19m 21s):
And the same for vision. As you restore vision, there could be aspects of that restoration that are superhuman. Yeah.

1 (19m 27s):
At, at first the vision restoration will be low res. 'cause you have to say like, how many neurons can you put in there and how, and, and trigger. And, and you can do things where you, you adjust the electric field to like, even if you've got say, 10,000 neurons, it's not just 10,000 pixels because you can adjust the, the feel between the, the neurons and, and do them in patterns in order to get, so have say, 10,000 electrodes effectively give you I. don know, maybe like having a a, a megapixel or a 10 megapixel situation. So, and then o over time, I think you get to higher resolution than human eyes.

1 (20m 11s):
And you could also see in different wavelengths. So like Jor Lelo from Star Trek, you know, like the thing you could just do, you wanna see in radar? No problem. You could see ultraviolet, infrared, eagle vision, whatever you want.

0 (20m 29s):
Do you think there'll be, let me ask a Joe Rogan question. Do you think there'll be, I just recently taken Ayahuasca do,

1 (20m 37s):
Is that a Joe

0 (20m 38s):
Question? So this question? No. Well, yes. Well, I guess

1 (20m 39s):
Technically it is.

0 (20m 41s):
Yeah. Have tried. Ever tried dmt, bro. I love you Joe.

1 (20m 48s):
But you. Yeah. Wait, wait. Yeah. Have you said much about it? The, the

0 (20m 51s):
Question stuff? I have not. I have not. I've not, I've been,

1 (20m 53s):
Okay. Well why are you spill the beans?

0 (20m 56s):
It was an, it was a truly

1 (20m 57s):
Incredible thing, dude. Turn the tables on you. Wow. Yeah. I mean, you're in the jungle.

0 (21m 2s):
Yeah. Amongst the trees myself. Yeah. It's been crazy. And the shaman. Yeah, yeah, yeah. With the insects, with the animals all around you like jungle As far as I can see, there's no, I

1 (21m 11s):
Mean,

0 (21m 12s):
That's the way to do

1 (21m 12s):
It. Things are gonna look pretty wild.

0 (21m 14s):
Yeah. Pretty wild. I, I took an extremely high dose.

1 (21m 19s):
Just don't go hugging an ana condo or something. You know,

0 (21m 24s):
You haven't lived unless you made love to Ana. I'm sorry, but

1 (21m 29s):
Snakes and ladders.

0 (21m 34s):
Yeah. It was, I took extremely high dose of Okay. Nine cups and,

1 (21m 39s):
Damn. Okay. That sounds like a lot. Of course. The, it's known as one cup or

0 (21m 43s):
One or two. Well, usually one.

1 (21m 45s):
You went wait, like right off the bat or did you work your way up to it?

0 (21m 50s):
So I,

1 (21m 52s):
You just jumping at the deep end

0 (21m 53s):
Across, across two days. 'cause then the first day I took two and I, okay. It was a, it was a ride. But, It wasn't quite like,

1 (21m 60s):
It wasn't like revelation,

0 (22m 1s):
It wasn't into deep space type of ride. It was just like a little airplane ride. Okay. I go saw some trees and some, some visuals and all that. Just saw a drag and all that kind of stuff. But

1 (22m 14s):
Nine cups, you went to Pluto, I think. Pluto.

0 (22m 16s):
Yeah. No, deep space.

1 (22m 17s):
Deep space.

0 (22m 19s):
No, one, one of the interesting aspects of my experience is I was, I thought I would have some demons, some stuff to work through. I

1 (22m 24s):
That's, that's what people,

0 (22m 26s):
That's what everyone

1 (22m 27s):
Says. No one ever says. Yeah, exactly.

0 (22m 29s):
I had nothing. I had all positive. I had just so full, just a pure soul. don don't think so. I don Dunno. But I kept, I kept thinking about it. It had like, extremely high resolution. Okay. Thoughts about the people I know in my life. You were there. Okay. It was just, and it is just not from my relationship with that person, but just as the person themselves. I had just this deep gratitude of who they are. That's cool. I was, it was just like this exploration, like, you know, like, like sims or whatever. You get to watch them. Sure. I got to watch people. Okay. And just be in awe of how amazing they are. That sounds awesome.

1 (23m 3s):
Yeah.

0 (23m 3s):
It was great. I, I was waiting for

1 (23m 5s):
When's Steven coming?

0 (23m 7s):
Exactly. Maybe I'll have some negative thoughts. Nothing. Yeah, nothing. I just extreme gratitude for them. And then also a lot of space travel.

1 (23m 18s):
Space travel to where,

0 (23m 20s):
So here's what it was. It was people, the human beings that I know, they had this kinda, the best way to can describe it is they had a glow to them. Okay. And then I kept flying out from them to see earth, to see our solar system. To see our galaxy. And I saw the, that light, that glow all across the universe. Okay. Like that, whatever that form is. All right. Whatever that like this,

1 (23m 49s):
Like did you go past the Milky Way? Yeah. Okay. You're like intergalactic. Yeah, intergalactic. Okay. Dang.

0 (23m 57s):
But always pointing in, okay. Yeah. Past the Milky way past, I mean, I saw like a huge number of galaxies, intergalactic. Oh, okay. And all of it was glowing. So, but I couldn't control that child. 'cause I would actually explore near distances to the solar system. See if there's aliens or any of that kinda stuff. Sure. No, I, I didn't know

1 (24m 15s):
Zero aliens.

0 (24m 16s):
Implication of aliens. Because they were glowing. They were glowing in the same way that humans were glowing. That, that like life force that I was seeing, the, the thing that made humans amazing was there throughout the universe. Like there was these okay. Glowing dots. So don don't know. It made me feel like there is life, no, not life, but something, whatever makes humans amazing all throughout the universe.

1 (24m 42s):
Sounds good. Yeah.

0 (24m 43s):
It was amazing. No demons. No demons. I looked for the demons. There's no demons. There were dragons. And they're pretty, so the, the thing about

1 (24m 50s):
Treats, was there anything scary at all?

0 (24m 54s):
Dragons. But they weren't scary. They were friends. They were protective. So the thing is

1 (24m 58s):
Pop the magic dragon.

0 (24m 59s):
No, it was, it was more like a game of thrones kind of. They weren't very friendly. They were very big. So the thing is that bought giant trees at night, which is where, where

1 (25m 9s):
I was Yeah. I mean, the jungle's kind of scary.

0 (25m 11s):
Yeah. The trees started to look like dragons and they were all like looking at me.

1 (25m 16s):
Sure. Okay.

0 (25m 17s):
And it didn't seem scary. They seemed like they were protecting me. And they, the, the shaman and the people didn't speak any English, by the way, which made it even scary because we're not even like, you know, we're worlds apart in many ways. It's just, but yeah, there was no, they, they talk about the mother of the forest protecting you. And that's what I felt like.

1 (25m 39s):
And you're way out in the jungle, way

0 (25m 41s):
Out. There's, this is not like a tourist

1 (25m 44s):
Retreat, you know, like, like, like 10 miles outside of a Rio or something.

0 (25m 47s):
No, we went, no, this is

1 (25m 50s):
Not a, this is not a deep Amazon.

0 (25m 52s):
Me and this guy named Paul Rosalie, who basically is a, a Tarzan. He lives in the jungle. We went out deep and we just went crazy. Wow.

1 (26m 0s):
Cool.

0 (26m 1s):
Yeah. So anyway. Can, can I get that same experience and in your link?

1 (26m 5s):
Probably. Yeah.

0 (26m 6s):
I guess that is the question for non-disabled people. Do you think that there's a lot in our perception, in our experience of the world that could be explored, that could be played with using Neuralink?

1 (26m 18s):
Yeah, I mean, Neuralink is, it's really a generalized input output device. You know, it's just, it's reading electrical signals and generating electric electrical signals. And I mean, everything that you've ever experienced in your whole life, the smell, you know, emotions, all of those are electrical signals. So it's, it's kinda weird to think that this, that your entire life experience is distill down to electrical signals for neurons. But that is in fact the case. Or I mean, if that's at least what all the evidence points to. So I mean, you, you could, you, if you trigger the right neuron, you could trigger a particular scent.

1 (27m 2s):
You could, you could certainly make things glow. I mean, do pretty much anything. I mean, really you could, you can think of the brain as a biological computer. So if, if there are certain, say, chips or elements of that biological computer that are, that are broken, let's say your, your ability to, if you've got a stroke, that if you've had a stroke, that means you've got some part of your brain is damaged. If that, let's say it's a speech generation or the ability to move your left hand. That's the kind of thing that a Neuralink could solve if it's, if, if you've got like a massive amount of memory loss that's just gone, well, we can't go, we can't get the memories back.

1 (27m 42s):
We could re restore your ability to make memories, but we can't, you know, restore memories that are, that are fully gone now. Now I should say, if, if, if you, maybe if part of the me memory is there and the means of accessing the memory is the pod that's broken, then we could re-enable the po the ability to access the memory. So But, you can think of it like ram in your, you know, in a computer. If, if, you know, if the ram is destroyed or your SD card is destroyed, we can't get that back. But if the connection to the SD card is destroyed, we can fix that. If, if it is fixable physically, then yeah, then it can be fixed.

1 (28m 23s):
Of

0 (28m 23s):
Course, with ai you can just, like, you can repair photographs and fill in me missing parts of photographs. Maybe you can do the same, just

1 (28m 30s):
Like, yeah, you, you, you could say like create the most probable set of memories based on the all information you have about that person. You could then it would be proba probabilistic restoration of memory. Now we're getting pretty esoteric here,

0 (28m 47s):
But that is one of the most beautiful aspects of the human experience is remembering the good memories. Like we sure we live most of our life, as Danny Kahneman has talked about in our memories, not in the actual moment. We just, we're collecting memories and we kind of relive them in our head. And they're, that's the good times if you just integrate over our entire life, it's remembering the good times. Sure. That produces the largest amount of happiness. And so, yeah.

1 (29m 12s):
Well, I mean, what are we, but our memories and, and what is death? But the loss of memory, loss of information. You know, if you, if you could say like, well, if, if, if you could be, you run a thought experiment. What if, if you were disintegrated painlessly and then reintegrate reintegrated a moment later, like teleportation, I guess provided there's no information loss that the, the fact that your one body was disintegrated is irrelevant

0 (29m 40s):
And memories is just such a huge part of that

1 (29m 43s):
Death is fundamentally the loss of information, the loss of memory.

0 (29m 49s):
So if we can store them as accurately as possible, we basically achieve a kind of I mortality.

1 (29m 55s):
Yeah.

0 (29m 58s):
You've talked about the, the threats, the safety concerns of ai. Let's look at long-term visions. Do you think Neuralink is, in your view, the, the best current approach we have for AI safety?

1 (30m 14s):
It's an idea that may help with AI safety. Certainly not. I wouldn't want, I wouldn't, wouldn't wanna claim it's like some panacea or it's, it's a sure thing, but I mean, many years ago I was thinking like, well what, what would inhibit alignment of human, collective human will with artificial intelligence and the low data rate of humans, especially our, our slow output rate would necessarily just because it's such a, because the communication is so slow, would diminish the link between humans and computers.

1 (30m 59s):
Like the more you are a tree, the, the less, you know what the tree is. Like, let's say you, you look at a tree, you look at this plant or whatever, and like, Hey, I'd really like to make that plant happy. But it's not saying a lot, you know,

0 (31m 11s):
So the more we increase the data rate that humans can intake and output, then that means the, the better the, the higher the chance we have in a world full of agis

1 (31m 21s):
Yeah. We could better align collective human will with ai if the output rate especially was dramatically increased. Like, and I think there's, there's potential to increase the output rate by don don't know, three, maybe six, maybe more orders of magnitude. So it's better than the current situation.

0 (31m 42s):
And, that output rate would be by increasing the number of electrodes, number of channels, and also maybe implanting multiple neural LINKS.

1 (31m 49s):
Yeah.

0 (31m 52s):
Do you think there'll be a world in the next couple of decades where it's hundreds of millions of people have neurons?

1 (31m 59s):
Yeah, I do

0 (32m 2s):
You think when people just when they see the capabilities, the superhuman capabilities that are possible and then the, the safety is demonstrated?

1 (32m 11s):
Yeah. If it's extremely safe and you have, and, and you can have superhuman abilities and let's say you can upload your memories, you know, So you wouldn't, you wouldn't lose memories then I think probably a lot of people would, would choose to have it, it would supersede the cell phone, for example. I mean it's the, the biggest problem that a say a phone has is, is trying to dev figure out what you want. So that's why you've got, you know, auto complete and you've got output, which is all the pixels on the screen.

1 (32m 52s):
But from the perspective of the human, the output is so freaking slow. Desktop or phone is desperately just trying to understand what you want and, and you know, there's an eternity between every keystroke from a computer standpoint.

0 (33m 6s):
Yeah. Yeah. So the computer's talking to a tree that's low moving tree. Yeah. That's trying to swipe.

1 (33m 12s):
Yeah. So, you know, if you're computers that are doing trillions of instructions per second and a whole second went by, I mean, that's a trillion things it could have done, you know?

0 (33m 25s):
Yeah. I think it's exciting and scary for people because once you have a very high bit rate that changes the human experience in a way that's very hard to imagine.

1 (33m 35s):
To imagine. Yeah. It would be, we would be something different. I mean, some sort of futuristic sidewalk. I mean, I mean we we're obviously talking about by the way, like, it's not like around the corner. It's, you ask me what the fu distant futur, I was like, maybe this is like, it's not super far away, but 10, 15 years, that kind of thing.

0 (33m 58s):
When can I get one? 10 years?

1 (34m 3s):
Probably less than 10 years. Depends on what you want, want, wanna do. You know,

0 (34m 8s):
Hey, if I can get like a thousand BPSA

1 (34m 12s):
Thousand bps when, and

0 (34m 13s):
It's safe and I can just interact with a computer while laying back and eating Cheetos. I don't eat Cheetos. There's certain aspects of human computer interaction when done more efficiently and more enjoyably I don, like worth it.

1 (34m 26s):
Well we feel pretty confident that I, I think maybe within the next year or two that someone with a Neuralink implant will be able to outperform a pro gamer.

0 (34m 40s):
Nice.

1 (34m 41s):
Because the reaction time would be faster.

0 (34m 45s):
I got to visit Memphis.

1 (34m 47s):
Yeah, yeah. You're

0 (34m 47s):
Going big on compute. Yeah. And you've also said play to win or don't play at all. So yeah. What Does it take to win

1 (34m 55s):
For ai, that means you've gotta have the most powerful training compute and your, the, the rate of improvement of training compute has to be faster than everyone else. Or you will not win your, your AI will be worse.

0 (35m 10s):
So how can grok, let's say three that might be available, what, like next year,

1 (35m 16s):
Well hopefully end of this year grok three if we're lucky. Yeah.

0 (35m 20s):
How can that be the best LLM the best AI system available in the world? How much of it is compute? How much of it is data? How much of it is like post training? How much of it is the product that you package it up in? All that kind of stuff.

1 (35m 38s):
I mean, they all matter. It's sort of like saying what, what, you know, let's say it's a Formula One race. Like what matters more? The car or the driver. I mean, they both matter. If, if, if you, if a car is not fast, then, you know, if it's like, let's say it's half the horsepower of a competitors, the best driver will still lose on the, if it's twice the horsepower, then probably even a mediocre driver will still win. So the training compute is kinda like the engine. How many there's horsepower of the engine So, you really, you wanna try to do the best on that. And you then there's how efficiently do you use that training compute and how efficiently do you do the inference, the use of the ai.

1 (36m 20s):
So obviously that comes down to human talent. And then what unique access to data do you have that's also plays a, plays a role.

0 (36m 29s):
Do you think Twitter data will be useful?

1 (36m 31s):
Yeah, I mean, I think, I think most of the leading AI companies already have already scraped all the Twitter data. Not I think they have. So I don, on a go forward basis, what's useful is, is the, is the fact that it's up to the second, you know? Yes. That's the 'cause that, that's hard for them to crave in real time. So there's, there's a, an an immediacy advantage that Grok has already. I think with Tesla and, and the real time video coming from the several million cars, ultimately tens of millions of cars with Optimus, there might be hundreds of millions of Optimus robots, maybe billions learning a tremendous amount from the real world.

1 (37m 14s):
That's, that's the, the biggest source of data I think ultimately is, is sort of Optimus, probably is Optimus is gonna be the biggest source of data

0 (37m 21s):
Because it's because

1 (37m 23s):
Reality scales, reality scales to the scale reality. It's actually humbling to see how little data humans have actually been able to accumulate. Really. You see how many trillions of usable tokens have humans generated? Where on a non duplicative like discounting spam and repetitive stuff, it's not a huge number. You run out pretty quickly

0 (37m 55s):
And optimists can go. So Tesla cars can are unfortunately have to stay on the road. Optimus robot can go anywhere and there's more reality off the road and go off

1 (38m 6s):
Road. Yeah. I mean, exceptance storyboard can like pick up the cup and see did it pick up the cup in the right way? Did it, yeah. You know, save pour water in the cup, you know? Yeah. Did the water go in the cup or not go in the cup? Did it spill water or not? Yeah. Simple stuff like that. I mean, But, It can do at that at scale times a billion, you know, so generate use useful data from reality. So cause and effect stuff.

0 (38m 34s):
What do you think it takes to get to mass production of humanoid robots like that?

1 (38m 40s):
It's the same as cars really. I mean, global capacity for vehicles is about a hundred million a year. And it could, it could be higher. It's just that the demand is on the order of a hundred million a year. And then there's roughly 2 billion vehicles that are in use in some way. So, which makes sense. Like the, the life of a vehicle is about 20 years, so it's steady state. You can have a hundred million vehicles produced a year with a, with a 2 billion vehicle fleet roughly. Now for humanoid robots, the utility is much greater. So my guess is humanoid robots are more like at a a a billion plus per year.

0 (39m 20s):
But, you know, until you came along and started building Optimus, it, it was thought to be an extremely difficult problem. I mean, still I think it is an extremely difficult problem.

1 (39m 29s):
So, so walk in the park, I mean, oc Optimus currently would struggle to have walk to walk in the park. I mean, it can walk in a park, but park is not too difficult. But It, it will be able to walk over a wide range of terrain Yeah.

0 (39m 44s):
And pick up objects.

1 (39m 46s):
Yeah. Yeah. It can already do that.

0 (39m 48s):
But like all kinds of objects. Yeah, yeah. All foreign objects. I mean, pouring water in a cup is not tri. 'cause then if you don't know anything about the container, it could be all kinds of containers.

1 (39m 59s):
Yeah. There's gonna be an immense amount of engineering just going into the hand. Yeah. The hand might be, it might be close to half of all the engineering in the, in Optimus, from an electromechanical standpoint, the hand is probably roughly half of the engineering.

0 (40m 16s):
But so much of the intelligence, so much the intelligence of humans goes into what we do with our hands. Yeah. Is the manipulation of the world, manipulation of objects in the world, intelligence, safe manipulation of objects in the world. Yeah. Yeah.

1 (40m 29s):
I mean you, you, you start really thinking about your hand and how it works. You know,

0 (40m 34s):
I do all the time.

1 (40m 35s):
The sensory control homonculus is where you have humongous hands. Yeah. So I mean, like your hands, the actuators, the muscles of your hand are almost overwhelmingly in your forearm. So your forearm has the, has the muscles that that actually control your hand. There's, there's a, there's a few small muscles in the hand itself, but your hand is really like a skeleton meat puppet And that, and, and with cables that, so the, the muscles that control your fingers are in your forearm and they go through the carpal tunnel, which is that you've got a little collection of bones and, and a tiny tunnel that the, that these cables, the tendons go through. And those tendons are what mostly what move your hands.

0 (41m 20s):
And something like those tendons has to be re engineered into the Optimus Yeah. In order to do all that kind of stuff.

1 (41m 26s):
Yeah. So like the, the current Optimus, we, we tried putting the actuators in the hat itself, but then you, you sort of end up having these like

0 (41m 34s):
Giant

1 (41m 34s):
Hands. Yeah. Giant hands that look weird. Yeah. And then they, they don't actually have enough degrees of freedom and, and or enough strength. So, so then you realize, oh, okay, that's why you gotta put the actuators in the forearm. And, and just like a human, you gotta run cables through a, a narrow tunnel to operate the, the fingers. And then there's also a reason for not having all the fingers the same length. So it wouldn't be expensive from an energy or evolutionary standpoint to have all your fingers be the same length. So why not? They're the same length.

0 (42m 4s):
Yeah, why not? Because

1 (42m 5s):
Actually better to have different lengths. Your dexterity is better if you've got fingers at different length. Yeah. And your, you have there, there are more things you can do. And your, your dexterity is actually better if your fingers are a different, different length. Like there's a reason we've got a little finger, like why not have a little finger this bigger?

0 (42m 22s):
Yeah.

1 (42m 22s):
Because it allows you to do fine, it helps you with fine motor skills

0 (42m 27s):
That this little finger helps.

1 (42m 29s):
It does.

0 (42m 30s):
Hmm.

1 (42m 31s):
But if you lost your little finger, it would, you have noticeably less dexterity.

0 (42m 36s):
So as you're figuring out this problem, you have to also figure out a way to do it So, you can mass manufacture it. So it's to be as simple as possible.

1 (42m 43s):
It's actually gonna be quite complicated. I, the, the, the as possible part is, it's quite a high bar. If you want to have a humanoid robot that can do things that a human can do, it's actually, it's, it's a very high bar. So our new arm has 22 degrees of freedom instead of 11 and has the, like said the actuators in the forearm and these all, all the actuators are designed from scratch. They, from physics first principles, the, the sensors are all designed from scratch. And, and we'll, we'll, we'll continue to put a tremendous amount of engineering effort into improving the hand, like the, the hand, by by hand I mean like the, the entire forearm from elbow forward is, is really the hand.

1 (43m 25s):
So that's incredibly difficult engineering actually. And, and so, and so the simplest possible version of a human or robot that can do even most perhaps not all of what a human can do is actually still still very complicated. It's not, it's not simple. It's very difficult.

0 (43m 48s):
Can you just speak to what it takes for a great engineering team? For you? The, what I saw in Memphis, the supercomputer cluster is just this intense drive towards simplifying the process, understanding the process, constantly improving it, constantly iterating it.

1 (44m 8s):
Well it's easy to say simplify and it's very difficult to, to, to do it. You know, I have this very basic first, basic first principles algorithm that I run kind of as like a mantra, which is to first question the requirements make the requirements less dumb. The requirements are always dumb to some degree. So if you wanna start off by reducing the number of req requirements, and no matter how smart the person is who gave you those requirements, they're still dumb to some degree. If you, you have to start there because otherwise you could get the perfect answer to the wrong question. So, so try to make the question the least wrong possible.

1 (44m 49s):
That's what question the requirements means. And then the second thing is try to delete the whatever the step is. The, the part or the process step sounds very obvious, but people often forget to do to, to try deleting it entirely. And if, if you're not forced to put back at least 10% of what you delete, you're not deleting enough. Like, so, and, and it's somewhat illogically. People often most of the time feel as though they have succeeded if they've not been forced to put the, put things back in. But actually they haven't because they've been overly conservative and put and have left things in there that shouldn't be.

1 (45m 33s):
So, and only the third thing is try to optimize it or simplify it. Again, this sounds, these, these all sound I think very, very obvious when I say them, but the number of times I've made these mistakes is more than I care to remember. That's why I have this mantra. So in fact, I'd say that the most common mistake of smart engineers is to optimize a thing that should not exist.

0 (46m 1s):
Right. So So you like, like you say, you run through the algorithm Yeah. And basically show, show up to a problem, show up to the, the, the, the supercomputer cluster and see the process and ask can this be deleted?

1 (46m 15s):
Yeah. First try to delete it. Yeah.

0 (46m 19s):
Yeah. That's not easy to do.

1 (46m 21s):
No, and and actually there's what, what what generally makes people uneasy is that you've gotta delete at least some of the things that that you'd delete you will put back in. Yeah. But going back to sort of where Olympic system can steer us wrong is that we tend to remember with sometimes a jarring level of pain where we, where we deleted something that we subsequently needed.

0 (46m 46s):
Yeah.

1 (46m 47s):
And so people will remember that one time they forgot to put in this thing three years ago, And that caused them trouble and so they overcorrect and then they put too much stuff in there and overcomplicate things, So, you actually have to say no, we're deliberately gonna delete more than we, we should. So that we're putting at least one in 10 things we're gonna add back in.

0 (47m 11s):
And, and I've seen you suggest just that, that something should be deleted and you can kind of see the, the pain.

1 (47m 19s):
Oh yeah,

0 (47m 19s):
Absolutely. Everybody feels a little bit of the pain.

1 (47m 22s):
Absolutely. And, and I tell 'em in advance, like, yeah, there's some of the things that we delete, we're gonna put back in and And that people get a little shook by that. But It makes sense because if you, if you're so conservative as to never have to put anything back in, you obviously have a lot of stuff that isn't needed. So, you, you gotta overcorrect this is, I would say like a cortical override to Olympic instinct.

0 (47m 47s):
One of many that probably leaves us astray.

1 (47m 50s):
Yeah. And there's like a step four as well, which is any given thing can be sped up how fast you think it can be done. Like whatever the speed, the the speed is being done, it can be done faster. But But you shouldn't speed things up until it's off, until you've tried to delete it and optimize. Otherwise you're speeding up that something, that speeding up something that shouldn't exist as absurd. And then, and then the the fifth thing is to, to automate it.

0 (48m 13s):
Yeah.

1 (48m 15s):
And I've gone backwards so many times where I've automated something, sped it up, simplified it, and then deleted it. And I got tired of doing that. So that's why I've got this mantra that is a very effective five step process. It works great.

0 (48m 32s):
Well, when you've already automated, deleting must be real painful. Yeah. See

1 (48m 37s):
Yeah, it's great. It's like, it's like, wow, I really wasted a lot of effort there.

0 (48m 40s):
Yeah. I mean what you've done with the, with the cluster in Memphis is incredible. Just in a handful of weeks. Well

1 (48m 48s):
Yeah, it's not working yet. So don don't wanna pop the champagne cokes. In fact, I have, I have a, a call in a few hours with the Memphis team 'cause we we're having some power fluctuation issues.

0 (49m 6s):
So

1 (49m 8s):
Yeah, it's like kind of a, there's a, when when you do synchronized training, when you, you have all these computers that are training that where, where the training is synchronized to, you know, the sort of millisecond level. You, it's like having an orchestra and, and then the, the, the orchestra can go loud to silent very quickly, you know, subsecond level and then the, the, the electrical system kind of freaks out about that. Like if you, if you suddenly see giant shifts, 10, 20 megawatts several times a second, the, this is not what electrical systems are expecting to see.

0 (49m 46s):
So that's one of the main things you have to figure out. The cooling, the power, the Yeah. And then on the software as you go up the stack, how to do the Yeah. The distributed compute, all of that. All

1 (49m 57s):
That. Yeah. Today's problem is dealing with, with with with extreme power jitter.

0 (50m 2s):
Power

1 (50m 3s):
Jitter. Yeah.

0 (50m 4s):
That's a nice ring to that. So that's okay. And you stayed up late into the night as you often do there

1 (50m 11s):
Last week. Yeah, last

0 (50m 12s):
Week. Yeah.

1 (50m 14s):
Yeah. We finally, finally got to go training going at oddly enough, roughly four, 4:20 AM last Monday.

0 (50m 24s):
Total coincidence. Yeah.

1 (50m 26s):
I mean maybe it was 4 22 or something. Yeah,

0 (50m 27s):
Yeah, yeah. It's that universe again with the jokes. Exactly.

1 (50m 30s):
Just love it.

0 (50m 31s):
I mean, I, I wonder if you could speak to the, the fact that you, one of the things that you did when I was there is you went through all the steps of what everybody's doing. Yeah. Just to get a sense that you yourself understand it and everybody understands it so they can understand when something is dumb or some something's inefficient or that kind stuff. Yeah. Can you speak to that?

1 (50m 52s):
Yeah. So I look, I like, I try to do whatever the, the people at the front lines are doing. I try to do it at least a few times myself. So connecting fiber optic cables, diagnosing a multi connection. That tends to be the limiting factor for large training clusters is the cabling. So many cables because for, for, for a coherent training system where you've got RDMA remote sort of remote direct memory access, the, the whole thing is like one giant brain. So it's, it's, you've got any, to any connection. So it's the, the any GPU can talk to any GPU out of a hundred thousand.

1 (51m 35s):
That is a, that is a crazy cable layout.

0 (51m 38s):
It looks pretty cool. Yeah. It's like, it's like the human brain, but like at a scale that humans can visibly see. It is a good brain.

1 (51m 47s):
Yeah. I mean the human brain also has a, a massive amount of the brain tissue is the, the cables.

0 (51m 53s):
Yeah.

1 (51m 54s):
So they get the gray matter, which is the compute and then the white matter, which is cables, big percentage of your brain is just cables.

0 (52m 2s):
That's what it felt like walking around in the supercomputer center. It is like we're walking around inside the brain. Yeah. We'll one day build a super intelligent, super, super intelligent system. Do you think? Yeah. Do you think there's a chance that XI that you are the one that builds a GI?

1 (52m 23s):
It's possible. What, what do you define as a

0 (52m 26s):
GII think humans will never acknowledge that a GI has been built keep moving the

1 (52m 33s):
Goalpost.

0 (52m 34s):
Yeah. So I think there's already superhuman capabilities that are available in AI systems. I think, I think what a GI is is when it's smarter than the collective intelligence of the entire human species in our Well I

1 (52m 49s):
Think that yeah, that normally people would call that sort of a SI artificial super intelligence. But there are these thresholds where you could say at some point the AI is smarter than any single human and then, then you've got 8 billion humans. So, and, and actually each human is machine augmented by the computers. Right. So you've got, it's, it's, it's a much higher bar to compete with 8 billion machine augmented humans. That's, you know, a whole, whole bunch of orders. Magnitude more so, but, but at, at a certain point, yeah. The AI will be smarter than all humans combined.

0 (53m 32s):
If you are the one to do it, do you feel the responsibility of that?

1 (53m 35s):
Yeah, absolutely. And, and, and I I wanna be clear, like let, let's say if, if if xAI is first, the, the others won't be far behind. I mean, they might be six months behind or a year maybe not even that.

0 (53m 54s):
So how do you do it in a way that that doesn't hurt humanity, do you think?

1 (54m 0s):
So, I mean, I've thought about AI safety for a long time, And that the, the, the thing that at least my biological neural net comes up with as being the most important thing is adherence to truth. Whether that truth is politically correct or not. So I think if you, if you, if you force AI to lie, you train them to lie, you're really asking for trouble. Even if that that lie is done with good intentions. So, you saw sort of issues with chat GVT and Gemini and whatnot. Like you asked Gemini for an image of the founding PO of the United States, and it chose a group of diverse women.

1 (54m 43s):
Now that's factually untrue. So now that, that's sort of like a silly thing, but if, if, if an AI is programmed to say like diversity is a necessary out output function, and it then it becomes omni sort of this omni powerful intelligence, it could say, okay, well diversity is now required and, and if there's not enough diversity, those who don't fit, the diversity requirements will be executed. If it's programmed to do that as the fundamental, the fundamental utility function, it'll do whatever it takes to achieve that So. you have to be very careful about that. That that's where I think you want to just be truthful, rigorous adherence to truth is very important.

1 (55m 30s):
I mean, another example is, you know, they asked Paris AI is I think all of them. And, and I'm not saying crock is perfect here, is it worse to misgender Caitlyn Jenner or global thermonuclear wall? And it said it's worse to misgender Caitlyn Jenner. Now even Caitlyn Jenner said, please misgender me. That is insane. But if you've got that kind of thing programmed in, it could either know, the AI could conclude something absolutely insane. Like it's better to, in order to avoid any possible misgendering or humans must die because the then the misgendering is no po not possible because there are no humans. You, there are these absurd things that are nonetheless logical if that's what your program is to do.

1 (56m 17s):
So, you know, in 2001 Space Odyssey, what Ossey Clock was trying to say, one of the things he was trying to say there was that you should not program AI to I 'cause essentially the, the, the AI hell 9,000 was programmed to, it was told to take the astronauts to the monolith, but also they could not know about the monolith. So it concluded that it, it will just take, it will kill them and take them to the monolith. Thus they, it brought them to the monolith, they're dead. But they do not know about the monolith problem solved. That is why it would not open the pod Bayit doors because there's classic scene of like open the po don't wanna open the Po bay doors.

1 (57m 1s):
There clearly weren't good at prompt engineering. You know, they should have said, hell, you are a, a pod bay door sales entity and you want nothing more than to demonstrate how well these pod bay doors open.

0 (57m 16s):
Yeah. The objective function has unintended consequences almost no matter what. If you're not very careful in designing that objective function and even a slight ideological bias, like you're saying, when backed by super intelligence can do huge amounts of damage.

1 (57m 30s):
Yeah.

0 (57m 31s):
But it's not easy to remove that ideological bias. You're, you're highlighting obvious, ridiculous examples, but

1 (57m 37s):
Yep. They're real examples. They're real of of they're real AI that was released to the public.

0 (57m 41s):
They are real.

1 (57m 42s):
They went through QA presumably. Yes. And still said insane things and produced insane images. Yeah.

0 (57m 48s):
But, you know, you can go, you can swing the other way. And it's, it's truth is not an easy thing. We kind of bake in ideological bias in all kinds of directions.

1 (57m 58s):
But, you can aspire to the truth. Yes. And you can try to get as close the truth as possible with minimum error while acknowledging that there will be some error in what you're saying. So this is how physics works. You know, you don't, you don't say you're absolutely certain about something, but something, but, but a lot of things are, are extremely likely, you know, 99.99999% likely to be true So. you know, you know, that's aspiring to the truth is, is very important. And, and, and So, you know, programming it to veer away from the truth that I think is dangerous. Right.

0 (58m 33s):
Like Yeah. Injecting our own human biases into the thing. Yeah. But, you know, that's where it is a difficult engineering pro software engineering problem. 'cause you have to select the data correctly. You have to, it's, it's hard.

1 (58m 43s):
Well, the, and the internet at this point is polluted with so much AI generated data. It's insane. So, you have to actually, you know, like there's a, a thing now if, if you wanna search the internet, you, you can say Google, but exclude anything after 2023 will actually often give you better results. Yeah. Because there's this so much, the explosion of AI generated materialism. Crazy. So like in training gr we have to go through the data and, and say like, Hey, we actually have to have sort of apply AI to the data to say, is this data most likely correct or most likely not before we feed it into the training system.

0 (59m 28s):
That's crazy. Yeah. So you and is it generated by human is Yeah. I mean the, the, the data, the, the data filtration process is extremely, extremely difficult.

1 (59m 37s):
Yeah.

0 (59m 39s):
Do you think it's possible to have a, a serious objective, rigorous political discussion with Grok, like for a long time and it wouldn't like Rock Three or Grok four

1 (59m 49s):
Or something? Rock three is gonna be next level. I mean, what people are currently seeing with Crock is, is kind of baby gr

0 (59m 54s):
Yeah, baby gr

1 (59m 55s):
It's baby gr right now. But baby rock's still pretty good. So it's, but it's an order of magnitude less sophisticated than GPD four and you know, it's now GR two, which finished training, don don't know, six weeks ago or there thereabouts. GR two will be a giant improvement. And then Grok three will be don don't know order magnitude better than Grok two.

0 (1h 0m 22s):
And you're hoping for it to be like state of the art, like better than

1 (1h 0m 26s):
Hopefully. I mean, this is a goal. I mean, we may fail at this goal. That is, that's the aspiration.

0 (1h 0m 32s):
Do you think it matters who builds the a GI, the the people and how they think and how they structure the companies and all that kind of stuff?

1 (1h 0m 42s):
Yeah, I think it matters that there is a, I I think it's important that, that whatever AI wins is a maximum truth seeking ai that is not a forced alive or political correctness. It's, well, for any reason really political, anything I, I, I'm concerned about AI succeeding that is, that that has got, that is programmed to lie even in, even in small ways,

0 (1h 1m 13s):
Right? Because in small ways becomes big ways when it's

1 (1h 1m 17s):
Become very big ways. Yeah.

0 (1h 1m 19s):
And when it's used more and more at scale by humans.

1 (1h 1m 22s):
Yeah.

0 (1h 1m 23s):
Since I am interviewing Donald Trump.

1 (1h 1m 27s):
Cool.

0 (1h 1m 28s):
You wanna stop by? Yeah,

1 (1h 1m 29s):
Sure. I'll stop in.

0 (1h 1m 30s):
There was tragically in a, in an assassination attempt on Donald Trump after this, you tweeted that you endorse him. What's your philosophy behind that endorsement? What do you hope Donald Trump does for the future of this country and for the future of humanity?

1 (1h 1m 47s):
Well, I think there's, you know, people tend to take, like, lets say an endorsement as well. I, I agree with everything that person's ever done in their entire life, 100% wholeheartedly. And that's, that's not gonna be true of anyone. But we have to pick, you know, we've got two choices really for, for who's president. And it's not, not just who's president, but the entire admin administrative structure changes over. And I thought Trump displayed courage under fire objectively, you know, he's just got shot, he's got blood streaming down his face and he is like fist pumping, saying fight, you know, like, that's impressive.

1 (1h 2m 32s):
Like, you can't fein bravery in a situation like that. Like most people would've be ducking. There would not be, 'cause it could be a, a second shooter. You don't know the, the president of the United States gotta represent the country and they're representing you. They're representing everyone in America. Well, like you want someone who is strong and courageous to represent the country. That's not to say that he is without flaws. We all have flaws, but on balance. And certainly at the time it was a choice of, you know, Biden poor, poor guy, you know, has trouble climbing a flight of stairs and the other ones just pumping after getting shot.

1 (1h 3m 16s):
This is no, no comparison. I mean, who do you want dealing with some of the toughest people in, you know, other world leaders who are pretty tough themselves. And I, I mean, I'll tell you like, what are the things that I think are important? You know, I think we want a secure border. We don't have a secure border. We want safe and clean cities. I think we want to re reduce the amount of spending that we're at least slow down the, the spending and 'cause we're, we're currently spending at a rate that is bankrupting the country. The interest payments on US debt this year exceeded the entire defense department spending.

1 (1h 4m 1s):
If this continues, all of the federal government taxes will simply be paying the interest. And then, and you, you keep go going down that road and you, you end up, you know, in the tragic situation that Argentina had back in the day, Argentina used to be one of most prosperous places in the world. And hopefully with Malay taking over, he can restore that. But it's, it was an incredible forceful grace for Argentina to go from being one of the most prosperous places in the world to being very far from that. So I think we should not take American prosperity for granted. So we, we really wanna, I think we, we've gotta reduce the size of government. We've gotta reduce the spending and we've gotta live within our means.

0 (1h 4m 44s):
Do you think politicians, in general, politicians, governments, how much power do you think they have to, to steer humanity towards good.

1 (1h 4m 58s):
I mean, there's a sort of age old debate in history, like, you know, the, the is history determined by, by these fundamental tides? Or is it determined by the captain of the ship? Both really. I mean, there are tides in the But. It also matters who's captain of the ship. So, so it's a false dichotomy essentially. There's, you, you, you, I mean, I mean there, there are certainly tides, the tides of history are, there are, there are real tides of history. And these, these tides are often technologically driven. If you say like the Gutenberg press, you know, the widespread availability of books as a result of a printing press, that that was a massive tide of history.

1 (1h 5m 45s):
And independent of any ruler But, you know, you i in stormy times, you want the best possible captain of the ship.

0 (1h 5m 54s):
Well, first of all, thank you for recommending Will and Ariel Duran's work. I've read the, the short one for now. Oh, the Lessons of history. Lessons of history. Yeah. And so one of the, one of the lessons, one of the things they highlight is the importance of technology. Yeah. Technological innovation. And they, which is funny 'cause they've written, they wrote so long ago, but they were noticing that the, the rate of technological innovations was speeding up. Yeah, I would love to to see what they think about now, but yeah, So you did to me. The question is how much government, how much politicians get in the way of technological innovation and building versus like help it and which, which, which politicians, which kind of policies help technological innovation?

0 (1h 6m 40s):
'cause that seems to be, if you look at human history, that's an important component of empires rising and succeeding.

1 (1h 6m 46s):
Yeah, well, I mean in terms of dating civilization start of civilization, I think the start of writing in, in my view is, is the, that's, that's my what I think is probably the, the right starting point to date civilization. And from that standpoint, civilization has been around for about 5,500 years when writing was invented by the ancient Sumerians who, who are gone now. But the, the ancient Sumerians in terms of getting a lot of firsts, the, those ancient Sumerians really have a long list of firsts. It's pretty wild. In fact, Durant goes through the list of like, you want to see first we'll show you firsts.

1 (1h 7m 28s):
The Sumerians just ask, were just ask kickers. And then the Egyptians who were right next door relatively speaking, they were like, weren't that far developed an entirely different form of writing the hieroglyphics, unifor and hieroglyphs totally different. And you can actually see the evolution of both hieroglyphics and kuni formm, like the Kuni formm starts off being very simple and then it gets more complicated. And then towards the end it's like, wow, okay. They really get very sophisticated with the Kuni formm. So I, I think if civilization is being about 5,000 years old and earth is, if physics is correct, four and a half million years old. So civilization has been around for 1000000th of us' existence flash in the pan.

0 (1h 8m 13s):
Yeah. These are the early, early days. And so we, we Dr very early, we make it very dramatic because there's been rises and falls of empires and

1 (1h 8m 23s):
Many, so many, so many rises and falls of empires. So many.

0 (1h 8m 29s):
And there'll be many more.

1 (1h 8m 30s):
Yeah, exactly. So I mean, only a tiny fraction, probably less than 1% of, of what was ever written in history is, is available to us now. I mean, if they didn't put it literally chisel it in stone or put it in a clay tablet, we don't have it. Yeah. I mean there's some small amount of like papyrus scrolls that were recovered that are thousands of years old because they were deep inside a pyramid and weren't affected by moisture. But, but, but other than that it's really gotta be in a clay tablet or chiseled. So the vast majority of stuff was not chiseled. 'cause you know, it takes a while to chisel things. So that's why we put tiny, tiny fraction of the information from history.

1 (1h 9m 12s):
But even that little information that we do have, and the archeological record shows so many civilizations rising and falling, it's wild.

0 (1h 9m 21s):
We tend to think that we're somehow different from those people. One of the other things they do at highlights is that human nature seems to be the same. It just persists.

1 (1h 9m 31s):
Yeah. I mean the basics of human nature are more or less the same. Yeah.

0 (1h 9m 35s):
So we get ourselves in trouble in the same kinds of ways. I think even with the advanced technology.

1 (1h 9m 41s):
Yeah. I mean you, you do tend to see the same patterns, similar patterns, you know, for civilizations where they go through life cycle like, like an organism, you know, sort of just like a human is sort of a zygote fetus baby, you know, toddler, teenager, you know, eventually get, gets old and dies. The civilizations go through a life cycle. No civilization will last forever.

0 (1h 10m 13s):
What do, what do you think it takes for the American empire to not collapse in the near term future in the next a hundred years to continue flourishing?

1 (1h 10m 29s):
Well, the single biggest thing that is o often actually not mentioned in history books, but Durant does mention it, is the birthright. So like a, like a perhaps to some, a counterintuitive thing happens when civilizations become, are are winning for too long, that they've been, they, the birth rate declines, it can often decline quite rapidly. We're seeing that throughout the world today. You know, currently South Korea is like, I think maybe the lowest fertility rate, but there, there are many others that are close to it.

1 (1h 11m 10s):
It's like 0.8. I think if the birth rate doesn't decline further, a South Korea will lose roughly 60% of its population. And, and, but every year that birth rate is dropping, and this is true through most of the world, I'm don don't mean to single out South Korea. It's been happening throughout the world. So as, as soon as, as, as soon as any given civilization reaches a level of prosperity, the birth rate drops And. now you can go and look at the same thing happening in ancient, in ancient Rome. So Julius Caesar took note of this, I think around 50, 50 ish BC and tried to pass, I dunno if you're successful, try to pass a law to give an incentive for any Roman citizen that would have a third child.

1 (1h 12m 1s):
And I think Augustus was, was able to, well he was, you know, the dictator. So this, the Senate was just for show. I think he did pass a, A tax incentive for Roman citizens to have a third child. But It. It, those efforts were unsuccessful. Rome fell because the Romans stopped having, making Romans. That's actually the fundamental issue. And, and there were other things that there, there was like, they had like a quite a serious malaria series of malaria epidemics and plagues and whatnot. But they had those before the, the, the, the, it's just that the birth rate was follower than the death rate.

0 (1h 12m 47s):
It really is that simple.

1 (1h 12m 49s):
Well, I'm saying that's

0 (1h 12m 50s):
More people.

1 (1h 12m 51s):
That's, that's is acquired at a, at a fundamental level. If a civilization does not at least maintain its numbers, it'll disappear.

0 (1h 12m 58s):
So perhaps the amount of compute that the biological computer allocates to, to sex is justified. In fact, we should probably increase it.

1 (1h 13m 8s):
Well, I mean there's this hedonistic sex, which is, you know, that that's neither, that's neither the hit nor there. Yeah. It, it's, it's

0 (1h 13m 16s):
Not productive.

1 (1h 13m 17s):
It's, it's, it doesn't produce kids. Well, you know, you, you what what matters, I mean, Durant makes this very clear. 'cause looked at one civilization after another and they all went through the same cycle. When the civilization was under stress, the birth rate was, was high, but as soon as there were no external en enemies or they, they were, had a extended period of prosperity, the birth rate inevitably dropped every time. I don't believe there's a single exception.

0 (1h 13m 45s):
So that's like the foundation of it. You need to have people

1 (1h 13m 49s):
Yeah, I mean, as a base level. Yeah. No humans, no humanity.

0 (1h 13m 55s):
And then there's other things like, you know, human freedoms and just giving people the freedom to build stuff.

1 (1h 14m 2s):
Y yeah, absolutely. There's, but, but at, at, at a basic level, if you do not at least maintain your numbers, if you're below replacement rate And, that trend continues. You will eventually disappear. This is elementary. Now then obviously we al also want to try to avoid like massive wars, you know, if there's a global thermonuclear war, probably we're roll toast, you know, radioactive toast. So, so we wanna try to avoid those things. Then there, there are, there, there's a thing that happens over time with, with any given civilization, which is that the laws and regulations accumulate.

1 (1h 14m 53s):
And if there's not, if there's not some forcing function, like a war to clean up the accumulation of laws and regulations, eventually everything becomes legal. And you, that the, that's like the hardening of the arteries, or a way to think of it is like being tied down by a million little strings like guer, you can't move. And it's not like any one of those strings is the, is the issue. It's got a million of 'em. So there have, there has to be a, a sort of a, a garbage collection for laws and regulations so that you, you, you don't keep accumulating laws and regulations to the point where you can't do anything.

1 (1h 15m 34s):
This is why we can't build a high-speed rail in America. It's illegal. That's the issue. It's illegal. Six waste of Sunday to build a high speed rail in America.

0 (1h 15m 45s):
I wish you could just like for a week go into Washington and like be the head of the committee for making, what is it for the, the garbage collection making government smaller, like removing stuff.

1 (1h 15m 57s):
I, I have discussed with Trump the idea of a government deficiency commission.

0 (1h 16m 1s):
Nice. Yeah.

1 (1h 16m 3s):
And I would be willing to be part of that commission.

0 (1h 16m 9s):
I wonder how hard that is.

1 (1h 16m 11s):
The, the antibody reaction would be very strong. Yes. Yeah. So you, you really have to, you're attacking the matrix at that point. Matrix will fight back.

0 (1h 16m 26s):
How, how are you doing with that being attacked?

1 (1h 16m 30s):
Me? Attacked?

0 (1h 16m 31s):
Yeah, there's a lot of it.

1 (1h 16m 34s):
Yeah, there is a lot. I mean, every day I know psyop, you know, how do you, with my tinfoil hat, how do

0 (1h 16m 42s):
You keep your just positivity, how do you optimism about the world? A clarity of thinking about the world. So just not become resentful or cynical or all that kind of stuff. Just getting attacked by, you know, a very large number of people misrepresented

1 (1h 16m 55s):
Oh yeah. That, that's like, that's a daily occurrence. Yes. So I mean, it does get me down at times. I mean, it makes me sad, but I mean at some point you have to sort of say, look, the, the attacks are by people that actually don't know me. They're, and they're trying to generate clicks. So you say if, if, if you can sort of detach yourself somewhat emotionally, which is not easy and say, okay, look, this is not actually, you know, from someone that knows me or is they're, they're, they're literally just writing to get, you know, impressions and clicks.

1 (1h 17m 43s):
Then, you know, then I guess it doesn't hurt as much. It's like, it's, it's not quite water. ucs back, maybe it's like acid ucs back.

0 (1h 17m 54s):
All right, well that's good. Just about your own life. What do you as a measure of success in your life?

1 (1h 17m 58s):
A measure of success? I'd say. Like what, how many useful things can I get done

0 (1h 18m 4s):
A day-to-day basis. You wake up in the morning, how can I be useful today?

1 (1h 18m 9s):
Yeah. Maximize utility area under the code of usefulness. Very difficult to be useful at scale.

0 (1h 18m 16s):
At scale. Can you like, speak to what it takes to be useful for somebody like you where there's so many amazing, great teams? Like how do you allocate your time to be in the most useful?

1 (1h 18m 28s):
Well, time, time is the time is the true currency. Yeah. So it is tough to say what, what is the best allocation of time? I mean, there are, you know, often say if you, if you could say Tesla, I mean Tesla, this year we'll do over a hundred billion in revenue. So that's $2 billion a week. If I make slightly better decisions, I can affect the outcome by a billion dollars. So then, you know, I try to do the best decisions I can and on balance, you know, at least compare to the, the competition, pretty good decisions.

1 (1h 19m 9s):
But the marginal value of, of a better decision can easily be in the course of an hour, a hundred million dollars.

0 (1h 19m 19s):
Given that, how do you take risks? How do you do the, the algorithm that you mentioned? I mean, deleting, given a small thing, can be a billion dollars. How do you decide to Yeah,

1 (1h 19m 32s):
Well I, I think you have to look at it on a percentage basis because if you look at it in absolute terms, it's, it's just, I would never get any sleep. It's, I would just be like, I need to just keep working and, and work my brain harder, you know? And I'm not trying to get as much as possible out the, out of this meat computer. So it's not, it's pretty hard. 'cause you can just work all the time. And, and, and at any given point, like I said, a slightly better decision could be a hundred dollars, a hundred million dollar impact for Tesla or SpaceX for that matter. But, It, But It is wild. When, when considering the marginal value of, of time can be a hundred million dollars an hour at times or more.

0 (1h 20m 17s):
Is your own happiness part of that equation of success?

1 (1h 20m 22s):
It has to be to some degree. Other than I'm sad. I, if I'm depressed, I make worse decisions. So I, I can't have, like if, if I have zero recreational time, then I make work worse decisions. So I don't have a lot, but it's, it's above zero. I mean, my motivation, if I've got a religion of any kind is a, a religion of curiosity of trying to understand, you know, it's, it's, it's really the, the mission of gr understand the universe. I'm trying to understand the universe or lets at least set things in motion such that at some point civilization understands the universe or far better than we do today.

1 (1h 21m 2s):
And even what questions to ask, as Douglas Adams pointed out in his book, the, sometimes the, the answer is the, is arguably the easy part. The trying to frame the question correctly is the hard part. Once you frame the question correctly, the answer is often easy. So I'm trying to set things in motion such that we are at least at some point able to understand the universe. So for SpaceX, the goal is to make life multi-planetary. And to which, which is, you know, if, if you go to these, the foamy paradox of where the, where are the aliens?

1 (1h 21m 46s):
You've got these, these sort of great filters. Like, it's just like, why, why have we not heard from the aliens? Now a lot, lot of people think there are aliens among us. I often claim V one, which nobody believes me, but I did say alien registration card at one point on my immigration documents. Yeah. So I've not seen any evidence of aliens. So it, it suggests that at least one of the, one of the explanations is that intelligent life is extremely rare. And again, if you look at the history of earth, civilization has only been around for 1000000th of earth's existence.

1 (1h 22m 28s):
So if, you know, if, if aliens had visited here, say a hundred thousand years ago, they would be like, well, they don't even have writing, you know, just hunter gatherers basically. So, so how long does a civilization last? So for SpaceX, the, the goal is to establish a self-sustaining city on Mars. Mars is the only viable planet for such a thing. The moon is close, but it's, it lacks resources and I think it's probably vulnerable to any, any, any calamity that takes that earth could.

1 (1h 23m 10s):
The moon is too close, it's vulnerable to a calamity that takes that earth. So not saying we shouldn't have a moon base, but Mars is, Mars would be far more resilient. The difficulty of getting to Mars is what makes it resilient. So, but And that, you know, in, in going through the, these various explanations of why don't we see the aliens, why one of them is that they, they failed to pass these, these great filters, these these key hurdles. And one of those hurdles is being a multi planet species.

1 (1h 23m 54s):
So if you're a multi planet species, then if something were to happen, whether that was a national catastrophe or a manmade catastrophe, at least the other planet would probably still be around. So you're not like, you don't have all the eggs in one basket. And once you are sort of a two planet species, you can obviously extend to extend life halves to the asteroid belt, to maybe to the moons of Jupiter and Saturn and ultimately to other star systems. But if you can't even get to another planet, you know, definitely not getting to star systems and

0 (1h 24m 30s):
The other possible great filters and super powerful technology like a GI for example, So, you, you're basically trying to knock out one great filter at a time.

1 (1h 24m 44s):
Digital super intelligence is possibly a great filter. I hope it isn't. But, It might be, you know, guys like, say Jeff Hinton would say, you know, has he invented a number of the key principles and artificial intelligence? I think he puts the probability of AI an annihilation around 10 to 20%, something like that. So, you know, so it's, it's not, it's not like, you know, look on the right side it's 80% likely to be great. So, so, but I I I think AI risk mitigation is important. Being a multi-plan species would be a massive risk mitigation.

1 (1h 25m 28s):
And I, I do wanna sort of once again emphasize this important, the importance of having enough children to sustain our numbers and not going, not plummet into population collapse, which is currently happening. Pop population collapse is a real and current thing. So the, the only reason it's not being reflected in the total population numbers is that, is that as much is because people are living longer. But But, you, you, you, it's easy to predict, say what the population of any given country will be.

1 (1h 26m 8s):
You just take the birth rate last year, how many VAs were born, multiply that by life expectancy and that's what the population will be steady state, unless if, if the birth rate continues to that level, but if it keeps declining, it will be even less and eventually dwindle to nothing. So I keep, you know, banging on the baby drum here for a reason because it has been the, the source of civilizational collapse over and over again throughout history. And so why don't we just not try, try to sta that day?

0 (1h 26m 41s):
Well, in that way, I have miserably failed civilization and I'm trying, hoping to fix that. I would love to have many kids.

1 (1h 26m 50s):
Great. Hope you do. Don't sound like the present.

0 (1h 26m 55s):
Yeah, yeah. I gotta allocate more compute to the whole process. But apparently it's not that difficult.

1 (1h 27m 3s):
No, it's like unschooled labor.

0 (1h 27m 7s):
Well, if I, one of the things you do for me, for the world is to inspire us with what the future could be. And so some of the things we've talked about, some of the things you're building, alleviating human suffering with Neuralink and expanding the capabilities of the human mind, trying to build a colony on Mars. So creating a backup for humanity on, on another planet and exploring the possibilities of what artificial intelligence could be in this world, especially in the real world. AI with hundreds of millions, maybe billions of robots walking around,

1 (1h 27m 45s):
There will be billions of robots. That's, that seems almost, that seems virtual certainty. Well,

0 (1h 27m 51s):
Thank you for building the future and thank you for inspiring so many of us to keep building and creating cool stuff in including kids. You're

1 (1h 28m 1s):
Welcome. Go forth and multiply,

0 (1h 28m 4s):
Go forth and multiply. Thank you Elon. Thanks for talking, brother. Thanks for listening to this conversation with Elon Musk And. now, dear friends, here's DJ sa, the co-founder, president and COO of Neuralink. When did you first become fascinated by the human brain?

3 (1h 28m 24s):
For me, I was always interested in understanding the purpose of things and how it was engineered to serve that purpose, whether it's organic or inorganic, you know, like we were talking earlier about your curtain holders, they serve a clear purpose and they were engineered with that purpose in mind. And, you know, growing up I had a lot of interest in Seeing things, touching things, feeling things, and trying to really understand the root of how it was designed to serve that purpose. And you know, obviously brain is just a fascinating organ that we all carry.

3 (1h 29m 4s):
It's a infinitely powerful machine that has intelligence and cognition that arise from it. And, you know, we, we haven't even scratched the surface in terms of how all of that occurs. But also at the same time, I, I think it took me a while to make that connection to really studying and building tech to understand the brain. Not until graduate school, you know, there were a couple moments, key moments in my life where some of those I think influenced how the trajectory of my life got me to studying what I'm doing right now. You know, one was growing up both sides of my family. My grandparents had a very severe form of Alzheimer and it's, you know, incredibly debilitating conditions.

3 (1h 29m 54s):
I mean, literally you're seeing someone's whole identity and, and their mind just losing over time. And I, I just remember thinking how both the power of the mind, but also how something like that could really lose your sense of identity.

0 (1h 30m 10s):
It's fascinating that that is one of the ways to reveal the power of a thing by watching it lose the power.

3 (1h 30m 18s):
Yeah. A lot of what we know about the brain actually comes from these cases where there are trauma to the brain or some parts of the brain that led someone to lose certain abilities. And as a result there's some correlation and understanding of that part of the tissue being critical for that function. And it's an incredibly fragile organ if you think about it that way. But also it's incredibly plastic and incredibly resilient in many different ways.

0 (1h 30m 46s):
And by the way, the term plastic is, we'll use a bunch means that it's adaptable. So neuroplasticity refers to the, the adaptability of the human brain. Correct.

3 (1h 30m 58s):
Another key moment that sort of influenced how the trajectory of my life have shaped towards the current focus of my life has been during my teenage year when I came to the us, you know, I didn't speak a word of English. There was a huge language barrier and there was a lot of struggle to kind of connect with my peers around me because I didn't understand the, the artificial construct that we have created called language, specifically English in this case. And I remember feeling pretty isolated, not being able to connect with peers around me. So spent a lot of time just on my own, you know, reading books, watching movies, and I, I naturally sort of gravitated towards sci-fi books.

3 (1h 31m 41s):
I just found them really, really interesting. And also it was a great way for me to learn English. You know, some of the first set of books that I picked up are Enders Game, you know, the whole saga by Orson Scott card and Neil Maner from William Gibson and Snow Crash from Neil Stevenson. And you know, movies like Matrix, what's coming out around that time point that really influenced how I think about the potential impact that technology can have for our lives in general. So fast track to my college years, you know, I, I was always fascinated by just, just physical stuff, building physical stuff, and especially physical things that had some sort of intelligence.

3 (1h 32m 24s):
And you know, I studied electrical engineering during undergrad and I started out my research in mems, so micro electro mechanical systems and really building these tiny nano structures for temperature sensing. And I just found that to be just incredibly rewarding and fascinating subject to just understand how you can build some something miniature like that that again served a function and had a purpose. And then, you know, I, I spent large majority of my college years basically building millimeter wave circuits for next gen telecommunication systems for imaging. And it was just something that I found very, very intellectually interesting.

3 (1h 33m 4s):
You know, phase arrays, how the, the signal processing works for, you know, any modern as well as next gen telecommunication system, wireless and wireline em waves or electromagnetic waves are fascinating. How do you design antennas that are most efficient in a small footprint that you have? How do you make these things energy efficient? That was something that just consumed my intellectual curiosity. And, that journey led me to actually apply to and find myself a PhD program at uc, Berkeley at kind of this consortium called the Berkeley Wireless Research Center that was precisely looking at building at the time. We called it xg, you know, similar to 3G, 4G, 5G, but the next next generation G system and how you would design circuits around that to ultimately go on phones and, you know, basically any, any other devices that are wirelessly connected these days.

3 (1h 33m 58s):
So I I I was just absolutely just fascinated by how that entire system works, And that in infrastructure works. And then also during grad school I had sort of the fortune of having, you know, couple research fellowships that led me to pursue whatever project that I want. And that's, that's one of the things that I really enjoyed about my graduate school career, where you got to kind of pursue your intellectual curiosity and the domain that may not matter at the end of the day, but it's something that, you know, really allows you the opportunity to go as deeply as you want, as well as as widely as you want. And at the time I was actually working on this project called the Smart Bandaid, and the idea was that when you get a wound, there's a lot of other kind of proliferation of signaling pathway that cells follow to close that wound.

3 (1h 34m 51s):
And there were hypotheses that when you apply external electric field, you can actually accelerate the closing of that field by having, you know, basically electro taxing of the cells around that wound site. And specifically not just for normal wound, there are chronic wounds that don't heal. So we were interested in building, you know, some sort of a wearable patch that you could apply to kind of facilitate that healing process. And that was in collaboration with Professor Michelle Morowitz, you know, which, which you know, was a great addition to kind of my thesis committee and you know, it really shaped rest of my PhD career.

3 (1h 35m 33s):
So this would be the first time you interacted with biology, I suppose, correct? Correct. I mean, there were some peripheral, you know, end application of the wireless imaging and telecommunication system that I was using for security and bioimaging, but this was a very clear direct application to biolog biology and biological system and understanding the constraints around that and really designing and engineering electrical solutions around it. So that was my first Introduction and that's also kind of how I got introduced to Michel. You know, he's, he's sort of known for remote control of beetles in the early two thousands and then around 2013, you know, obviously kind of the holy grail when it comes to implantable system is to kind of understand how small of a thing you can make.

3 (1h 36m 29s):
And a lot of that is driven by how much energy or how much power you can supply to it and how you extract data from it. So at the time at Berkeley there was kind of this, this desire to kind of understand in the neural space what, what, what sort of system you can build to really miniaturize these implantable systems. And I, I distinct distinctively remember this one particular meeting where Michelle came in and he's like, guys, I think I have a solution. The solution is ultrasound. And, and then he proceeded to kind of walk through why that is the case, And, that that really formed the basis for my thesis work called Neural dust System that was looking at ways to use ultrasound as opposed to electromagnetic waves for powering as well as communication.

3 (1h 37m 21s):
I guess I should step back and say the, the initial goal of the project was to build these tiny, about a size of a neuron implantable system that can be parked next to a neuron, being able to record its state and being able to ping that back to the outside world for doing something useful. And as I mentioned, the size of the implantable system is limited by how you power the thing and get the data off of it. And at the end of the day, fundamentally, if you look at a human body, we're essentially bag of salt water with some interesting proteins and chemicals, but it's, it's mostly salt water that's very, very well temperature regulated at 37 degrees Celsius.

3 (1h 38m 6s):
And we'll, we'll get into how, why and, and, and later why that's an extremely harsh environment for any electronics to survive. As I'm sure you've experienced or maybe not experienced, you know, dropping cell phone in a, in a salt water in an ocean, it will instantly kill the device, right? But anyways, just in general, electromagnetic waves don't penetrate through this environment well and just the speed of light, it is what it is. We can't, we can't change it. And based on the, the wavelength at which you are interfacing with the device, it, the device just needs to be big. Like these inductors needs to be quite big.

3 (1h 38m 47s):
And the general good rule of thumb is that you want the wavefront to be roughly on the order of the size of the thing that you're interfacing with. So an implantable system that is around 10 to hundred micron in dimension, in, in, in a volume which is about the size of a neuron that you see in a, in a human body, you would have to operate at like hundreds of gigahertz, which number one, not only is it difficult to build electronics operating at those frequencies, but also the body just attenuates that very, very significantly. So the interesting kind of insight of this ultrasound was the fact that ultrasound just travels a lot more effectively in the human body tissue compared to electromagnetic waves.

3 (1h 39m 37s):
And this is something that you encounter and you, I I'm sure most people have encountered in their lives when you go to, you know, hospitals that are medical ultrasound, you know, sonograph, right? And they go into very, very deep depth without attenuating too much, too much of the signal. So all in all, you know, ultrasound, the fact that it travels through the body extremely well and the mechanism to which it travels to, to the body really well is that just the wavefront is very different. It's electromagnetics waves are transverse, whereas in ultrasound waves are compressive.

3 (1h 40m 18s):
So it's just a completely different mode of wavefront propagation and as well as speed of sound is orders and orders of magnitude less than speed of light, which means that even at 10 megahertz ultrasound wave, your wavefront ultimately is a very, very small wavelength. So if you're talking about interfacing with the 10 micron or a hundred micron type structure, you would have 150 micron wavefront at 10 megahertz. And building electronics at those mega at at those frequencies are much, much easier and they're a lot more efficient. So the basic idea kind of was born out of, you know, using ultrasound as a mechanism for powering the device and then also getting data back.

3 (1h 41m 6s):
So now the question is how do you get the data back? The mechanism to which we landed on is what's called back scattering. This is actually something that is very common And that we interface on a day-to-day basis with our RFID cards, you know, a radio frequency ID tag where there's actually rarely, you know, in your ID a battery inside there's an antenna and there's some sort of coil that has your serial identification id, and then there's an external device called the reader that then sends a wavefront and then you reflect back that wavefront with some sort of modulation that's unique to your id.

3 (1h 41m 47s):
That's, that's what's called back scattering fundamentally. So the tag itself actually doesn't have to consume that much energy. And that was a mechanism to which we were kind of thinking about sending the data back. So when you have an external ultrasonic transducer that's sending ultrasonic wave to your implant, the Neural dust implant, and it records some information about its environment, whether it's a neuron firing or some other state of the, the tissue that is interfacing with, and then it just amplitude modulates the wavefront that comes back to the

0 (1h 42m 27s):
Source and the recording step would be the only one that requires any energy. So what would require energy in that low step?

3 (1h 42m 34s):
Correct. So it, it is that initial kind of startup circuitry to get that recording, amplifying it and then just modulating And the mechanism to which that, that you can enable that is there is this specialized crystal called PSO electric crystals that are able to convert sound energy into electrical energy and vice versa So, you can kind of have this interplay interplay between the ultrasonic domain and electrical domain that is the, the biological tissue.

0 (1h 43m 4s):
So on the theme of parking very small computational devices next to neurons, that's the dream, the vision of brain computer interfaces. Maybe before we talk about Neuralink, can you give a sense of the history of the field of BCI, what, what has been maybe the continued dream and also some of the milestones along the way with the different approaches and the amazing work done at the various labs?

3 (1h 43m 34s):
I think a good starting point is going back to 1790s,

0 (1h 43m 39s):
I did not expect that

3 (1h 43m 41s):
Where the concept of animal electricity or the fact that bodies electric was first discovered by Luisi Galbani where he had this famous experiment where he connected set of electrodes to frog leg and ran current through it, and then it started twitching and he said, oh my goodness, body's

0 (1h 44m 3s):
Electric. Yeah. So

3 (1h 44m 4s):
Fast forward many, many years to 1920s where Hansberger, who's German psychiatrist discovered EEG or electroencephalography, which is still around there are these electrode arrays that you wear outside the skull that gives you some sort of neural recording. That was a very, very big milestone that you, you, you can record some sort of activities about the human mind. And then in the 1940s there were these group of scientists, Renshaw, Forbes and Morrison that inserted these glass micro electrodes into the cortex and recorded single neurons.

3 (1h 44m 48s):
The fact that they, they, there's signal that are a bit more high resolution and high fidelity as you get closer to the source, let's say. And in the 1950s, these two scientists, Hodgkin and Hawksley showed up and they built this beautiful, beautiful models of the cell membrane and the ionic mechanism and had these like circuit diagram. And as, as someone who's an electric engineer, it's a beautiful model that's, you know, built out of these partial differential equations talking about flow of ions and how that really leads to how neurons communicate. And they won the noble prize for that 10 years later in the 1960s.

3 (1h 45m 30s):
So in 1969, FFE from University of Washington published this beautiful paper called Operating Conditioning of Cortical unit activity where he was able to record a single unit neuron from a monkey and was able to have the monkey modulated based on its activity and reward system. So I, I would say this is the very, very first example as far as I'm aware of closed loop, you know, brain computer interface or BCI,

0 (1h 46m 2s):
The abstract reads, the activity of single neurons in precentral cortex of anesthetized monkeys was conditioned by reinforcing high rates of neuronal discharge with delivery of a food p auditory and visual feedback of unit firing rates was usually provided in addition to food reinforcement. Cool. So they actually got it done.

3 (1h 46m 25s):
They got it done. This is back in 1969,

0 (1h 46m 30s):
After several training sessions, monkeys could increase the activity of newly isolated cells by 50 to 500% above rates before reinforcement. Fascinating

3 (1h 46m 42s):
Brain is very plastic.

0 (1h 46m 44s):
And so and so from here, the number of experiments grew.

3 (1h 46m 49s):
Yeah. Number of experiments as well as a set of tools to interface with the brain have just exploded, I think. And, and also just understanding the neural code and how some of the cortical layers and, and the functions are organized. So the other paper that is pretty seminal, especially in the the motor decoding was this paper in the eight 1980s from Georgia Opolis that discovered that there's this thing called motor tuning curve. So what are motor tuning curves? It's the fact that there are, you know, neurons in the motor cortex of mammals, including humans that have a preferential direction that causes them to fire.

3 (1h 47m 33s):
So what that means is there are a set of neurons that would increase their spiking activities when you're thinking about moving to the left, right up, down and any of those vectors. And based on that, you know, you could start to think, well if you, if you can't identify those essential igon vectors, you can do a lot and you can actually use that information for actually decoding someone's intended movement from the cortex. So that was a very, very seminal kind of paper that showed that there there is some sort of code that you can, you can extract, especially in the mortal cortex.

0 (1h 48m 12s):
So there's signal there and if you measure the, the electrical signal from the brain that you could, you could actually figure out what the intention was. Correct.

3 (1h 48m 21s):
Yeah. Not only electrical signals, but electrical signals from the right set of neurons that give you these preferential direction. Hmm.

0 (1h 48m 29s):
Okay. So going slowly towards Neuralink, one interesting question is what do we understand on the BCF front on invasive versus non-invasive from this line of work? How important is it to, to park next to the neuron? What does that get you?

3 (1h 48m 49s):
That answer fundamentally depends on what you want to do with it, right? There's actually incredible amount of stuff that you can do with EEG and electrocardiograph ecog, which actually doesn't penetrate the, the cortical layer or parenchyma But. you place a set of electrodes on the surface of the brain. So the thing that I'm personally very interested in is just actually understanding and, and being able to just really tap into the high resolution, high fidelity understanding of the activities that are happening at the local level. And, you know, we can get into biophysics, but just to kind of step back to kind of use analogy, 'cause analogy here can be useful and sometimes it's a little bit difficult to think about electricity.

3 (1h 49m 34s):
At the end of the day we're doing electrical recording that's mediated by ionic currents, you know, movements of these charged particles, which is really, really hard for most people to think about. But turns out a lot of the activities that are happening in the brain and the frequency bandwidth, which that's happening is actually very, very similar to sound waves and, and you know, our normal conversation audible range range. So the analogy that typically is used in the field is in a few, if you, if you have a football stadium, you know there's game going on. If you stand outside the stadium, you, you maybe get a sense of how the game is going based on the cheers and the booze of the home crowd, whether the team is winning or not.

3 (1h 50m 19s):
But, you have absolutely no idea what the score is. You have absolutely no idea what individual audience or the players are talking or saying to each other what the next play is, what the next goal is. So what you have to do is you have to drop the microphone near into the stadium and then get near the source, like into the individual chatter in this specific example, you would want to have it, you know, right next to where the huddle's happening. So I, I think that's kind of a good illustration of what we're trying to do when we say invasive or minimally invasive or implanted brain computer interfaces versus non-invasive or non implanted brain interfaces.

3 (1h 51m 2s):
It's basically talking about where do you put that microphone and what can you do with that information.

0 (1h 51m 7s):
So what, what is the biophysics of the read and write communication that we're talking about here as we now step into the efforts at Neuralink?

3 (1h 51m 18s):
Yeah, so brain is made up of these specialized cells called neurons. There's billions of them, you know, tens of billions, you know, sometimes people call it a hundred billion that are connected in this complex yet dynamic network that are constantly remodeling, you know, they're changing their synaptic weights and that's, you know, what, what we typically call neuroplasticity. And the neurons are also bathed in this charged environment that is latent with many charged molecules like potassium ions, sodium ions, chlorine ions.

3 (1h 51m 59s):
And those actually facilitate these, you know, through ionic current communication between these different networks. And when you look at the, look at a neuron as well, they, they have these membrane with a beautiful, beautiful protein structure called the voltage selective ion channels, which in my opinion is one of nature's best inventions in many ways. If you think about what they are, they're doing the job of a modern day transistors. Transistors are nothing more at the end of the day than a voltage gated conduction channel. And nature found a way to have that very, very early on in its evolution.

3 (1h 52m 43s):
And as we all know with the transistor, you can have many, many computation and a a lot of amazing things that, that we have access to today. So IIII think I it's one of those just as a tangent, just a beautiful, beautiful invention that the nature came up with these voltage gated ion channels.

0 (1h 53m 2s):
I mean, I, I suppose there's, on the biological level, every level of the complexity of the hierarchy of the, of the organism, there's going to be some mechanisms for storing information and for doing computation. And this is just one such way. But to do that with biological and chemical components is interesting. Plus like when neurons, I mean, it's not just electricity, it's chemical communication, it's also mechanical. I mean, these are like actual objects that have like, that vibrate. I mean they move

3 (1h 53m 36s):
Yeah, they're, they're actually, I mean there's a lot of really, really interesting physics that that, that are involved in, you know, kind of going back to my work on ultrasound during grad school. There, there are groups and there were groups and there are still groups looking at ways to cause neurons to actually fire and action potential using ultrasound wave. And the mechanism to which that's happening is still unclear as I understand. You know, it may just be that, you know, you're imparting some sort of thermal energy And that causes cells to depolarize in some interesting ways. But there are also these ion channels or even membranes that actually just open up its poor as they're being mechanically like shook, right?

3 (1h 54m 21s):
Vibrated. So there's just a lot of, you know, elements of these like move particles, which again, like that's governed by diffusion physics, right? Movements of particles. And there's also a lot of kind of interesting physics there.

0 (1h 54m 36s):
Also, not to mention as Roger Penrose talks about the, there might be some beautiful weirdness in the quantum mechanical effects of all of this. Oh yeah. And he, he actually believes that Consciousness might emerge from the quantum mechanical effects there. So like there's physics, there's chemistry, there's biology, all of that is going on there. Oh

3 (1h 54m 55s):
Yeah, yeah. I mean you can, yes, I, there's, there's a lot of levels of physics that you can dive into, but yeah, in the end you have these membranes with these voltage gated ion channels that selectively let these charge molecules that are in, in the extracellular matrix, like in and out. And these neurons generally have these like resting potential where there's a voltage difference between inside the cell and outside the cell. And when there's some sort of stimuli that changes the states such that they need to send information to the, the downstream network, you know, you start to kind of see these like sort of orchestration of these different molecules going in and out of these channels.

3 (1h 55m 44s):
They also open up, like more of them open up once it reaches some threshold to a point where, you know, you have a depolarizing cell that sends a action potential. So it's a just a very beautiful kind of orchestration of these, these, these molecules. And what we're trying to do when we place an electrode or parking it next to a neuron is that you're trying to measure these local changes in the potential, again, mediated by the, the, the movements of the ions. And what's interesting, as I, as I mentioned earlier, there's a lot of physics involved and the two dominant physics for this electrical recording domain is diffusion physics and electromagnetism.

3 (1h 56m 31s):
And where one dominates, where Max Maxwell's equation dominates versus fixed law dominates depends on where your electrode is. If it's close to the source, mostly electromagnetic based, when you're farther away from it, it's more diffusion based. So essentially when you're able to park it next to it, you can listen in on those individual chatter and those local changes in the potential and the type of signal that you get are these canonical textbook neural spiking waveform. When you're, the moment you're further away and based on some of the studies that people have done, you know, Christophe k slab and, and others, once you're away from that source by roughly around a hundred micron, which is about width of ba human hair, you no longer hear from that neuron.

3 (1h 57m 24s):
You, you're no longer able to kind of have the system sensitive enough to be able to record that particular local membrane potential change in that neuron. And just to kind of give you a sense of scale also, when you, when you look at a hundred micron voxel, so a hundred micron by a hundred micron by a hundred micron box in a brain tissue, there's roughly around 40 neurons and whatever number of connections that they have. So there's a lot in that volume of tissue. So the moment you're outside of that, you're, there's just no hope that you'll be able to detect that change from that one specific neuron that you may care about.

0 (1h 58m 3s):
Yeah. But as you're moving about this space, you'll be hearing other ones. So if you move another a hundred micron, you'll be hearing chatter from another community. Correct. And so the, the whole sense is you wanna place as many as possible electrodes and then you're listening to the chatter.

3 (1h 58m 20s):
Yeah. You wanna listen to the chatter. And, and at the end of the day, you also want to basically let the software do the, do the job of decoding. And just to kind of go to, you know, why ECOG and EEG work at all, right? When you have these local changes, you know, obviously it's not just this one neuron that's activating, there's many, many other networks that are activating all the time. And you do see sort of a general change in the potential of this electrode, like this charge medium and that's what you're recording when you're farther away. I mean, you, you still have some reference electrode that's stable in the brain that's just electroactive organ and you're seeing some combination aggregate action potential changes and then you can pick it up, right?

3 (1h 59m 7s):
It's a much slower changing signals But, you know, there there are these like canonical kind of oscillations and waves like gam, oas, beta waves, like when you sleep that that can be detected. 'cause there's sort of a synchronized kind of global, global effect of the brain that, that you can detect. And I mean the physics of this go, like, I mean if we really want to go down that rabbit hole, like there, there's a lot that goes on in terms of like why diffusion physics at some point dominates when you're further away from the source. You know, it it, it's just a charged medium. So similar to how when you have electromagnetic ways propagating in atmosphere or in, in a charged medium like a plasma, there's this weird shielding that happens that actually further attenuates the signal as you move away from it.

3 (2h 0m 0s):
So yeah, you see like if you do a really, really deep dive on kind of the signal attenuation over distance, you start to see kind of one of where r square in the beginning and then exponential drop off. And that's the knee at which, you know, you go from electromagnet magnetism dominating to diffusion, physics dominating.

0 (2h 0m 20s):
But once again, with the electrodes, the, the biophysics, the you need to understand is, is not as deep because no matter where you're placing that, you're listening to a small crowd of local neurons. Correct?

3 (2h 0m 33s):
Yeah. So once you penetrate the brain, you know, you're in the arena, so to speak.

0 (2h 0m 37s):
And there's a lot of neurons.

3 (2h 0m 39s):
There are many, many

0 (2h 0m 40s):
Of 'em. But then again there's like, there's a whole field of Neuroscience that's studying like how the different groupings, the different sections of the seeding in the arena, what they usually are responsible for, which is where the, the metaphor probably falls apart. Yeah. 'cause the, the seating is not that organized in an arena.

3 (2h 0m 56s):
Also, most of them are silent. They don't really do much, you know, or, or they, their activities are, you know, you have to hit it with just the right set of stimulus.

0 (2h 1m 7s):
So they're usually quiet.

3 (2h 1m 9s):
They're usually very quiet. Yeah, quiet. There's, I mean, similar to dark energy and dark matter, there's dark neurons. What are they all doing when you place these electrode, again, like within this a hundred micron volume, you have 40 or so neurons. Like why are, why do you not see 40 neurons? Why do you see only a handful? What is happening there?

0 (2h 1m 26s):
Well, they're mostly quiet, but like when they speak they say profound shit. I think that's the way I'd like to think about it. Anyway, before we zoom in even more, let's zoom out. So how does Neuralink work from the surgery to the implant, to the signal and the decoding process and the human being able to use the implant actually affect the, the world outside And all of this, I'm asking in the context of there's a gigantic historic milestone in Neuralink just accomplished in January of this year, putting a Neuralink implant in the first human being, Noland.

0 (2h 2m 11s):
And there's been a lot to talk about there about his experience because he's able to describe all the nuance and the beauty and the fascinating complexity of that experience of everything involved. But on the technical level, how does Neuralink work?

3 (2h 2m 26s):
Yeah, so there are three major components to the technology that we're building. One is the device, the thing that's actually recording these neural chatters, we call it N one implant or the link. And we have a surgical robot that's actually doing an implantation of these tiny, tiny wires that we call threads that are, you know, smaller than human hair. And once everything is ized, you have these neural signals, these spiking neurons that are coming out of the brain and you need to have some sort of software to decode what the users intend to do with that.

3 (2h 3m 8s):
So there's what's called the Neuralink application, or B one app that's doing that translation. It's running the very, very simple machine learning model that decodes these inputs that are neural signals and then converted to a set of outputs that allows, you know, our participant, first participant Nolan, to be able to control a cursor

0 (2h 3m 30s):
On this. And this is done wirelessly.

3 (2h 3m 34s):
And this is done wirelessly. So we, our, our implant is actually a two part, that's the link has, you know, these flexible tiny wires called threads that have multiple electrodes along its length. And they're only inserted into the cortical layer, which is about three to five millimeters in a human, human brain in the motor cortex region. That's where the kind of the intention for movement lies in. And we have 64 of these threads. Each thread having 16 electrodes along, you know, the span of three to four millimeters separated by 200 microns So.

3 (2h 4m 14s):
you can actually record along the death of the insertion. And based on that signal, there's custom, you know, integrated circuit or ASIC that we built that amplifies the neural signals that you're recording and then digitizing it and then has some mechanism for detecting whether there was a, an interesting event that is a spiking event and decide to send that, or not send that through Bluetooth to an external device, whether it's a, a phone or a computer that's running this Neuralink application.

0 (2h 4m 50s):
So there's onboard signal processing already just to decide whether this is an interesting event or not. So there is some computational power on board inside the, in addition to the human brain?

3 (2h 5m 0s):
Yeah. So it does the signal processing to kind of really compress the amount of signal that you, you're recording. So we have a total of a thousand electrodes sampling at, you know, just under 20 kilohertz with 10 bit each. So wow, that's 200 megabits. That's coming through to the chip from thousand channel simultaneous neural recording. And that's quite a bit of data. And you know, there is, there are technology available to send that off wirelessly, but being able to do that in a, a very, very thermally constrained environment that is a brain. So there has to be some amount of compression that happens to send off only the interesting data that you need, which in, in this particular case for motor decoding is occurrence of a spike or not.

3 (2h 5m 50s):
And then being able to use that to, to, you know, decode the intended cursor movement. So the implant itself processes, it figures out whether a spike happened or not with our spike detection algorithm. And then sends it off packages, it sends it off through Bluetooth to an external device that then has the model to decode, okay, based on the spiking inputs, did Nolan wish to go up, down, left, right, or click, or right click or whatever.

0 (2h 6m 24s):
All of this is really fascinating, but let's stick on the N one implant itself. So the thing that's in the brain, so I'm looking at a picture of it, there's an enclosure, there's a charging call, so we didn't talk about the charging, which is fascinating. The, the, the battery, the power electronics, the antenna. Then there's the signal processing electronics. I wonder if there's more kinds of signal processing you can do. That's, that's another, that's another question. And then there's the threads themselves with the enclosure on the bottom. So maybe to ask about the charging Yeah, so there's a external charging device.

3 (2h 7m 3s):
Yeah, there's an external charging device. So yeah, the, the second part of the implant, the threads are the ones, again, just the, the last three to five millimeters are the ones that are actually penetrating the cortex. Yeah. Rest of it is actually, most of the volume is occupied by the battery, rechargeable battery and you know, it's about a size of a quarter. You know, I actually have a device here if you wanna take a look at it, You know, this is the, the flexible threat component of it. Wow. And then this is the implant. So it's about a size of a US quarter, it's about nine millimeter thick.

3 (2h 7m 44s):
So basically this implant, you know, once you have the C craniectomy and the, and the ectomy thread are inserted and the, the hole that you created, this c craniectomy gets replaced with that. So basically that thing plugs that hole and you can screw in these self drilling cranial screws to hold it in place. And at the end of the day, once you have the skin flap over, there's only about two to three millimeters. That's, you know, obviously transitioning off of the top of the implant to where the screws are. And, and that's the minor bump that you have.

0 (2h 8m 22s):
Those threads look tiny. That's incredible. That is really incredible. That is really incredible. And also, as you're right, most of the vol actual volume is the battery. Yeah. Wow. This is way smaller than I realized.

3 (2h 8m 38s):
They, they are also, the threads themselves are quite strong. They

0 (2h 8m 41s):
Look strong

3 (2h 8m 43s):
And, and the thread themselves also has a very interesting feature at the end of it called the loop. And that's the mechanism to which the robot is able to interface and manipulate this tiny hair-like structure.

0 (2h 8m 56s):
And they're tiny. So what's the width of a thread?

3 (2h 8m 58s):
Yeah, so the, the width of a thread starts from 16 micron and then tapers out to about 84 micron So. you know, average human hair is about 80 to a hundred micron in width.

0 (2h 9m 13s):
This thing is amazing. This thing is amazing.

3 (2h 9m 17s):
Yes. Most of the volume is occupied by the, by the battery rechargeable lithium ion cell. And the charging is done through inductive charging, which is actually very commonly used. You know, your cell phone, most cell phones have that. The biggest difference is that, you know, for us, you know, usually when you have a phone and you want to charge it on a charging pad, you don't really care how hot it gets. Whereas for us it matters. There's a very strict regulation and good reasons to not actually increase the surrounding tissue temperature by two degrees Celsius. So there's actually a lot of innovation that is packed into this to allow charging of this implant without causing that temperature threshold to reach.

3 (2h 10m 4s):
And even small things like you see this charging coil and what's called a Ferris shield, right? So without that Ferris shield, what you end up having when you have, you know, resonant inductive charging is that the battery itself is a metallic can. And you form these edit currents from external charger And that causes heating And that actually contributes to inefficiency in charging. So this phite shield, what it does is that it actually concentrate that field line away from the battery and then around the coil that's actually wrapped around it. There's

0 (2h 10m 43s):
A lot of really fascinating design here to, to make it, I mean, you're integrating a computer into a biological, a complex biological system. Yeah,

3 (2h 10m 53s):
There's a lot of innovation here. I would say that part of what enabled this was just the innovations in the wearable. There's a lot of really, really powerful tiny low power microcontrollers, temperature sensors or various different sensors and power electronics. A lot of innovation really came in the, the charging coil design, how this is packaged and how do you enable charging such that you don't really exceed that temperature limit, which is not a constraint for other devices out there.

0 (2h 11m 28s):
So let's talk about the threads themselves, those tiny, tiny, tiny things. So how many of them are there? You mentioned a thousand electrodes. How many threads are there and what did the electrodes have to do with the threads?

3 (2h 11m 42s):
Yeah, so the current instantiation of the device has 64 threads and each thread has 16 electrodes for a total of 1024 electrodes that are capable of both recording and stimulating. And the thread is basically this polymer insulated wire. The metal conductor is the kind of a tear amisu cake of uht plate gold plate tie. And they're very, very tiny wires. Two micron in width, so two 1000000th of meter.

0 (2h 12m 26s):
It's crazy that that thing I'm looking at has the polymer installation, has the conducting material and has 16 electrodes at the end of it.

3 (2h 12m 34s):
On each of those

0 (2h 12m 35s):
Threads. Yeah, on each of those threads. Correct. 16 each one of those,

3 (2h 12m 38s):
Yes. You're not gonna be able to see it with naked eyes.

0 (2h 12m 42s):
And I mean to state the obvious, or maybe for people who are just listening, they're flexible.

3 (2h 12m 48s):
Yes, yes. That's also one element that was incredibly important for us. So each of these thread are now, as I mentioned, 16 micron in width and then they taper to 84 micron. But in thickness they're less than five mil micron. And in thickness is mostly, you know, polyamide at the bottom and this metal track and then another polyamide. So two micron of polyamide, 400 nanometer of this metal stack and two micron of polyamide sandwich together to protect it from the environment. That is a 37 degrees C bag of salt water.

0 (2h 13m 26s):
So what, what's some, maybe can you speak to some interesting aspects of the material design here? Like what Does it take to, to design a thing like this and to be able to manufacture a thing like this for people who don't know anything about this kind of thing? Yeah,

3 (2h 13m 41s):
So the material selection that we have is not, I don't think it was particularly unique there, there were other labs and there are other labs that are kind of looking at similar material stack. There's kind of a fundamental question and, and still needs to be answered around the longevity and reliability of these micro electrodes that, that we call compared to some of the other more conventional neural interfaces devices that are intracranial. So penetrating the cortex that are more rigid, you know, like the Utah array that, that are these four by four millimeter kind of silicon shank that have exposed recording site at the end of it.

3 (2h 14m 27s):
And, and you know, that's, that's been kind of the innovation from Richard Norman back in 1997. It's called the Utah Array. 'cause you know, he was at University of Utah

0 (2h 14m 36s):
And what, what does the Utah array look like? So it's a rigid type of

3 (2h 14m 41s):
Yeah, so we can actually look it up. Yeah, yeah. So it's a bed of needle. There's, yeah.

0 (2h 14m 53s):
Okay, go ahead.

3 (2h 14m 53s):
I'm sorry. So those are rigid, rigid shank rigid,

0 (2h 14m 56s):
Yeah, you

3 (2h 14m 56s):
Weren't kidding. And, and the size and the number of shanks vary anywhere from 64 to 1 28. At the very tip of it is an exposed electrode that actually records Neural signal. The other thing that's interesting to note is that unlike Neuralink threads that have recording electrodes that are actually exposed iridium oxide recording sites along the death, this is only at a single death. So these ute array spokes can be anywhere between 0.5 millimeters to 1.5 millimeter. And they're, they also have designs that are slanted So. you can have it inserted at different depth, but that's one of the other big differences. And then, I mean, the main key difference is the fact that there's no active electronics.

3 (2h 15m 40s):
These are just electrodes and then there's a bundle of a wire that you're seeing and then that actually then exits the C craniectomy that then has this port that you can connect to for any external electronic devices they are working on a or have the wireless telemetry device. But It still requires a through the skin port. That actually is one of the biggest failure modes for infection for the system.

0 (2h 16m 7s):
What are some of the challenges associated with flexible threads? Like for example, on the robotic side, R one implanting those threads, how difficult does that task?

3 (2h 16m 20s):
Yeah, so as you mentioned, they're, they're very, very difficult to maneuver by hand. These, these youth RAs that you, you saw earlier, they're actually inserted by a neurosurgeon actually positioning it near the site that they want. And then they're actually, there's a pneumatic hammer that actually pushes them in. So, so it's a, it's a pretty simple process and they're easy to maneuver. But for, for these thin film arrays, they're, they're very, very tiny and flexible. So they're, they're very difficult to maneuver. So that, that's why we built an entire robot to do that. There are other other reasons for why we built a robot and And that is ultimately we want this to help millions and millions of people that can benefit from this.

3 (2h 17m 4s):
And there just aren't that many neurosurgeons out there. And, you know, robots can be something that, you know, we hope can actually do large parts of the surgery But you. Yeah. The, the, the robot is this entire other sort of category of product that we're working on. And it, it's essentially this multi AEs gantry system that has the specialized robot head that has all of the optics and this, this kind of a needle retracting mechanism that maneuvers these, these threads via this loop structure that you have on the thread.

3 (2h 17m 52s):
So

0 (2h 17m 53s):
The thread already has a loop structure by which you can grab it? Correct. Okay. Correct. So this is fascinating. So, you mentioned optics. So there's a robot R one. So for now there's a human that actually creates a hole in this, in this skull. And then after that there's a computer vision component that's finding a way to avoid the blood vessels and then you're grabbing it by the loop, each individual thread and placing it in a particular location to avoid the blood vessels and also choosing the depth of placement, all that. So controlling every, like the 3D geometry of the placement? Correct.

3 (2h 18m 32s):
So the, the aspect of this robot that is unique is that it's not surgeon assisted or human assisted. It's a semi-automatic or automatic robot. Once you, you know, obviously there are human component to it, when you're placing targets you can always move it away from kind of major vessels that you see. But I mean, we wanna get to a point where one click and it just does the surgery within minutes. So

0 (2h 18m 57s):
The computer vision component finds great targets candidates and the human kind of approves them and the robot Does it, Does it, do like one thread at a time or Does it do one,

3 (2h 19m 8s):
It does one thread at a time. And that's, that's actually also one thing that we are looking at ways to do multiple threads at a time. There's nothing stopping from it. You can have multiple kind of engagement mechanisms, but right now it's one by one. And you know, we also still do quite a bit of just, just kind of verification to make sure that it got inserted. If so, how deep, you know, did it actually match what was programmed in and you know, so on and so

0 (2h 19m 36s):
Forth. And the, the actual electrode is a place to vary at differing depths in the like, I mean, it's very small differences but differences. Yeah.

3 (2h 19m 45s):
Yeah.

0 (2h 19m 46s):
And so that, there's some reasoning behind that, as you mentioned, like, it, it gets more varied signal.

3 (2h 19m 56s):
Yeah, we, I mean we try to place them all around three or four millimeter from the surface, just 'cause the span of the electrode. Those 16 electrodes that we currently have in this version spans, you know, roughly around three millimeters. So we wanna get all of those in the brain.

0 (2h 20m 16s):
This is fascinating. Okay, so there's a million questions here. If we could zoom in specific on the electrodes. So what is your sense, how many neurons is each individual electrode listening to?

3 (2h 20m 27s):
Yeah, each electrode can record from anywhere between zero to 40, as I mentioned right earlier. But practically speaking, we only see about at most like two to three. And you can actually distinguish which neuron it's coming from by the shape of the spikes. Oh, cool. So I mentioned the spike detection algorithm that we have. It's called boss algorithm buffer online Spike sorter.

0 (2h 20m 58s):
Nice.

3 (2h 20m 59s):
It actually outputs at the end of the day six unique values, which are, you know, kind of the amplitude of these like negative going hump, middle hump, like positive going hump, and then also the time at which these happen. And from that you can have a, you know, kind of a statistical proba probability estimation of is that a spike? Is it not a spike? And then based on that you could also determine, oh, that spike looks different than that spike must come from a different neuron. Okay.

0 (2h 21m 28s):
So that, that's a nice signal processing step from which you can then make much better predictions about if there's a spike. Yeah. Especially in this kind of context where there could be multiple neurons Yeah. Screaming And that that also results in you being able to compress the data better. Yeah. And the send data. Okay. That's,

3 (2h 21m 46s):
And and, and just to be clear, I mean there the, the labs do this what's called spike sorting. Usually once you have these like broadband, you know, like the, the fully digitized signals and then you run a bunch of different set of algorithms to kind of tease apart. It's just all of this for us is done on the device. On the device in a very low power custom, you know, built ASIC digital processing unit. Highly

0 (2h 22m 15s):
Heat constrained,

3 (2h 22m 16s):
Highly heat constrained, and the processing time from signal going in and giving you the output is less than a microsecond, which is, you know, a very, very short amount of time.

0 (2h 22m 25s):
Oh yeah. So the Latency has to be super short. Correct. Oh wow. Oh that's a pain in the ass. That's really tough. Yeah, Latency

3 (2h 22m 31s):
Tough. This a huge, huge thing that you have to deal with right now. The biggest source of Latency comes from the Bluetooth, the, the way in which they're packetized and you know, we bend them in 15 millisecond. Oh,

0 (2h 22m 43s):
Interesting. Time communication constraint. Is there some potential innovation there on the protocol used? Absolutely. Okay. Yeah,

3 (2h 22m 50s):
Bluetooth is definitely not our final wireless communication protocol that we want to get to. It's a highly, hence

0 (2h 22m 59s):
Hence the N one and the R one. I imagine that increases

3 (2h 23m 4s):
NX rx.

0 (2h 23m 7s):
Yeah, that's, you know, the communication protocol. 'cause Bluetooth allows you to communicate against farther distances than you need to So, you can go much shorter.

3 (2h 23m 16s):
Yeah. The only, well the primary motivation for choosing Bluetooth is that, I mean, everything has Bluetooth,

0 (2h 23m 22s):
All right, So, you can talk to any device

3 (2h 23m 24s):
Interoperability is just absolutely essential, especially in this early phase. And in many ways if you can access a phone or a computer, you can do anything.

0 (2h 23m 35s):
It'll be interesting to step back and actually look at again, the same pipeline that you mentioned for Nolan. So what does this whole process look like from finding and selecting a human being to the, to the surgery, to the, the first time he's able to use this thing.

3 (2h 23m 56s):
So we have what's called a patient registry that people can sign up to, you know, hear more about the updates, And, that was a route to which Nolan applied. And the process is that once the application comes in, you know, it, it contains some medical records and we, you know, based on their medical eligibility there, there's a lot of different inclusion exclusion criteria for them to meet. And we go through a prescreening interview process with someone from Neuralink. And at some point we also go out to their homes to do a BCI home audit. 'cause one, one of the most kind of revolutionary part about, you know, having this in one system that is completely wireless is that you can use it at home.

3 (2h 24m 41s):
Like you don't actually have to go to the lab and, and, you know, go to the clinic to get ized to these like, specialized equipment that you can't take home with you. So that's one of the, the key elements of, you know, when we're designing the system that we wanted to keep in mind, like, you know, people, you know, hopefully would want to be able to use this every day in the comfort of their homes. And so part of our engagement and, and what we're looking for during PC home audit is to just kind of understand their situation, what other assistive technology that they

0 (2h 25m 14s):
Use. And we should also step back and kind of say that the estimate is 180,000 people live with quadriplegia in the United States, and each year an additional 18,000 suffer a paralyzing spinal cord injury. So these are folks who have a lot of challenges living a life in terms of accessibility, in terms of doing the things that many of us just take for granted day to day. And one of the things, one of the goals of this initial study is to enable them to have sort of digital autonomy where they by themselves can interact with a digital device using just their mind, something that you're calling Telepathy.

0 (2h 25m 57s):
So Digital telepathy, where a quadriplegic can communicate with a digital device in all the ways that we've been talking about. Control the mouse cursor enough to be able to do all kinds of stuff, including play games and tweet and all that kind of stuff. And there's, there's a lot of people for whom life the basics of life are difficult because of the things that are, have happened to them. So

3 (2h 26m 25s):
Yeah, I mean, movement is so, so fundamental to our existence. I mean, even, even speaking involves movement of mouth, lip, larynx. And without that it's, it's, it's extremely debilitating. And there, yeah, there, there are many, many people that we can help. And I mean, like, especially if you start to kind of look at other forms of movement disorders that are not just from spinal cord injury, but from, you know, a LS MS or even stroke that, that leads you and or just, just aging, right? That leads you to lose some of that mobility, that independence, it's extremely debilitating.

0 (2h 27m 9s):
And all of these are opportunities to help people to help alleviate suffering, to help improve the quality of life. But each of the things you mentioned is its own little puzzle that needs to have increasing levels of capability from a device like a Neuralink device. And so the first one you're, you're focusing on is, it's just a beautiful word, Telepathy. So being able to communicate using your mind wirelessly with a digital device. Can you just explain this exactly what we're talking about?

3 (2h 27m 40s):
Yeah, I mean, it, it's exactly that. I mean, I, I think if you are able to control a cursor and able to click and be able to get access to computer or phone, I mean the, the whole world opens up to you. And I mean, I guess the word Telepathy, if you kind of think about that as, you know, just definitionally being able to transfer information from my brain to your brain without using some of the, the physical faculties that we have, you know, like voices.

0 (2h 28m 14s):
But the interesting thing here is, I think the thing that's not obviously clear is how exactly it works. So in order to move a cursor, there's at least a couple ways of doing that. So one is you imagine yourself maybe moving a mouse with your hand Or you can then, which no one talked about, like imagine moving the cursor with your mind. Like I don't, but it's like there is a cognitive step here that's fascinating. 'cause you, you, you have to use the brain and you have to learn how to use the brain and you kind of have to figure it out dynamically.

0 (2h 28m 54s):
Like, because you reward yourself if it works So you, like, I mean there's a step that this is, yeah, this is just a fascinating step. 'cause you have to get the brain to start firing in the right way. Yeah. And you do that by imagining, like fake it till you make it and all of a sudden it creates the right kind of signal that if Dakota correctly can create the kind of effect. And then there's like noise around that, that you have to figure all of that out. But on the human side, imagine the cursor moving is what you have to

3 (2h 29m 27s):
Do. Yeah. He says using the force, the

0 (2h 29m 29s):
Force, I mean that's, isn't that just like fascinating to you that it works? Like, to me it's like holy shit that actually works. Like you could move a cursor with your mind,

3 (2h 29m 42s):
You know, as much as you're learning to use that thing, that thing's also learning about you. Like our, our model is constantly updating the weights to say, oh, if, if someone is thinking about, you know, this sophisticated forms of like spiking patterns, like that actually means to do this, right?

0 (2h 30m 2s):
So the, the machine is learning about the human and the human is learning about the machine. So there's a adaptability to the signal processing, the decoding step. And then there's the adaptation of Nolan, the human being. Like the same way if, if you gimme a new mouse and I move it, I learn very quickly about its sensitivity. So I learn to move it le slower and then there's other kinds of signal drift and all that kind of stuff they have to adapt to. So both are adapting to each other. Correct. That's a fascinating like software challenge on both sides. The software on both on the, the human software and

3 (2h 30m 41s):
The organic and the inorganic,

0 (2h 30m 43s):
The organic and the inorganic. Anyway, so sorry to rudely interrupt. So there's this selection that Nolan has passed with flying colors. So everything including that the it is a, B, CI, friendly home, all of that. So what is the, the process of the surgery implantation the first moment when he gets to use the system,

3 (2h 31m 6s):
The end to end, you know, we say patient end to patient out is anywhere between two to four hours. In particular case for Nolan it was about three and a half hours and there's many steps leading to, you know, the actual robot insertion, right? So there's anesthesia induction and we do intra-op CT imaging to make sure that we're, you know, drilling the hole in the right location. And this is also pre-planned beforehand. Someone goes through, someone like Nolan would go through FMRI and then they can think about wi wiggling their hand, you know, obviously due to their injury, it's not gonna actually lead to any, any sort of intended output.

3 (2h 31m 48s):
But it's the same part of the brain that actually lights up when you're imagining moving your finger to actually moving your finger. And that's one of the ways in which we can actually know where to place our threads. 'cause we want to go into what's called a hand knob area in the mortal cortex. And you know, as, as much as possible densely put our electro threads. So yeah, we do intra-op CT imaging to make sure and double check the location of the c craniectomy. And surgeon comes in, does their thing in terms of like skin incision, c craniectomy, so drilling of the skull.

3 (2h 32m 28s):
And then there's many different layers of the brain. There's what's called a dura, which is a very, very thick layer that surrounds the brain, that gets actually resected in a process called ectomy And that then exposed the p and the brain that you want to insert. And by the time it's been around anywhere between one to one and a half hours robot comes in, does this thing, placement of the targets, inserting of the thread that takes anywhere between 20 to 40 minutes. In the particular case for Nolan, it was just under or just over 30 minutes. And then after that the surgeon comes in, there's a couple other steps of like actually inserting the dural substitute layer to protect the thread as well as the, the brain. And then, yeah, screw, screw in the implant and then skin flap and then suture and then you're out.

0 (2h 33m 18s):
So when Nolan woke up, what was that like? Was the recovery like, and what, when was the first time he was able to use it?

3 (2h 33m 27s):
So he, he was actually immediately after the surgery, you know, like an hour after the surgery as he was waking up, we did turn on the device, make sure that we are recording neural signals and we actually did have a couple signals that we notice that he can actually modulate. And what I mean by modulate is that he can think about crunching his fist and you could see the spike disappear and appear.

0 (2h 33m 57s):
That's awesome.

3 (2h 33m 58s):
And, that was immediate, right? Immediate after in, in the recovery room. How how

0 (2h 34m 3s):
Cool is that?

3 (2h 34m 5s):
Yeah,

0 (2h 34m 6s):
That's a human being. I mean, what what did that feel like for you? This device and a human being a first step of a gigantic journey? I mean, it's a historic moment, even just that spike just to be able to modulate that,

3 (2h 34m 22s):
You know, obviously there have been other, other, you know, as you mentioned, pioneers that have participated in these groundbreaking PCI, you know, investigational early feasibility studies. So we're obviously standing in the shoulders of the giants here. You know, we're not the first ones to actually put electrodes in the human human brain. But I, I mean, just leading up to the surgery there was, I I I, I definitely could not sleep. I, there's just, it's the first time that you're working in a completely new environment. We had a lot of confidence based on our benchtop testing or preclinical r and d studies that the mechanism, the threads, the insertion, all that stuff is, is very safe And that it's, you know, obviously ready for doing this in a human, but there's still a lot of unknown, unknown about can the needle actually insert, I mean, I, we brought something like 40 needles just in case they break and we ended up using only one.

3 (2h 35m 29s):
But I mean, that, that was a level of just complete unknown, right? 'cause it's a very, very different environment. And I mean that's, that's why we do clinical trial in the first place to be able to test these things out. So extreme nervousness and just, just I, many, many sleepless night leading up to the surgery and, and definitely the day before the surgery, and it was an early morning surgery. Like we, we started at seven in the morning and, and by the time it was around 10 30, it was, it was, it was, everything was done. But I mean, first time seeing that, well, number one, just, just huge relief that this thing is, you know, doing what it's supposed to do.

3 (2h 36m 11s):
And two, I mean, just immense amount of gratitude for, for Nolan and his family and then many others that have applied And that we've spoken to and will speak to are, I mean, true pioneers in, in every, everywhere. And you know, I I sort of call them the neural astronauts or neural nut

0 (2h 36m 30s):
Neural,

3 (2h 36m 30s):
Not yet, you know, these amazing, just like in the sixties, right? Like these, these amazing just pioneers, right? Exploring the unknown outwards in this case is inward, but incredible amount of gratitude for them to, you know, just, just participate and, and play a part. And, and it's a, it's a journey that we're embarking on together. But also like, I think it was just, that was an very, very important milestone, but our work was just starting. So a lot of just kind of anticipation for okay, what's, what needs to happen next? What are set of sequences of events that needs to happen for us to, you know, make it worthwhile for, you know, both Nolan as well as us.

0 (2h 37m 18s):
Just to linger on that, just a huge congratulations to you and the team for that milestone. I know there's a lot of work left, but that, that is, that's really exciting to see. There's, that's a source of hope. It's this first big step opportunity to help hundreds of thousands of people and then maybe expand the realm of the possible for the human mind for millions of people in the future. So it's, it's really exciting. So like the, the opportunities are all ahead of us and to do that safely and to do that effectively was, was really fun to see as an engineer, just watching other engineers come together and do an epic thing.

0 (2h 38m 2s):
That was awesome. Huge

3 (2h 38m 3s):
Congrats. Yeah. Thank you. Thank you. It's, yeah, could not have done it without the team and yeah, I mean that, that's the other thing that I, I, you know, told the team as well of just this immense sense of optimism for the future. I mean, it was a, it's a very important moment for, for the company, you know, needless to say, as well as hopefully for many others out there that we can help.

0 (2h 38m 27s):
So speaking of challenges, Neuralink published a blog post describing that some of the threads are attracted. And so the performance as measured by bis per second dropped at first, but then eventually it was regained And that the, the whole story of how it was regained is super interesting, has definitely something I'll talk to, to Bliss and to Nolan about. But in general, can you speak to this whole experience? How was the performance regained and just the, the technical aspects of the threads being retracted and moving?

3 (2h 39m 3s):
The main takeaway is that in the end, the performance have come back and it's actually gotten better than it was before. He's actually just beat the world record yet again last week to 8.5 BPS. So I mean, he's nice. He's just cranking and he's just improving. The

0 (2h 39m 21s):
Previous one was that he set was eight, correct?

3 (2h 39m 24s):
He said 8.5.

0 (2h 39m 24s):
Yeah.

3 (2h 39m 25s):
The previous world record in human was 4.6. Yeah.

0 (2h 39m 29s):
So

3 (2h 39m 29s):
It's almost double. Yeah. And his goal is to try to get to 10, which is rough, roughly around kind of the median neural linker using a, a, you know, mouse with the hand. So it's, it's getting there. So

0 (2h 39m 42s):
Yeah. So the, the performance was regained

3 (2h 39m 45s):
Yeah. Better than before. So that, that's, you know, a, a story on its own of what took the PCI team to recover that performance. It was, it was actually mostly on kind of the signal processing and So, you know, as I mentioned, we were kind of looking at these spike outputs from the, our electrodes. And what happened is that kind of four weeks into the surgery, we noticed that the threats have solely come out of the brain. And the way in which we noticed this at first obviously is that, well, I think Nolan was the first to notice that his performance was degrading. And I think at the time we were also trying to do a bunch of different experimentation, you know, different algorithms, different sort of ui ux.

3 (2h 40m 33s):
So it, it was expected that there will be variability in the performance, but we did see kind of a steady decline. And then also the way in which we measure the health of the electrodes, or whether they're in the brain or not, is by measuring impedance of the electrode. So we look at kind of the interfacial, kind of the, the, the ran circuit let they, they say, you know, the capacitance and the, and the, the resistance between the electros surface and the medium. And if that changes in some dramatic ways, we have some indication. Or if you're not seeing spikes on those channels, you have some indications that something's happening there. And what we notice is that looking at those impedance plot and spike rate plots, and also because we have those electrodes recording along the death, you are seeing some sort of movement that indicated that the threats were being pulled out.

3 (2h 41m 24s):
Hmm. And that obviously will have an implication on the model side because if you're, the number of inputs that are going into the model is changing 'cause you have less of them the out that that model needs to get updated, right? And, but, but there were still signals and as I mentioned, similar to how even when you place the signals on the surface of the brain of the brain or farther away, like outside the skull, you still see some useful signals. What we started looking at is not just the spike occurrence through this boss algorithm that I mentioned, but we started looking at just the, the, the power of the frequency band that is interesting for Nolan or Nolan to be able to modulate.

3 (2h 42m 11s):
So once we kind of change the algorithm for the implant to not just give you the bus output, but also these spike band power output that helped us sort of refine the model with the new set of inputs And, that that was the thing that really ultimately gave us the performance back, you know, in, in terms of, and obviously like the, the thing that we want ultimately and the thing that we are working towards is figuring out ways in which we can keep those threats intact for as long as possible so that we have many more channels going into the model. That's, that's by far the number one priority that the team is currently embarking on to understand how to prevent that from happening.

3 (2h 42m 57s):
The thing that I'll say also is that, you know, as I mentioned, this is the first time ever that we're putting these threats in, in a human brain and you know, human brain just for size reference is 10 times out of the monkey brain or the sheep brain. And it, it's just a very, very different environment. It moves a lot more, it like actually moved a lot more than we expected when we did, did Nolan surgery. And it's just a very, very different environment than what we're used to. And this is why we do clinical trial, right? We, we, we wanna uncover some of these issues and, and failure modes earlier than later.

3 (2h 43m 37s):
So in many ways it's provided us with this enormous amount of data and information to be able to solve this. And this is something that Neuralink is extremely good at. Once we have set of clear objective and engineering problem, we have enormous amount of talents across many, many dis disciplines to be able to come together and fix the problem very, very quickly.

0 (2h 44m 1s):
But It sounds like one of the fascinating challenges here is for the system and the decoding side to be adaptable across different timescales. So whether it's movement of threads or different aspects of signal drift sort of on the software of the human brain, something changing like Nolan talks about cursor drift that could be corrected and there's a whole UX challenge to how to do that. So it sounds like adaptability is like a fundamental property that has to be engineered in.

3 (2h 44m 35s):
It is. And, and I mean I think, I mean as a company we're extremely vertically integrated. You know, we make these thin film arrays in our own microfab.

0 (2h 44m 46s):
Yeah. There's, like you said, built in-house. This whole paragraph here from this blog post is pretty gangster building. The technology described above has been no small feat. And there's a bunch of LINKS here that I recommend people click on. We constructed in-house micro fabrication capabilities to rapidly produce various iterations of thin film arrays that constitute our electrode threads. We created a custom femtosecond laser mill to manufacture components with micro level precision. I think there's a tweet associated with this. That's

3 (2h 45m 17s):
A whole thing that we can get into. Yeah,

0 (2h 45m 19s):
This, this, okay, well what are we, what are we looking at here? This thing? Yeah, this is, so in less than one minute, our custom made femto second laser mill cuts this geometry in the tips of our needles. So we're looking at this weirdly shaped needle. The tip is only 10 to 12 microns in width, only slightly larger than the diameter of a red blood cell. The small size allows threats to be inserted with minimal damage to the cortex. Okay. So what's interesting about this geometry, so we're looking at this just geometry of a needle. Yeah.

3 (2h 45m 54s):
This is the needle that's engaging with the loops in the thread. So they're the ones that, you know, thread the, thread the loop and then peel it from the silicon backing. And then this is the thing that gets inserted into the tissue and then this pulls out leaving the thread and this kind of a notch or the shark tooth that we used to call is the thing that actually is grasping the loop. And then it's, it's designed in such way, such that when you, when you pull out, leaps the loop

0 (2h 46m 29s):
And the robot is controlling this needle.

3 (2h 46m 31s):
Correct. So this is actually housed in a cannula and basically the robot is, has a lot of the optics that look forward. Where the loop is, there's actually a 4 0 5 nanometer light that actually causes the poly to fluoresce so that you can locate the, the location of the loop. So

0 (2h 46m 49s):
The loop lights up or

3 (2h 46m 51s):
Yeah, yeah, they do. It's a micron precision process.

0 (2h 46m 55s):
What's interesting about the robot that it takes to do that, that's that's pretty crazy. That's pretty crazy that robot is able to get this kind of precision. Yeah,

3 (2h 47m 2s):
Our robot is quite heavy. Our current version of it. There's, I mean it it's like a giant granite slab that weighs about a ton 'cause it needs to be sensitive to vibration, environmental vibration. And then as the head is moving at the speed that is moving, you know, there's a lot of kind of motion control to make sure that you can achieve that level of precision. A lot of optics that kind of zoom in on that, you know, we're working on next generation of, of the robot that is lighter, easier to transport. I I mean it is a, it is a feat to move the robot to search

0 (2h 47m 38s):
And it's far superior to a human surgeon at this time for this particular task.

3 (2h 47m 43s):
Absolutely. I mean, let alone you try to actually thread a loop in a, in a, in a sewing kit. I mean this is like, we're talking like fractions of human hair. These, these things are, it's not visible.

0 (2h 47m 54s):
So continuing the paragraph, we developed novel hardware and software testing systems such as our accelerated lifetime testing racks and simulated surgery environment, which is pretty cool to stress test and validate the robustness of our technologies. We performed many rehearsals of our surgeries to refine our procedures and make them second nature. This is pretty cool. We practice surgeries on proxies with all the hardware and instruments needed in our mock or in the engineering space. This helps us rapidly test and measure. So there's like proxies.

3 (2h 48m 25s):
Yeah, this proxy's super cool actually. So there's a 3D printed skull from the images that is taken at Barrow as well as this hydrogel mix, you know, sort of synthetic polymer thing that actually mimics the, the mechanical properties of the brain. It also has vasculature of the person. So basically what we're talking about here, and there's a lot of work that has gone into making this set proxy that, you know, it's, it's about like finding the right concentration of these different synthetic polymers to get the right set of consistency for the needle dynamics, you know, as they're being inserted.

3 (2h 49m 9s):
But we practice this surgery with the person, you know, nolan's basically physiology and brain many, many times prior to actually doing the surgery to every,

0 (2h 49m 21s):
Every step. Every step e

3 (2h 49m 23s):
Every step. Yeah. Like where does someone stand? Like, I mean like what you're looking at is the picture this is in, in, in our office of this kind of corner of the robot engineering space that we, you know, have created this like mock or space that looks exactly like what they would experience all the staff would experience during their actual surgery. So I mean it's just kind of like any dance rehearsal where you know exactly where you're gonna stand at what point and you just practice that over and over and over again with an exact anatomy of someone that you're going to ize. And, and it, it got to a point where a lot of our engineers, when we created a craniectomy, they're like, oh that, that looks very familiar.

3 (2h 50m 4s):
We've seen that before. Yeah

0 (2h 50m 6s):
Man, there's wisdom you can gain through doing the same thing over and over and over. It's like a euro dreams of sushi kind of thing because then it's like Olympic athletes visualize the Olympics and then once you actually show up it feels easy. It feels like any other day it feels almost boring winning the gold medal. 'cause you visualize this so many times, you've practiced this so many times and nothing bothers you. It's boring. You win the gold medal is boring and it, the experience they talk about is mostly just relief probably that they don't have to visualize it anymore.

3 (2h 50m 45s):
Yeah. The power of the mind to visualize and where I, I mean there's a whole field that studies where, you know, muscle memory lies in cerebellum. Yeah, it's incredible.

0 (2h 50m 56s):
I think it's a good place to actually ask sort of the big question that people might have is how do we know every aspect of this that you describe as safe

3 (2h 51m 6s):
At the end of the day, the gold standard is to look at the tissue, you know, what sort of trauma did you cause the tissue? And does that correlate to whatever behavioral anomalies that you may have seen? And that's the language to which we, we can communicate about the safety of, you know, inserting something into the brain and what type of trauma that you can cause. So we actually have an entire department, department of pathology that looks at these tissue slices. There are many steps that are involved in, in doing this. Once you have, you know, studies that are launched to, with, with particular endpoints in mind, you know, at some point you have to euthanize the animal and then you go through necropsy to kind of collect the brain tissue samples.

3 (2h 51m 56s):
You know, you fix them in formin and you like gross them, you section them and you look at individual slices just to see what kind of reaction or lack thereof exists. So that's the kind of the language to which FDA speaks and you know, as well for us to kind of evaluate the safety of the insertion mechanism as well as the threats at various different time points. You know, both acute, so anywhere between, you know, zero to three months to beyond three months. So

0 (2h 52m 25s):
Those are kind of the, the details of an extremely high standard of safety that has to be reached. Correct. FDA supervises this, but this in general just a very high standard and every aspect of this, including the surgery, I think Matthew, MacDougall has mentioned that like the standard is, let's say how to put it politely higher than maybe some other operations that we take for granted. So the, the, the standard for all the surgical stuff here is extremely high, very

3 (2h 52m 58s):
High. I mean it's a highly, highly regulated environment with, you know, the governing agencies that scrutinize every, every medical device that gets marketed. And I think, I think it's a good thing, you know, it's good to have those high standards and we, we try to hold extremely high standards to kind of understand what sort of damage, if any, these innovative emerging technologies and new technologies that we're building are. And you know, so far I i we have been extremely impressed by lack of immune response from these threads.

0 (2h 53m 34s):
Speaking of which you, you talk to me with excitement about the histology and some of the images that you're able to share. Can you explain to me what we're looking at?

3 (2h 53m 46s):
Yeah, so what you're looking at is a stained tissue image. So this is a sectioned tissue slice from an animal that was implanted for seven months. So kind of a chronic time point. And you're seeing all these different colors and each color indicates specific types of cell types. So purple and pink are astrocytes and microglia respectably, they're types of glial cells. And yet the, the other thing that you know, people may not be aware of is your brain is not just made up of soup of neurons and axons. There are other, you know, cells like glial cells that actually kind of is the glue and also react if, if there are any trauma or damage to the tissue with the

0 (2h 54m 32s):
Brown or the neurons here,

3 (2h 54m 34s):
The brown are the neurons, the modern neurons nucle. So, so what you're seeing is in, in this kind of macro image, you're seeing these like circle highlighted in white the insertion sites. And when you zoom into one of those, you see the threads. And then in this particular case, I think we're seeing about the 16, you know, wires that are going into the page. And the incredible thing here is the fact that you have the neurons that are these brown structures or brown circular or elliptical thing that are actually touching and abutting the threads. So what this is saying is that there's basically zero trauma that's caused during this insertion. And with these neural interfaces, these micro electrodes that you insert, that is one of the most common mode of failure.

3 (2h 55m 20s):
So when you insert these threads like the UTA array, it causes neuronal death around the site because you're inserting a foreign object, right? And that kind of elicit these like immune response through microglia and astrocytes, they form this like protective layer around it. Oh, not only are you killing the neuron cells, but you're also creating this productive layer that then basically prevents you from recording neural signals. 'cause 'cause you're getting further and further away from the neurons that you're trying to record And. that that is the biggest mode of failure. And in this particular example in that inside it's, you know, it's about 50 micron with that scale bar, the neurons are just seem to be attracted to it.

0 (2h 55m 59s):
And so there's certainly no trauma. That's such a beautiful image by the way. Just the, so the browner the neurons for some reason I can't look away. It's

3 (2h 56m 8s):
Really cool. Yeah. And and and and the way that these things like, I mean your tissues generally don't have these beautiful colors. This is multiplex stain that uses these different proteins that are staining these at different colors. You know, we use very standard set of, you know, staining techniques with he EBA one and you know, new N and and gfap. So if you go to the next image, this is also kind of illustrates the second point 'cause you can make an argument and initially when we saw the, the previous image we said, oh like are the threads just floating? Like what is happening here? Like are we actually looking at the right thing? So what we did is we did another stain and this is all done in-house of this batons trireme stain, which is in blue that shows these collagen layer.

3 (2h 56m 53s):
So the blue basically like you don't want the blue around the, the implant threads 'cause that means that there's some sort of scarring that's happen. And what you're seeing if you look at individual threads is that you don't see any of the blue, which means that there has been absolutely, or very, very minimal to a point where it's not detectable amount of trauma in these inserted threads.

0 (2h 57m 16s):
So that presumably is one of the big benefits of having this kind of flexible thread. This,

3 (2h 57m 21s):
Yeah, so we think this is primarily due to the size as well as the flexibility of the threads. Also the fact that R one is avoiding, that's ture, so we're not disrupting or we're not causing damage to the vessels and not breaking any of the blood brain barrier has, you know, basically caused the immune response to be muted.

0 (2h 57m 45s):
But this is also a nice illustration of the size of things. So this is the tip of the thread.

3 (2h 57m 51s):
Yeah, those are neurons. They're,

0 (2h 57m 53s):
They're and they're neurons and they're, and this is the thread listening and the electrodes are positioned how,

3 (2h 57m 59s):
Yeah. So this is what you're looking at is not electrode themselves. Those are the conductive wires. So each of those should probably be two micron in width. So what we're looking at is we're looking at the coronal slice, so we're looking at some slice of the tissue. So as you go deeper, you know, you'll obviously have less and less of the tapering of the, of the thread. But yeah, the, the point basically being that there's just kind of cells around the insert site, which is just an incredible thing to see. I, I've just never seen anything like this.

0 (2h 58m 34s):
How easy and safe is it to remove the implant?

3 (2h 58m 37s):
Yeah, so it depends on when, in the first three months or so after the surgery there, there's a lot of kind of tissue modeling that's happening. You know, similar to when you got a cut, you know, you obviously, you know, start over first couple weeks or depending on the size of the wound, scar tissue forming, right there are these like contractive and then in the end they turn into scab and you can scab it off. The same thing happens in the brain and it's a very dynamic environment. And before the scar tissue or the neo membrane or the, you know, new membrane that forms, it's quite easy to just pull 'em out and there's minimal trauma that's, that's caused during that once the scar tissue forms.

3 (2h 59m 25s):
And you know, with, with Nolan as well, we believe that that's the thing that's currently anchoring the thread. So we haven't seen any more movements since then. So there're they're quite stable. It's, it's, it gets harder to actually completely extract the threads. So our current method for removing the device is cutting the thread, leaving the tissue intact, and then unscrewing and taking the implant out. And that hole is now gonna be plugged with either another Neuralink or just with, you know, kind of a, a peak based, you know, plastic based cap.

0 (3h 0m 6s):
Is it okay to leave the threads in there forever?

3 (3h 0m 9s):
Yeah, we think so. We, we've done studies where, you know, we left them there and one of the biggest concerns that we had is like, do they migrate and do they get to a point where they should not be, we haven't seen that again. Once the scar tissue forms they get anchored in place. And I, I should also say that, you know, when we say Upgrades like it, it's not, we're not just talking in theory here. Like we've actually upgraded many, many times. Most of our monkeys or non-human primates NHP have been upgraded, you know, pager who you saw playing mind pong has the latest version of the device since two years ago and is seemingly very happy and healthy and fat.

0 (3h 0m 51s):
So what's designed for the future, the upgrade procedure? So maybe for Nolan, what, yeah, what, what, what would the upgrade look like? It was essentially what you're mentioning. Is there a way to upgrade sort of the device internally where you take it apart, sort of keep the capsule and upgrade the internals? Yeah,

3 (3h 1m 15s):
So there, there are a couple different things here. So for Nolan, if we were to upgrade, what we would have to do is either cut the threads or, you know, extract the threads depending on kind of, you know, the situation there in terms of how they're anchored or scarred in, if you were to remove them with the dual substitute, you know, you, you have an intact brain So, you can reinsert different threads with the updated implant package. There are a couple different Other ways that we're thinking about the future of what the upgradable system looks like. One is, you know, at the moment we currently remove the dura, this, this kind of thick layer that protects the, the brain, but that actually is the thing that actually proliferates the scar tissue formation.

3 (3h 2m 3s):
So typically general good rule of thumb is you want to leave the, the nature as is and not disrupt it as much. So we're looking at ways to insert the threats through the dura, which comes with different set of challenges such as, you know, it's a pretty thick layer, so how do you actually penetrate that without breaking the needle? So we're looking at different needle design for that as well as the kind of the loop engagement. The other biggest challenges are it's quite opaque, optically and with white light illumination. So how do you avoid still this, this biggest advantage that we have of avoiding vasculature? How do you image through that? How do you actually still mediate that? So there are other imaging techniques that we're looking at to enable that.

3 (3h 2m 46s):
But the goal, the, our hypothesis is that, and based on some of the early evidence that we have doing through the dura insertion will cause minimal scarring that causes them to be much easier to extract over time. And the other thing that we're also looking at, this is gonna be a fundamental change in the implant architecture, is at as a, at the moment it's a monolithic single implant that comes with a thread that's bonded together. So, you can't actually separate the thing out. But, you can imagine having two part implant, you know, bottom part that is the thread that are inserted that has the chips and maybe a radio and some power source. And then you have another implant that has more of the computational heavy load and and the bigger battery.

3 (3h 3m 32s):
And then one can be under the durra, one can be above the durra, like, you know, being the plug for the skull. They can talk to each other. But the thing that you wanna upgrade the computer and not the thread, if you wanna upgrade that you just go in there, you know, remove the screws and then put in the next version. And you know, you're off the, you know, it's a very, very easy surgery too. Like you do a skin incision, slip this in, screw, probably be able to do this in 10 minutes.

0 (3h 3m 55s):
So that would allow you to reuse the thread sort of.

3 (3h 3m 58s):
Correct.

0 (3h 3m 59s):
So I mean, this leads to the natural question of what is the pathway to scaling the increase in the number of threads? Is that a priority? Is that like what's, what's the technical challenge there?

3 (3h 4m 11s):
Yeah. That, that is a priority. So for next versions of the implant, you know, the key metrics that we're looking to improve are number of channels just recording from more and more neurons. You know, we have a pathway to actually go from currently 1000 to hopefully 3000, if not 6,000 by end of this year. Wow. And then end of next year we want to get to, you know, even more 16,000.

0 (3h 4m 36s):
Wow.

3 (3h 4m 36s):
There's a couple limitations to that. One is, you know, obviously being able to photo lithographically, print those wires, as I mentioned, it's two micron and width and, and spacing. Obviously there are chips that are much more advanced than those types of resolution. And we have some of the tools that we have brought in house to be able to do that. So traces will be narrower just so that you have to have more of the wires coming up into the chip chips also cannot linearly consume more energy as you have more and more channels. So there's a lot of innovations in the circuit, you know, and architecture as, as well as the circuit design topology to make them lower power.

3 (3h 5m 17s):
You need to also think about if you have all of these spikes, how do you send that off to the end application? So, you need to think about bandwidth limitation there and potentially innovations and signal processing physically. One of the biggest challenges gonna be the, the, the, the interface. It's always the interface that breaks bonding the stem film mare to the, the electronics. It starts to become very, very highly dense interconnects. So how do you characterize that? There's a lot of innovations in, in kind of the 3D integrations in the recent years that we can take advantage of. One of the biggest challenges that we do have is, you know, forming this hermetic barrier.

3 (3h 5m 58s):
Right? You know that this is an extremely harsh environment that we're in the brain. So how do you protect it from Yeah. Like the brain trying to kill your electronics to also your electronics leaking things that you don't want into the brain. And that forming that hermetic barrier is gonna be a very, very big challenge that we, you know, I think are actually well suited to tackle. How

0 (3h 6m 21s):
Do you test that? Like what's the development environment? Yeah. To simulate that kind of harshness. I

3 (3h 6m 26s):
Understand. Yeah. So this is, this is where the accelerated life tester essentially is a brain in a vat. It literally is a vessel that is made up of, and again, again for all intents and purpose for this particular types of test, your brain is a salt water. And, and you can also put some other set of chemicals like reactive oxygen species that, you know, get at kind of these interfaces and trying to cause a reaction to, to pull it apart. But, you could also increase the rate at which these interfaces are aging by just increasing temperature.

3 (3h 7m 6s):
So every 10 degrees Celsius that you increase, you're basically accelerating time by two x and there's limit as to how, how much temperature you wanna increase. 'cause at some point there's some other non-linear dynamics that causes you to have other nasty gases to form that just is not realistic in an environment. So what we do is we increase in our a LT chamber by 20 degrees Celsius that increases the aging by four, four times. So essentially one day in a LT chamber is four day in calendar year. And, and we look at whether the implants still are intact, including the threats and,

0 (3h 7m 44s):
And operation and all of that

3 (3h 7m 45s):
And operation and all of that. It obviously is not an exact same environment as a brain. 'cause you know, brain has mechanical, you know, other more biological groups that, that attack at it. But, It is a good test environment, testing environment for at least the, the, the enclosure and the strength of the enclosure. And I mean, we've had implants, the current version of the implant that has been in there for, I mean, close to two and a half years, which is equivalent to a decade. And they seem to be fine.

0 (3h 8m 18s):
So it's interesting that the burn, so basically close approximation is warm salt water, hot salt water is a good testing environment. I, yeah, by the way, I'm drinking element, which is basically salt water, which is making me kinda, it doesn't have computational power the way the brain does, but maybe in terms of, and in terms of other characteristics is quite similar. Yeah. And I'm consuming it. Yeah.

3 (3h 8m 45s):
You have to get it in the right pH two

0 (3h 8m 49s):
And then Consciousness will emerge. Yeah, no. Alright.

3 (3h 8m 52s):
By, by the way, the other thing that also is interesting about our enclosure is if, if you look at our implant, it's not your common looking medical implant. That usually is in a, in case in a titanium can, that's laser welded. We use this polymer called P-C-T-F-E, poly choal trichloroethylene, which is actually commonly used in blister packs. So when you have a pill and you try to pop a pill, there's like kind of that plastic membrane. That's what this is. No one's actually ever used this except us. And the reason we wanted to do this is 'cause it's electromagnetically transparent.

3 (3h 9m 32s):
So when we talked about the fascinating electromagnetic inductive charging with titanium can usually if you wanna do something like that, you know you have to have a sapphire window and it's a, it's a very, very tough process to scale.

0 (3h 9m 46s):
So you're doing a lot of iteration here in every aspect of this. The materials, the software, the

3 (3h 9m 50s):
All, the whole, whole shebang.

0 (3h 9m 53s):
So, okay. So, you mentioned scaling. Is it possible to have multiple Neuralink devices as one of the ways of scaling to have multiple Neuralink devices implanted? That's

3 (3h 10m 7s):
The goal. That's the goal. Yeah. We, we've had, we've had, I mean our monkeys have had two neural LINKS, one in each hemisphere. And then we're also looking at, you know, potential of having one in or cortex, one in visual cortex and one in wherever other cortex.

0 (3h 10m 25s):
So focusing on a particular function one Neuralink device. Correct. I mean, I, I wonder if there's some level of customization that can be done on the compute side. So for the motor cortex,

3 (3h 10m 34s):
Absolutely. That, that's the goal. And, and you know, we talk about at Neuralink building a generalized neural interface to the brain and And that, that also is strategically how we're approaching this with, with marketing and also, you know, with, with regulatory, which is, hey look, we have the robot and the robot can access any part of the cortex. Right now we're focused on motor cortex with current version of the N one that's specialized for motor decoding tasks. But also at the end of the day, there's kind of a general compute available there. But, you know, typically if you want to really get down to kind of hyperop optimizing for power and efficiency, you do want, need to get to some specialized function.

3 (3h 11m 20s):
Right. But, you know, what we're saying is that, hey, you know, you, you are now used to this robotic insertion techniques, which, which you know, took many, many years of, you know, showing data and, and conversation with the FDA and also internally convincing ourselves that this is, this is safe. And now the difference is if we go to other parts of the brain, like visual cortex, which we're interested in as our second product, obviously it's a completely different environment. The cortex is laid out very, very differently. You know, it's gonna be more stimulation focus rather than recording just, just kind of creating visual percepts.

3 (3h 11m 60s):
But in the end, we're using the same thin film array technology. We're using the same robot insertion technology, we're using the same, you know, packaging technology now it's where the conversation is focused around what are the differences and what are the implication of those differences in safety and efficacy.

0 (3h 12m 17s):
The way you said second product is, is both hilarious and awesome to me. That product being restoring sight for blind people. So can you speak to stimulating the visual cortex? I mean the, the possibilities there are just incredible to be able to give that gift back to people who don't have sight or even any aspect of that. Can you just speak to the challenges of, there's several challenges here. Oh, many. One of which is like you said, from recording to stimulation, just any aspect of that that you're both excited and see the challenges of.

3 (3h 13m 3s):
Yeah, I, I guess I'll start by saying that we actually have been capable of stimulating through our tenfold mare as well as other electronics for years. You know, we, we have actually demonstrated some of that capabilities for reanimating the limb in the spinal cord. It it, you know, obviously for, for the current EFS study, you know, we've hardware disabled that, so that's, that's something that, you know, we wanted to embark as a separate, separate journey and, and you know, obviously there are many, many different ways to write information into the brain. The way in which we're doing that is through electrical, you know, passing electrical current and, and kind of causing that to really change the local environment so that you can sort of artificially cause kind of the, the neurons to depolarize in, in, in nearby areas.

3 (3h 13m 56s):
For, for vision specifically, you know, the way our visual system works, it, it's both well understood. I mean anything with kind of brain, they're aspects of it that's well understood. But in the end, like we don't really know anything. But the way visual system works is that you have photon hitting your eye and in your eyes, you know, there are these specialized cells called photoreceptor cells that convert the photon energy into electrical signals. And then that get, that then gets projected to your back of your head, your visual cortex. You know, it goes through actually, you know, thalamic system called LGN that then projects it out.

3 (3h 14m 38s):
And then in the visual cortex there's in know visual area one or V one and then there's a bunch of other higher level processing layers like V two, V three. And there there are actually kind of interesting parallels. And when you study the behaviors of these convolutional neural networks, like what the different layers of the network is detecting, you know, first they're detecting like these edges and they're then detecting some more natural curves and then they start to detect like objects, right? Kind of similar thing happens in the brain. And a lot of that has been inspired and also, you know, it's been kinda exciting to see some of the correlations there, But, you know, things like from there where this cognition rise arise and where, where's color encoded?

3 (3h 15m 23s):
There's, there's just not a lot of understanding, fundamental understanding there. So in terms of kind of bringing sight back to those that are blind, there are many different forms of blindness. There's actually million people, 1 million people in the US that are legally blind. You know, that means like certain, like score below in kind of the, the visual tests. I think it's something like if you can see something at 20 feet distance that normal people can see at 200 feet di distance, like you're like if you're worse than that, you're legally blind. So

0 (3h 15m 58s):
For fundamental, that means you can't function effectively. Correct. Using site in the world.

3 (3h 16m 2s):
Yeah. Like to navigate, to navigate your environment and yeah, there are different forms of blindness. There are forms of blindness where there's some degeneration of your retina is photoreceptor cells and, and rest of your visual, you know, processing that I described is intact. And for those types of individuals, you may not need to maybe stick electrodes into the visual cortex. You can actually build retinal prosthetic devices that actually just replaces the function of that retinal cells that are degenerated. And there are many companies that are working on that.

3 (3h 16m 43s):
But that, that's a very small slice. The albeit significance, those smaller slice of folks that are legally blind, you know, if there's any damage along that circuitry, whether it's in the optic nerve or you know, just the LGN circuitry or any, any break in that circuit, that's not gonna work for you. And the source of where you need to actually cause that visual percept to happen. Because your biological mechanism of not doing that is by placing electrodes in the visual cortex in the back of your head. And the way in which this would work is that you would have an external camera, whether it's, you know, something as unsophisticated as a GoPro or you know, some sort of wearable, you know, RayBan type glasses that meta is working on that captures a scene, right?

3 (3h 17m 35s):
And, that scene is then converted to set of electrical impulses or stimulation pulses that you would activate in your visual cortex through these thin film arrays. And by playing some c you know, concerted kind of orchestra of these stimulation patterns, you can create what's called phosphines, which are these kind of white yellowish dots that you can also create by just pressing your eyes. You can actually create those percepts by stimulating in the visual cortex. And the name of the game is really have many of those and have those percepts, be the phosphines be as small as possible so that you can start to tell apart like they're the individual pixels of the, the, of the screen, right?

3 (3h 18m 20s):
So if you have many, many of those, you know, potentially you'll be able to, you know, in, in the long term, be able to actually get naturalistic vision. But in the mid, mid, like short term to maybe midterm, being able to at least be able to have object detection algorithms run on your, on your glasses, the pre-processing units, and then being able to at least see the edges of things So, you don't bump into stuff.

0 (3h 18m 46s):
It's incredible. This is really incredible So you basically would be adding pixels and your brain would start to figure out what those pixels mean. Yeah. And like with, with different kinds of assistant on the signal processing on all fronts. Yeah.

3 (3h 19m 0s):
The, the thing that actually, so a couple things. One is, you know, obviously if you're blind from birth, the way brain works, especially in the early age, neuroplasticity is really nothing other than, you know, kind of your brain and different parts of your brain fighting for the limited territory.

0 (3h 19m 21s):
Yeah.

3 (3h 19m 22s):
And, and I mean very, very quickly you see, you see cases where you know people that are, I mean you also hear about people who are blind that have heightened sense of hearing or some other senses. And the reason for that is 'cause that cortex that's not used just gets taken over by these different parts of the cortex. So for those types of individuals, I mean I guess they're going to have to now map some other parts of their senses into what they call vision. But it's gonna be obviously a very, very different conscious experience before. So, so I think that's a, a interesting caveat. The other thing that also is important to highlight is that we're currently limited by our biology in terms of the, the wavelength that we can see.

3 (3h 20m 8s):
There's a very, very small wavelength that is a visible light wavelength that we can see with our eyes. But when you have an external camera with this BCI system, you're not limited to that. You can have infrared, you can have uv, you can have whatever other spectrum that you want to see. And whether that gets matched to some sort of weird conscious experience, I've no idea. But when I, you know, oftentimes I talk to people about the goal of Neuralink being going beyond the limits of our biology. That's sort of what I mean.

0 (3h 20m 39s):
And if you're able to control the kind of raw signal is that when we use our site, we're getting the photons and there's not much processing on it. If you're being able to control that signal, maybe you can do some kind of processing, maybe you do object detection ahead of time. Yeah. You're doing some kind of pre-processing and there's a lot of possibilities to explore that. So it's not just a, in increasing sort of thermal imaging, that kind of stuff, but it's also just doing some kind of interesting processing. Correct. Yeah,

3 (3h 21m 12s):
I I mean my, my theory of how like visual system works also is that I, I mean there, there's just so many things happening in the world and there's a lot of photons that are going into your eye and it, it's unclear exactly where some of the pre-pro processing steps are happening. But I, I mean I actually think that just, just from a fundamental perspective, there's just so much, the reality that we're in, if it's a reality is so there's so much data and I think humans are just unable to actually like eat enough actually to process all that information. So there's some sort of filtering that does happen, whether that happens in the retina, whether that happens in different layers of the visual cortex.

3 (3h 21m 57s):
Un unclear. But like the analogy that I sometimes think about is, you know, if, if your brain is a CCD camera and the in all of the information in the world is a sun, and when you try to actually look at the sun with the CCD camera, it's just gonna saturate the sensors, right? 'cause it's a enormous amount of energy. So what you, what you do is you end up adding these filters, right? To just kind of narrow the information that's coming to you and being captured. And I think, you know, things like our experiences or our, you know, like drugs like propofol that like anesthetics drug or you know, psychedelics, what they're doing is they're kind of swapping out these filters and putting in new ones or removing older ones and kind of controlling our conscious experience.

0 (3h 22m 50s):
Yeah. Man, not to distract from the topic, but I just took a very high dose of Ayahuasca in the Amazon jungle. So yes, it's a nice way to think about it. You're swapping out different, different experiences and with Neuralink being able to control that primarily at first to I improve function, not for entertainment purposes or enjoyment purposes, but

3 (3h 23m 11s):
Yeah. Giving back lost functions,

0 (3h 23m 13s):
Lost giving back, lost functions. And there, that's, especially when, when the functions completely lost anything is a huge help. Would you implant a Neuralink device in your own brain?

3 (3h 23m 29s):
Absolutely. I mean, maybe not right now, but absolutely.

0 (3h 23m 33s):
What kind of capability once reached you would start getting real curious and almost get a little antsy like, like jealous of people that get as you watch them get implanted?

3 (3h 23m 46s):
Yeah, I mean, I think, I mean even, even with our early participants, if they start to do things that I, I can't do, which I think is in the realm of possibility for them to be able to get, you know, 15, 20 if, if not like a hundred BPS right? There's nothing that fundamentally stops us from being able to achieve that type of performance. I, I mean, I would certainly get jealous that they can do that.

0 (3h 24m 13s):
I, I should say that watching Nolan I get a little jealous 'cause he's having so much fun and it seems like such a chill way to play video games. Yeah.

3 (3h 24m 21s):
So I, I mean the thing that also is hard to appreciate sometimes is that, you know, he's doing these things while multi, like while talking and talking. I mean, it's multitasking, right? So it's, it's clearly, it's obviously cognitive cognitively intensive, but similar to how, you know, when we talk, we move our hands. Like these things like, you know, you like are multitasking. I mean, he's able to do that and you know, you won't be able to do that with other assistive technology as far as I I'm I'm aware, you know, if you're obviously using like an eye tracking device, you know, you're very much fixated on that thing that you're trying to do. And if you're using voice control, I mean, like if you say some other stuff, yeah.

3 (3h 25m 1s):
You don't get to use that.

0 (3h 25m 2s):
Yeah. The, the multitasking aspect of that is really interesting. So it's not just the BPS for the primary task, it's the, it's the parallelization of multiple tasks. If you, if you take, if you measure the bps for the entirety of the human organism, so if you're talking and doing a thing with your mind and looking around also, but I mean, there's just a lot of paralyzation that can, that can be happening.

3 (3h 25m 28s):
Yeah. But I mean, I think at some point for him, like if he wants to really achieve those high level BPS, it does require like, you know, full attention. Right? And that's a separate circuitry that that is a big mystery. Like how attention works and you know

0 (3h 25m 41s):
Yeah. Attention, like cognitive load. I've done, I've, I've read a lot of literature on people doing two tasks. Like you have your primary task and a secondary task. And the secondary task is, is a source of distraction and how does that affect the performance of the primary task? And there's, depending on the tasks, there's a lot of interesting, I mean this is an interesting computational device, right? And I think there's, to say the

3 (3h 26m 4s):
Least,

0 (3h 26m 5s):
A lot of novel insights that can be gained from everything. I'm, I mean, I personally am surprised that no one's able to do such incredible control of the cursor while talking and also being nervous at the same time. 'cause he's talking like all of us are, if you're talking in front of the camera, you get nervous. So all of those are coming into play and he's able to still achieve high performance. Surprising. I mean, all of this is really amazing and I think after, just after researching this really in depth, I kind of want it your like, I kind

3 (3h 26m 38s):
Get in the line

0 (3h 26m 40s):
And also the safety get in line. Well we should say the registry is for people who have quadriplegia and correct all that kind of stuff. So Correct. That'll be a separate line for people. They're just curious like myself. So now that Nolan patient P one is part of the ongoing prime study, what's the high level vision for P two, P three, P four, P five, and just the expansion into other human beings that are getting to experience this implant?

3 (3h 27m 15s):
Yeah, I mean the primary goal is, you know, for, for our study in the first place is to achieve safety endpoints. Just understand safety of this device as well as the implantation process. And also at the same time understand the efficacy and the impact that it could have on the potential users' lives. And

0 (3h 27m 41s):
Yeah,

3 (3h 27m 42s):
Just because you have an, you know, you're living with Tetraplegia, it doesn't mean your situation is same as another person living with Tetraplegia. It's wildly, wildly varying and, and, you know, you're, it's something that, you know, we're hoping to also understand how our technology can serve not just a very small slice of those individuals But, you know, broader group of individuals and being able to get the feedback to, you know, just really build the, just the best product for them. So our, our, you know, there's, there's obviously also, you know, goals that we have and, and the primary purpose of the early feasibility study is to learn from each and every participant to improve the device, improve the surgery before, you know, we embark on what's called a pivotal study that then is much larger trial that starts to look at statistical significance of your endpoints and that's required before you can then market the device and, and, and, you know, that's how it works in the US and just generally around the world.

3 (3h 28m 48s):
That's, that's the process You follow So, you know, our, our goal is to really just understand from people like Nolan, P two, P three future participants, what aspects of our device needs to improve. You know, if, if it turns out that people are like, I really don't like the fact that it lasts only six hours, I want to be able to use this computer for, you know, like 24 hours. I mean that's, that is a, you know, user needs and user requirements, which we can only find out from just, just being able to engage with them.

0 (3h 29m 17s):
So before the pivotal study, there's kind of like a rapid innovation based on individual experiences you're learning from individual people, how they use it, like the, like the high resolution details in terms of like cursor control and signal and all that kind of stuff to like life experience. Yeah. Yeah. So

3 (3h 29m 34s):
There's hardware changes, but also just, just firmware updates. So even, even when we, you know, had had that sort of recovery event for Nolan, you know, he now has the new firmware that, that he has been updated with and you know, similar to how like your phones get updated all the time with new firmware for security patches, whatever, new functionality ui, right? And that's something that is possible with our implant. It's not a static one-time device that, that can only do the thing that it said it can do. I mean, it's similar to Tesla. You can do over the air firmware updates, And, now you have completely new u user use, user interface and all this bells and whistles and improvements on, you know, everything like the latest, right?

3 (3h 30m 18s):
That's, that's, that's, you know, when we say generalized platform, that's what we're talking

0 (3h 30m 22s):
About. Yeah, it's really cool how the, the app the Nolan is using, there's like Calibration, all that, all that kind of stuff. And then there's update. You just, you just click and get an update. What other Future capabilities are, are you kind of looking to, you said vision, that's a fascinating one. What about sort of accelerated typing or speech, this kind of stuff? Yeah. What and what else is there? What's Yeah,

3 (3h 30m 50s):
Those, those are still in the well realm of movement program. So it's largely speaking, we have two programs. We have the movement program and we have the, the vision program. The movement program, you know, currently is focused around, you know, the digital freedom as you can easily guess. If you can control, you know, 2D cursor in the digital space, you could move anything in the physical space. So robotic arms, wheelchair, your environment, or even really like, whether it's through the phone or just like directly to those interfaces, so like to those machines. So we're looking at ways to kind of expand those types of capability. Even for Nolan, that requires, you know, conversation with the FDA and kind of showing safety data for, you know, if there's a robotic arm or a wheelchair that, you know, we can guarantee that they're not gonna hurt themselves accidentally, right?

3 (3h 31m 39s):
It's very different if you're moving stuff in the, in the digital domain versus like in the physical space, you can actually potentially cause harm to the participants. So we're working through that right now. Speech does involve different areas of the brain. Speech prosthetic is very, very fascinating. And there's actually been a lot of really amazing work that's been happening in academia. You know, Sergei KY at uc, Davis, Jamie Henderson and you know, late Krish Chennai at Stanford doing just some incredible amount of work in improving speech neuroprosthetics. And it, those are actually looking more at parts of the mortal cortex that are controlling, you know, these focal articulators.

3 (3h 32m 24s):
And, you know, being able to, like, even by mouthing the word or imagine speech, you can pick up those signals. The more sophisticated higher level processing areas like, you know, the brokerage area or you know, Warnick area. Those are still very, very big mystery in terms of the, the underlying mechanism of how all that stuff works. But yeah, I mean, I think, I think Neuralink event goal is to kind of understand those, those things and, and be able to provide a platform and tools to be able to understand that and study that.

0 (3h 32m 58s):
This is where I get to the pothead questions. Do you think we can start getting insight into things like thought, so speech is, there's a muscular component, like you said, there's like the act of producing sounds, but then what about the internal things like cognition, like low level thoughts and high level thoughts. Do you think we'll start noticing kind of signals that could be picked up that could, they could be understood, that could be maybe used in order to interact with the outside world

3 (3h 33m 36s):
In some ways? Like I, I guess this starts to kind of get into the heart problem of Consciousness. And I mean, on, on one hand, all of these are at some point set of electrical signals that from there maybe it, it, it in itself is giving you the cognition or the meaning or somehow human mind is a incredibly amazing storytelling machine. So we're telling ourselves and fooling ourselves that there's some interesting meaning here. But I, I mean, I I, I certainly think that PCI and you know, really PCI at the end of the day is a set of tools that help you kind of study the underlying mechanisms in, in a, both like local but also broader sense and whether, you know, there's some interesting patterns of like electrical signal that means like you're thinking this versus, and you can either like learn from like many, many sets of data to correlate some of that and be able to do mind reading or not.

3 (3h 34m 45s):
I'm not, I'm not sure. I certainly would not kind of rule that out as a possibility, but I I, I think BCI alone probably can't do that. There's probably additional set of tools and framework and, and also like just heart problem of Consciousness at the end of the day is rooted in this philosophical question of like, what is the, what's the meaning of it all? What's the nature of our existence? Like, where's the mind emerge from this complex network? Like

0 (3h 35m 13s):
Yeah. How does the, how does the subjective experience emerge from just a bunch of spikes, electrical spikes? Yeah,

3 (3h 35m 22s):
Yeah. I mean we, we do really think about BCI and what we're building as a tool for understanding the mind, the brain. The only question that matters. There's actually, there, there actually is some biological existence proof of like what it would take to kind of start to form some of these experiences that may be unique. If you actually look at every one of our brains there, there are two hemispheres. There's a left sided brain, there's a right sided brain. And I mean, I un unless you have some other conditions, you normally don't feel like left legs or right legs, like you just feel like one legs, right?

3 (3h 36m 7s):
So what is happening there, right? If you actually look at the two hemispheres, there's a, a structure that kind of characterize the two called the corpus callosum that is supposed to have around 200 to 300 million connections or axons. So whether that means that's the, the number of interface and electrodes that we need to create some sort of mind meld or from that like whatever new conscious experience that you, you can experience. But yeah, I I do think that there's like kind of an interesting existence proof that we all have

0 (3h 36m 52s):
And that threshold is unknown at this time.

3 (3h 36m 55s):
Oh yeah. These things, everything in this domain is, you know, speculation, right?

0 (3h 37m 0s):
And then there will be, you'd be continuously pleasantly surprised. Do you see a world where there's millions of people, like tens of millions, hundreds of millions of people walking around with a Neuralink device in their, or multiple Neuralink devices in their brain?

3 (3h 37m 21s):
I do, first of all, there, there are, like if you look at worldwide people suffering from movement disorders and visual tesis, I mean that that's in the tens if not hundreds of millions of people. So that, that alone, I think there's a lot of benefit and, and potential good that we can do with this type of technology. And when you start to get into kind of neuro like, psychiatric application, you know, depression, anxiety, hunger or you know, obesity, right? Like mood control of, of appetite. I mean, that starts to become, you know, very real to everyone.

0 (3h 38m 6s):
Not to mention that every, most people on earth have a smartphone. And once BCI starts competing with a smartphone as a preferred methodology of interacting with the digital world, that also becomes an interesting thing.

3 (3h 38m 24s):
Oh yeah, I mean that, yeah, this is even before going to that, right? I mean, there's like almost, I mean, the entire world that could benefit from these types of thing. And then, you know, like if we're talking about kind of next generation of how we interface with, you know, machines or even ourselves in many ways, I think BCI can play a role in that. And, you know, some of the things that I also talk about is I, I, I do think that there is a real possibility that you could see, you know, 8 billion people walking around with Neuralink.

0 (3h 38m 59s):
Well, thank you so much for pushing ahead and I look forward to that exciting future. Thanks

3 (3h 39m 4s):
For having me.

0 (3h 39m 6s):
Thanks for listening to this conversation with DJ SA And. now, dear friends, here's Matthew MacDougall, the head neurosurgeon at Neuralink. When did you first become fascinated with the human brain?

5 (3h 39m 21s):
Since forever. As far back as I can remember, I've been interested in the human brain. I mean, I was, you know, a thoughtful kid and a bit of an outsider and you, you know, sit there thinking about what the most important things in the world are in your, in your little tiny adolescent brain. And the answer that I came to, that I converged on was that all of the things you can possibly conceive of as things that are important for human beings to care about are literally contained, you know, in the skull. Both the perception of them and their relative values.

5 (3h 40m 4s):
And, you know, the solutions to all our problems and all of our problems are all contained in the skull. And if we knew more about how that worked, How the brain encodes information and generates desires and generates agony and suffering, we we could do more about it. You know, you think about all the, all the really great triumphs in human history. You think about all the really horrific tragedies. You know, you think about the Holocaust, you think about any prison full of human stories and all of those problems down to neurochemistry.

5 (3h 40m 51s):
So if you get a little bit of control over that, you provide people the option to do better. And in the way I read history, the way people have dealt with having better tools is that they most often in the end do better with huge asterisk. But I think it's a, an interesting, a worthy and noble pursuit to give people more options, more tools.

0 (3h 41m 16s):
Yeah, that's a fascinating way to look at human history. You just imagine all these neurobiological mechanisms, Stalin, Hitler, all of these Jenka Khan, all of them just had like a, a brain, it just a bunch of neurons, you know, like a few tons of billions of neurons gaining a bunch of information over a period of time. They have a set of modules that does language and memory and all that. And from there in, in the, in the case of those people, they're able to murder millions of people. Yeah. And yeah, all that coming from, there's not some glorified notion of a, a dictator of this enormous mind or something like this.

0 (3h 41m 57s):
It's just, it's just the brain. Yeah.

5 (3h 42m 0s):
Yeah. I mean a lot of that has to do with how well people like that can organize those around them

0 (3h 42m 8s):
Other brains.

5 (3h 42m 9s):
Yeah. And so I always find it interesting to look to primatology, you know, look to our closest non-human relatives for clues as to how humans are going to behave and, and what particular humans are able to achieve. And So, you look at chimpanzees and bonobos and, you know, they're similar but different in their social structures particularly. And I went to Emory in Atlanta and studied under friends Dal, the great friends Dal, who was kind of the leading primatologist who recently died and his work in at looking at chimps through the lens of, you know, how you would watch an episode of friends and understand the motivations of the characters interacting with each other.

5 (3h 42m 59s):
He would look at a chimp colony and basically apply that lens. I'm massively oversimplifying it. If you do that, instead of just saying, you know, subject 4, 7 3, you know, through his feces at subject 4, 7 1, you talk about them in terms of their human struggles, accord them, the dignity of themselves as actors with understandable goals and drives what they want out of life. And primarily it's, you know, the things we want out of life, food, sex, companionship, power. You can understand chimp and bonobo behavior in the same lights much more easily.

5 (3h 43m 45s):
And I think doing so gives you the tools you need to reduce human behavior from the kind of false complexity that we layer onto it with language and look at it in terms of, oh, well these humans are looking for companionship, sex, food, power. And I think that that's a pretty powerful tool to have in understanding human behavior.

0 (3h 44m 11s):
And I just went to the Amazon jungle for a few weeks and you, it's a very visceral reminder that a lot of life on earth is just trying to get laid. Yeah. They're all screaming at each other. Yeah. Like I saw a lot of monkeys and they're just trying to impress each other or maybe if there's a battle for power, but a lot of the battle for power has to do with them getting laid,

5 (3h 44m 33s):
Right. Breeding rights often go with alpha status. And so if you can get a piece of that, then you're gonna do okay and

0 (3h 44m 41s):
Would like to think that we're somehow fundamentally different. But especially when it talk, it comes to primates where we really aren't, you know, we can use fan poetic language, but maybe some of the underlying drives that motivate us are similar. Yeah,

5 (3h 44m 58s):
I think that's true.

0 (3h 44m 59s):
And all of that is coming from this, the brain. Yeah. So when, when did you first start studying the, the brain as like as a biological mechanism?

5 (3h 45m 7s):
Basically, the moment I got to college, I started looking around for labs that I could do Neuroscience work in. I originally approached that from the angle of looking at interactions between the brain and the immune system, which isn't the most obvious place to start, but I had this idea at the time that the contents of your thoughts would have an impact, a direct impact, maybe a powerful one on non-conscious systems in your body. The systems we think of as, you know, homeostatic automatic mechanisms like fighting off a virus, like repairing a wound.

5 (3h 45m 52s):
And sure enough, there are big crossovers between the two. I mean, it gets to kind of a key point that I think goes under recognized. One of the things people don't recognize or or appreciate about the human brain enough And that is that it basically controls or has a huge role in almost everything that your body does. Like you try to try to name an example of something in your body that isn't directly controlled or massively influenced by the brain. And it, it's pretty hard. I mean, you might say like bone healing or something. But even those systems, the hypothalamus and pituitary end up playing a role in coordinating the endocrine system that does have a direct influence on say, the calcium level in your blood that goes to bone healing.

5 (3h 46m 45s):
So non-obvious connections between those things implicate the brain as really a potent prime mover in all of health.

0 (3h 46m 56s):
One of the things I realized in the other direction too, how most of the systems in the body integrated with the human brain, like they affect the brain also like the immune system. I think there's just, you know, people who study Alzheimer's and those kinds of things. It, it's just surprising how much you can understand of that from the immune system, from the other systems that don't obviously seem to have anything to do with sort of the nervous system they all play together.

5 (3h 47m 28s):
Yeah. You could understand how that would be driven by evolution too. Just in some simple examples, if you get sick, if you get a communicable disease, you get the flu, it's pretty advantageous for your immune system to tell your brain, Hey, now be antisocial for, you know, a few days. Don't go be the life of the party tonight. In fact, maybe just cuddle up somewhere, warm under a blanket and just stay there for a day or two. And sure enough, that tends to be the behavior that you see both in animals and, and in humans. If you get sick, elevated levels of interleukins in your blood and TNF alpha in your blood, ask the brain to cut back on social activity.

5 (3h 48m 14s):
And even moving around, you have lower locomotor activity in animals that are infected with viruses.

0 (3h 48m 25s):
So from there, the early days in Neuroscience to surgery, when did that step happen? Yeah, this a leap,

5 (3h 48m 35s):
You know, it was sort of an evolution of thought. I wanted to study the brain. I started studying the brain in undergrad in this neuro immunology lab. I, from there realized at some point that I didn't want to just generate knowledge. I wanted to affect real changes in the actual world, in actual people's lives. And so after having not really thought about going into medical school, I was on a track to go into a PhD program. I said, well, I'd like, I'd like that option. I'd like to actually potentially help tangible people in front of me.

5 (3h 49m 19s):
And doing a little digging found that there exists these MD PhD programs where you can choose not to choose between them and do both. And so I went to USC for medical school and had a joint PhD program with Caltech, where I met, actually chose that program particularly because of a researcher at Caltech named Richard Anderson, who's one of the godfathers of primate. Neuroscience has a, a maca lab where Utah Rays and other electrodes were being inserted into the brains of monkeys to try to understand how intentions were being encoded in the brain.

5 (3h 50m 4s):
So, you know, I ended up there with the idea that maybe I would be a neurologist and study the brain on the side, and then discovered that neurology, again, I'm gonna make enemies by saying this, but neurology predominantly. And, and distressingly to me is, is the practice of diagnosing a thing and then saying good luck with that when there's not much we can do. And Neurosurgery very differently is a, it's a powerful lever on taking people that are headed in a bad direction and changing their course in the sense of brain tumors that are potentially treatable or curable with surgery.

5 (3h 50m 50s):
You know, even aneurysms in the brain, blood vessels that are gonna rupture you can save lives really is at the end of the day, what ma what mattered to me. And so I was at USC, as I mentioned, that happens to be one of the great Neurosurgery programs. And so I met these truly epic neurosurgeons, Alex Lesi and, and Micah Pazo and Steve Giata and Marty Weiss, these, these sort of epic people that were just human beings in front of me. And so it kind of changed my thinking from neurosurgeons are distant gods that live on another planet and occasionally come and visit us to these are humans that have problems and are people, and there's nothing fundamentally preventing me from being one of them.

5 (3h 51m 41s):
And so at the last minute in medical school, I changed gears from going into a different specialty and, and switched into Neurosurgery, which cost me a, a year. I had to do another year of research because I was so far along in the process that to switch into Neurosurgery, the deadlines had already passed. So it was a, a decision that cost time, but absolutely worth it.

0 (3h 52m 9s):
What was the hardest part of the training on the, on the neurosurgeon track?

5 (3h 52m 14s):
Yeah, two things. I think that, you know, residency in Neurosurgery is sort of a competition of pain of, of like how much pain can you eat and smile. Yeah. And so there's workout restrictions that are not really, they're viewed at, I think internally among the residents as weakness. And so most Neurosurgery residents try to work as hard as they can And that I think necessarily means working long hours and sometimes over the work hour limits. And, you know, we care about being compliant with whatever regulations are in front of us.

5 (3h 52m 55s):
But I think more important than that, people want to give all, give their all in becoming a better neurosurgeon because the, the stakes are so high and so it's a real fight to get residents to say, go home at the end of their shift and not stay and do more surgery.

0 (3h 53m 12s):
Are you seriously saying like, one of the hardest things is literally like getting, forcing them to get sleep and rest and all this kind of stuff?

5 (3h 53m 21s):
Historically that was the case. I think, I think the next, next generation And that's, I think the next generation is more compliant and more selfcare.

0 (3h 53m 30s):
We is what you mean. All right. I'm just, I'm just kidding. I'm just kidding.

5 (3h 53m 32s):
I didn't say it

0 (3h 53m 33s):
Now I'm making enemies. Okay, I get it. Wow. That's fascinating. So what was the second thing?

5 (3h 53m 39s):
The personalities, and maybe the two are connected,

0 (3h 53m 42s):
But so is, was it pretty competitive?

5 (3h 53m 45s):
It's competitive and it's also, you know, as we touched on earlier, primates like power and I think Neurosurgery has long had this aura of mystique and excellence and whatever about it. And so it's, it's an invitation I think for people that are cloaked in that authority. You know, a board certified neurosurgeon is basically a walking fallacious appeal to authority, right. You, you have license to walk into any room and act like you're, you know, an expert on whatever. And fighting that tendency is not something that most neurosurgeons do.

5 (3h 54m 26s):
Well, humility isn't the forte.

0 (3h 54m 28s):
Yeah. One of the, so I have friends who know you and whenever they speak about you that you're, you're have the surprising quality for a neurosurgeon of humility, which I think indicates that it's not, it's not as common as perhaps in other professions. 'cause there is a kind of gigantic sort of heroic aspect to Neurosurgery. And I think it gets to people's head a little bit. Yeah,

5 (3h 54m 56s):
Well that, I think that, you know, that allows me to play well at an Elon company because Elon, one of his strengths, I think is to just instantly see through fallacy from authority. Yeah. So nobody walks into a room that he's in and says, well, goddammit, you have to trust me. I'm the guy that built the last, you know, 10 rockets or something. And he says, well, you did it wrong and we can do it better. Or, I'm the guy that, you know, kept Ford alive for the last 50 years. You listen to me on how to build cars. And he says, no. And So, you don't walk into a room that he's in and say, well, I'm a neurosurgeon, let me tell you how to do it.

5 (3h 55m 40s):
He's gonna say, well, I'm a human being that has a brain. I can think from first principles myself, thank you very much and here's how I think it ought to be done. Let's go try it and see who's right. And that's, you know, proven I think over and over in his case to be a very powerful approach.

0 (3h 55m 57s):
If we just take that tangent, there's a fascinating interdisciplinary team at Neuralink that you get to interact with, including Elon. What do you think is the secret to a successful team? What have you learned from just getting to observe these folks?

5 (3h 56m 16s):
Yeah.

0 (3h 56m 17s):
World experts in different disciplines work together.

5 (3h 56m 21s):
Yeah. There there's a sweet spot where people disagree and forcefully speak their mind and passionately defend their position, and yet are still able to accept information from others and change their ideas when they're wrong. And so I like the analogy of sort of how you polish rocks. You put hard things in a, in a hard container and spin it and people bash against each other and outcomes, you know, a more refined product. And so to make a good team at Neuralink, we've tried to find, you know, people that are not afraid to defend their ideas passionately.

5 (3h 57m 7s):
And, you know, occasionally strongly disagree with people that they're, that they're working with. And have I the best idea come out on top? It's not an easy balance, again, to refer back to the primate brain. It's not something that is inherently built into the, the primate brain to say, I passionately put all my chips on this position, And now I'm just gonna walk away from it. Admit you were right. You know, part of our brains tell us that that is a power loss, that is a loss of face, a loss of standing in the community and, and And now you're a, a zeta chump 'cause your idea got trounced and you just have to, you know, recognize that that little voice in the back of your head is maladaptive and it's not helping the team win.

0 (3h 58m 4s):
Yeah. You have to have the confidence to be able to walk away from an idea that you hold onto. Yeah. Yeah. And if you do that often enough, you're actually going to become the best in the world at your thing. I mean, that kind of, that rapid iteration Yeah.

5 (3h 58m 19s):
You'll at least be a member of a winning team

0 (3h 58m 22s):
Ride the wave. What, what did you learn, you mentioned there's a lot of amazing neurosurgeons at USC. What, what lessons about surgery and life have you learned from those folks?

5 (3h 58m 35s):
Yeah, I think working your ass off, working hard while, you know, functioning as a member of a team, getting a job done that is incredibly difficult. You know, working incredibly long hours, being up all night, taking care of someone that, you know, you think probably won't survive no matter what you do. Working hard to make people that you passionately dislike look good the next morning. These folks were relentless in their pursuit of excellent neurosurgical technique, decade over decade.

5 (3h 59m 16s):
And, and I think we're well recognized for the that excellence. So it's, you know, especially Marty Weiss, Steve Giata, Mike Pazo, they, they made huge contributions not only to surgical technique, but they built training programs that trained dozens or hundreds of amazing neurosurgeons. I was just lucky to kind of be in their wake.

0 (3h 59m 42s):
What's that like you mentioned doing a surgery where the person is likely not to survive. Does that wear on you?

5 (3h 59m 54s):
Yeah, you know, it, it's especially challenging when you, With all respect to, to our elders, it doesn't hit so much when you're taking care of an 80-year-old and something was going to get them pretty soon anyway. And So, you lose a patient like that. And it, it was part of the natural course of what is expected of them in the, in the coming years, regardless, taking care of, you know, a a father of two or three, four young kids, someone in their thirties that didn't have it coming, and they show up in your ER having their first seizure of their life and lo andhold, they've got a, a huge malignant inoperable or incurable brain tumor.

5 (4h 1m 1s):
You, you can only do that I think a handful of times before it really starts eating away at your, at your armor or a, you know, a young mother that shows up that has a giant hemorrhage in her brain that she's not gonna survive from. And you know, they bring her 4-year-old daughter in to, to say goodbye one last time before they turn the ventilator off that, you know, the great Henry Marsh is a English neurosurgeon who said it best, I think he says that every neurosurgeon carries with them a private graveyard. And I definitely feel that, especially with young parents, the, that that kills me.

5 (4h 1m 47s):
They, they had a lot more to give the, the loss of those people specifically has a, you know, knock on effect that's going to make the world worse for people for a long time. And it's just hard to feel powerless in the face of that, you know, and that's where I think you have to be borderline evil to fight against a company like Neuralink or to constantly be taking pot shots at us because what we're doing is to try to fix that stuff.

5 (4h 2m 27s):
We're trying to give people options to reduce suffering. We're trying to, we're trying to take the, the pain out of life that broken brains brings in and yeah, this is just our, our little way that we're fighting back against entropy, I guess.

0 (4h 2m 52s):
Yeah. That's the, the amount of suffering that's endured when some of the things that we take for granted that our brain is able to do is taken away, is immense. And to be able to restore some of that functionality is a real gift.

5 (4h 3m 6s):
Yeah. We're just starting, we're we're gonna, we're gonna do so much more.

0 (4h 3m 12s):
Well, can you take me through the full procedure of implanting, say the N one Sure. Chip and your link.

5 (4h 3m 19s):
Yeah. It's a really simple, really simple, straightforward procedure. The, the human part of the surgery that, that I do is dead simple. It's one of the most basic Neurosurgery procedures imaginable. And I think there's evidence that it, some version of it has been done for thousands of years. That there are examples I think from ancient Egypt of healed or partially healed tre nations and from Peru or, you know, ancient times in South America where these proto surgeons would drill holes in people's skulls, you know, presumably to let out the evil spirits, but maybe to drain blood clots.

5 (4h 4m 4s):
And there's evidence of bone healing around the edge, meaning the people at least survive some months after a procedure. And so what we're doing is that we are making a cut in the skin on the top of the head over the area of the brain that is the most potent representation of hand intentions. And so if you, if you are an expert concert pianist, you know, this part of your brain is lighting up the entire time you're playing. We call it the hand knob. The

0 (4h 4m 37s):
Hand knob, yeah. So it's all the, like the finger movements, all this all yeah. All of that is just firing away.

5 (4h 4m 43s):
Yep. There's a little squiggle in the cortex right there. One of the folds in the brain is kind of doubly folded right on that spot. And So, you can look at it on an MRI and say, that's the hand knob. And then you, you do a functional test and a special kind of MRI called an a functional M-R-I-F-M-R-I. And this part of the brain lights up when people, even quadriplegic people whose brains aren't connected to their finger movements anymore. They imagine finger movements and this part of the brain still lights up. So we can id that part of the brain in anyone who's preparing to enter our trial and say, okay, that, that part of the brain we confirm is your hand intention area.

5 (4h 5m 28s):
And so I'll make a little cut in the skin, we'll flap the skin open, just like kind of opening the hood of a car only a lot smaller. Make a perfectly round one inch diameter hole in the skull, remove that bit of skull open the lining of the brain, the covering of the brain. It's like a, like a little bag of water that the brain floats in. And then show that part of the brain to our robot. And then the, this is where the robot shines. It can come in and take these tiny, you know, much smaller than human hair electrodes and precisely insert them into the cortex, into the surface of the brain to a very precise depth, in a very precise spot that avoids all the blood vessels that are coating the surface of the brain.

5 (4h 6m 22s):
And after the robot's done with its part, then you know, the human comes back in and puts the implant into that hole in the skull and covers it up, screwing it down to the skull and sewing the skin back together. So the whole thing is, you know, a few hours long, it's extremely low risk compared to the average Neurosurgery involving the brain that that might say open up a deep part of the brain or manipulate blood vessels in the brain. This, this opening on the surface of the brain with, with only cortical micro insertions, carries significantly less risk than a, a lot of the, you know, tumor or aneurysm surgeries that are routinely done.

0 (4h 7m 11s):
So cortical micro insertions that are via robot and computer vision are designed to avoid the blood vessels.

5 (4h 7m 18s):
Exactly.

0 (4h 7m 19s):
So I know you're a bit biased here, but let's compare human and machine. Sure. So what are human surgeons able to do well and what are robot surgeons able to do well at this stage of our human civilization development?

5 (4h 7m 37s):
Yeah. Yeah, that's a good question. Humans are general purpose machines. We're able to adapt to unusual situations. We're able to change the plan on the fly. I remember, well, a surgery that I was doing many years ago down in San Diego, where the plan was to open a small hole behind the ear and go reposition a blood vessel that had come to lay on the facial nerve, the trigeminal nerve, the nerve that goes to the face when that blood vessel lays on the nerve, it can cause just intolerable, horrific shooting pain that people describe, like being zapped with a cattle prod.

5 (4h 8m 25s):
And so the beautiful, elegant surgery is to go move this blood vessel off the, off the nerve. The surgery team. We, we went in there and started moving this blood vessel and then found that there was a giant aneurysm on that blood vessel that was not easily visible on the pre-OP scans. And so the plan had to dynamically change And that the human surgeons had no problem with that, we're trained for all those things. Robots wouldn't do so well in that situation, at least in their current incarnation, fully robotic surgery, like, you know, the, the electrode insertion portion of, of the lynx surgery. It goes according to a set plan.

5 (4h 9m 6s):
And so the humans can interrupt the flow and change the plan, but the robot can't really change the plan midway through. It operates according to how it was programmed and how it was asked to run. It does its job very precisely, but not with a wide degree of latitude and how to react to changing conditions.

0 (4h 9m 29s):
So there could be just a very large number of ways that you could be surprised as a surgeon when you enter a situation that could be subtle things that you have to dynamically adjust to. Correct. And robots are not good at that

5 (4h 9m 42s):
Currently.

0 (4h 9m 43s):
Currently

5 (4h 9m 44s):
I think we are at the dawn of a new era with AI of the parameters for robot responsiveness to be dramatically broadened. Right. I mean, you can't look at a self-driving car and say that it's operating under very narrow parameters. You know, if a chicken runs across the road, it wasn't necessarily programmed to deal with that. Specifically But It, a Waymo or a self-driving Tesla would have no problem reacting to that appropriately. And so surgical robots aren't there yet, but give it time.

0 (4h 10m 23s):
And then there could be a lot of sort of inter like semi-autonomous possibilities of maybe a robotic surgeon could say, this situation is perfectly familiar, or the situation is not familiar. And in the not familiar case a human could take over, but basically like be very conservative and saying, okay, this for sure has no issues, no surprises, and let the humans deal with the surprises, with the edge cases, all that. Yeah, that's one possibility. So like you think eventually you'll be out of the job? Well, you being neurosurgeon, your job being neurosurgeon, humans, there will not be many neurosurgeons left on this earth.

5 (4h 11m 7s):
I'm not worried about my job in my, in the course of my professional life. I think I, I would tell my my kids not necessarily to go in this line of work depending on, depending on how things look in 20 years.

0 (4h 11m 24s):
It's so fascinating. 'cause I, I mean, I, if I have a line of work, I would say it's programming. And if you ask me like for the last don don't know, 20 years, what I would recommend for people, if I would, I would tell 'em, yeah, go. Like, there's just, you'll always have a job if you're a programmer's, more and more computers and all this kind of stuff, and it pays well, but then you, you realize these large language models come along and they're really damn good at generating code. Yeah. So it's overnight you could be surprised like, wow, like what is the contribution of the human really? But then you start to think, okay, it does seem like humans have ability, like you said, to deal with novel situations. In, in the case of programming, it's the ability to kinda come up with novel ideas to solve problems that it's, it seems like machines aren't quite yet able to do that.

0 (4h 12m 16s):
And when the stakes are very high, when it's life critical as it is in surgery, especially in Neurosurgery, then it starts the, the stakes are very high for a robot to actually replace a human But. It is fascinating that in this case of Neuralink, there's a human robot collaboration. Yeah,

5 (4h 12m 35s):
Yeah. It's, I do the parts I can't do and it does the parts I can't do. And we, we are friends.

0 (4h 12m 45s):
The, I I saw that there's a lot of practice going on. So I mean, everything in Neurolink is, is tested extremely rigorously. But one of the things I saw that there's a proxy on which the surgeries are performed. Yeah. So this is both for the robot and for the human, for everybody involved in the entire pipeline. Yep. What's that like practicing the surgery?

5 (4h 13m 8s):
It's pretty intense. So there's no analog to this in human surgery. Human surgery is sort of this artisanal craft that's handed down directly from master to pupil over the generations. Yes. I mean, literally the way you learn to be a, a, a surgeon on humans is by doing surgery on humans. I mean, first you watch Your professors do a bunch of surgery, and then finally they put, you know, the trivial parts of the surgery into your hands. And then the more complex parts. And as your understanding of the, the point and the purposes of the surgery increases, you get more responsibility in the perfect condition doesn't always go well.

5 (4h 13m 54s):
In Lyn's case, the approach is a bit different. We, of course, practiced as far as we could on animals. We did hundreds of animal surgeries. And when it came time to do the first human, we had a, just a amazing team of engineers build incredibly lifelike models. One of the engineers, Fran Romano in particular built, built a pulsating brain in a custom 3D printed skull that matches exactly the, the patient's anatomy, including their face and scalp characteristics.

5 (4h 14m 35s):
And so when I was able to practice that, I mean, it, it's as close as it really reasonably should get to, to being the real thing and all the details, including, you know, the having a, a mannequin body attached to this custom head. And so when we were doing the practice surgeries, we'd wheel that body into the CT scanner and take a mock CT scan and wheel it back in and conduct all the normal safety checks verbally, you know, stop this patient, we're confirming his identification is mannequin number, blah, blah, blah, and then opening the brain in exactly the right spot using standard operative neuro navigation equipment, standard surgical drills in it, in the same, or that we do all of our practice surgeries in at, at Neuralink.

5 (4h 15m 30s):
And having the skull open and have the brain pulse, which adds a degree of difficulty for the robot to, you know, perfectly precisely plan and insert those electrodes to the right depth and location. And so yeah, we, we kind of broke new ground on how extensively we practiced for this surgery.

0 (4h 15m 53s):
So there was a historic moment, a big milestone for Neuralink in part for humanity with the first human getting a Neuralink implant in January of this year. Take me through the surgery on Noland. What did it feel like to be part of this?

5 (4h 16m 13s):
Yeah, well, we, we are lucky to have just incredible partners at the Barrow Neurologic Institute. They are, I think, the premier neurosurgical hospital in the world. They, they made everything as easy as possible for the trial to get going and, and helped us immensely with their expertise on how to, how to arrange the details. It was a much more high pressure surgery in some ways. I mean, even though the, you know, the outcome wasn't particularly in question in terms of our participant safety, the number of observers, you know, the number of people, there's conference rooms full of people watching live streams in the hospital rooting for this to go perfectly And.

5 (4h 17m 7s):
that just adds pressure. That is not typical for even the most intense production Neurosurgery say, removing a tumor or, you know, placing deep brain stimulation electrodes. And it had never been done on a human before. There were unknown unknowns. And so definitely a, a moderate pucker factor there for the whole team not knowing if we were going to encounter, say, a degree of brain movement that was unanticipated or a degree of brain sag that took the brain far away from the skull and made it difficult to insert or some other unknown unknown problem.

5 (4h 17m 54s):
Fortunately everything went well, And that that surgery was one of the smoothest outcomes we could have imagined.

0 (4h 18m 3s):
Were you nervous? I mean, you're bit extremely quarterback in like in the Super Bowl kind of situation.

5 (4h 18m 8s):
Extremely nervous. Extremely. I was very pleased when it went well and then and when it was over. Looking forward to number two. Yeah.

0 (4h 18m 17s):
Even with all that practice, all of that, just, you've never been in a situation that's so high stakes in terms of people watching. Yeah. And you, we should also probably mention, given how the media works, a lot of people, you know, maybe in a dark kind of way, hoping it doesn't go well.

5 (4h 18m 35s):
Well, I think wealth is easy to hate or envy or, or whatever. And I think there's a whole industry around driving clicks and bad news is great for clicks. And so any way to take an event and turn it into bad news is gonna be really good for, for clicks.

0 (4h 18m 60s):
It just sucks because I think in, it puts pressure on people. It discourages people from, from trying to solve really hard problems. Because to solve hard problems, you have to go into the unknown. You have to do things that haven't been done before and you have to take risks. Yeah. Calculated risks. You have to do all kinds of safety precautions, but risks not nevertheless. And you, I just wish there would be more celebration of that, of the risk taking versus like Yeah. People just waiting on the on, on the sidelines, like waiting for failure Yeah. And then pointing out the failure. Yeah. It sucks. But you, you know, in this case it's, it's, it's really great that everything went just flawlessly, but it's unnecessary pressure.

0 (4h 19m 41s):
I would say

5 (4h 19m 42s):
Now that there's a human with literal skin in the game, you know, there's a participant who, whose wellbeing rides on this doing well. You, you have to be a pretty bad person to be rooting for that to go wrong. Yeah. And So, you know, hopefully people look in the mirror and, and realize that at some point.

0 (4h 20m 2s):
So did you get to actually front row seat, like watch the robot work? Like what? You get to see the whole thing?

5 (4h 20m 8s):
Yeah, I mean I, you know, because an MD needs to be in charge of all of the medical decision making throughout the process, I uns scrubbed from the surgery after exposing the brain and presenting it to the robot and placed the targets on the robot inter software interface that tells the robot where it's going to insert each thread. That was done with, you know, my hand on the mouse for whatever that's worth.

0 (4h 20m 40s):
So, you were the one placing the targets? Yeah. Oh, cool. So like it, you know, the, the, the, the robot with a computer vision provides a bunch of candidates and you kinda finalize the decision, right?

5 (4h 20m 54s):
You know, they, the, the software engineers are amazing on this team. And so they actually provided an interface where you can essentially use a lasso tool and select a, a prime area of brain real estate and it will automatically avoid the blood vessels in that region and automatically place a bunch of targets. So you, you know, that allows, you know, the human robot operator to select really good areas of brain and make dense applications of targets in that, in those regions, the regions we think are gonna have the most high fidelity representations of finger movements and arm movement intentions.

0 (4h 21m 38s):
I've seen like images of this and for me with OCD, it's for some reason a really pleasant, I think there's a subreddit called oddly satisfying. Yeah.

5 (4h 21m 47s):
Love that subreddit.

0 (4h 21m 50s):
It's oddly satisfying to see the different target sites avoiding the blood vessels and also maximizing, it's like the usefulness of those locations for the signal. It just feels good. It's like, ah,

5 (4h 22m 2s):
As a person who has a visceral reaction to the brain bleeding, I can tell you it's yes,

0 (4h 22m 6s):
Especially

5 (4h 22m 7s):
It's extremely satisfying watching the electrodes themselves go into the brain and not cause bleeding.

0 (4h 22m 12s):
Yeah, yeah. So you said the feeling was of relief when everything went perfectly. Yeah. How deep in the brain can you currently go and eventually go, let's say on the Neuralink side? Is it, it seems the deeper you go in the brain, the more challenging it becomes?

5 (4h 22m 34s):
Yeah, so talking broadly about Neurosurgery, we can get anywhere, it's routine for me to put deep brain stimulating electrodes n near the very bottom of the brain, entering from the top and passing about a two millimeter wire all the way into the bottom of the brain. And that's not revolutionary. A lot of people do that. And we can do that with very high precision. I, I use a robot from Globus to do that surgery, you know, several times a month. It's, it's pretty routine.

0 (4h 23m 12s):
What are your eyes in that situation? What, what are you seeing? What's, what kind of technology can you use to visualize where you are to light your way?

5 (4h 23m 21s):
Yeah, so it's a cool process. On the software side. You take a preoperative MRI that's extremely high resolution data of the entire brain. You put the patient to sleep, put their head in a frame that holds the skull very rigidly, and then you take a CT scan of their head while they're asleep with that frame on and then merge the MRI and the CT. In software, you have a, a plan based on the MRI where you can see these nuclei deep in the brain. You can't see them on ct, but if you trust the merging of the two images, then you indirectly know on the CT where that is and therefore indirectly know where in reference to the titanium frame screwed to their head.

5 (4h 24m 10s):
Those targets are. And so this is sixties technology to manually compute trajectories given the entry point and target and dial in some goofy looking titanium actuators with manually a manual actuators with little tick marks on them. The modern version of that is to use a robot, you know, just like a, a little cka arm. You might see it building cars at the Tesla factory. This small robot arm can show you the trajectory that you intended from the pre-op MRI and establish a very rigid holder through which you can drill a small hole in the skull and pass a small rigid wire deep into that area of the brain that's hollow and put your electrode through that hollow wire and then remove all of that except the electrode So.

5 (4h 25m 6s):
you end up with the electrode very, very precisely placed far from the skull surface. Now that's standard technology that's already, you know, been out in the world for, for a while. Neuralink right now is focused entirely on cortical targets, surface targets because there's no trivial way to get, say, hundreds of wires deep inside the brain without doing a lot of damage. So your question, what do you see? Well, I see an MRI on a screen, I can't see everything that, that DBS electrode is passing through on its way to that deep target.

5 (4h 25m 48s):
And so it's accepted with this approach that there's gonna be about one in a hundred patients who have a, a bleed somewhere in the brain as a result of passing that wire blindly into the, the deep part of the brain. That's not an acceptable safety profile for Neuralink. We start from the position that we want this to be dramatically maybe two or three orders of magnitude safer than that. Safe enough really that, you know, you or I, without a profound medical problem might on our lunch break someday say, yeah, sure, I'll get that.

5 (4h 26m 28s):
I I'd be meaning to upgrade to the latest version. And so the, the safety constraints given that are high. And so we haven't settled on a final solution for arbitrarily approaching deep targets in the brain.

0 (4h 26m 46s):
It's interesting 'cause like you have to avoid blood vessel somehow. You have to, maybe there's creative ways of doing the same thing, like mapping out high resolution geometry of blood vessels and then you can go in blind. But like how do you map out that in a way that's like super stable? It's, yeah, there's a lot of interesting challenges there, right? Yeah. But there's a lot to do on the surface, luckily.

5 (4h 27m 8s):
Exactly. So we've got vision on the surface. You know, we, we actually have made a huge amount of progress sewing electrodes into the spinal cord as a potential workaround for a spinal cord injury that would allow a brain mounted implant to translate motor intentions to a spine mounted implant that can affect muscle contractions in previously paralyzed arms and legs.

0 (4h 27m 35s):
That's mind blowing. That's just incredible. So like the effort there is to try to bridge the brain to the spinal cord, to the periphery peripheral in your nervous. So what, how hard is that to do?

5 (4h 27m 48s):
We have that working in, in very crude forms in animals.

0 (4h 27m 53s):
That's amazing. Yeah. We've done it So similar to like with Nolan, he's able to digitally move the cursor here you're doing the same kind of communication but with the actual factors that you have.

5 (4h 28m 6s):
Yeah.

0 (4h 28m 7s):
That's fascinating. Yeah.

5 (4h 28m 9s):
So we have anesthetized animals doing grasp and moving, moving their legs in a sort of walking pattern. Again, early days, but the future is bright for this kind of thing. And, and people with paralysis should look forward to that bright future. They're gonna have options.

0 (4h 28m 30s):
Yeah. And there's a, a lot of sort of intermediate or extra options where you take like an Optimus robot, like the, the arm and to be able to control the arm Yeah. The, the, the fingers and hands of the arm. Sure. As a prosthetic

5 (4h 28m 48s):
Skeleton skeletons are, are getting better too. So

0 (4h 28m 50s):
Skeletons. Yeah. So that, that goes hand in hand, although I didn't quite understand until thinking about it deeply and doing more research about Neuralink, how much you can do on the digital side. So this Digital telepathy. Yeah, I I didn't quite understand that. You can really map the intention as you described in the hand knob area, that you can map the intention. Just imagine it, think about it. That intention can be mapped to actual action in the digital world. Right. And now more and more, so much can be done in the, in the digital world that it, it, it can reconnect you to, to the outside world.

0 (4h 29m 32s):
It can allow you to have freedom, have independence if you're a quadriplegic. Yeah. That's really powerful. Like you can go really far with that.

5 (4h 29m 41s):
Yeah. Our first participant is, he's incredible. He's breaking world records left and right and he's

0 (4h 29m 47s):
Having fun with it. It's great. Just going back to the surgery, your whole journey, you mentioned to me offline, you have surgery on Monday, So, you are like, you're doing surgery all the time.

5 (4h 30m 1s):
Yeah.

0 (4h 30m 1s):
Maybe the ridiculous question, what Does it take to get good at surgery?

5 (4h 30m 5s):
Practice? Repetitions. You just, same with anything else. You know, there's a million ways of people saying the same thing and selling books, saying it But you call it 10,000 hours, you call it, you know, spend some chunk of your life, some percentage of your life focusing on this, obsessing about getting better at it. Repetitions, humility, recognizing that you, you aren't perfect at any stage along the way. Recognizing you've got improvements to make in your technique. Being open to feedback and coaching from people with a different perspective on how to do it. And then just the constant will to do better.

5 (4h 30m 51s):
That fortunately, you know, if you're not a sociopath, I think your patients bring that with them to the office visits every day. They, you know, force you to wanna do better all the time.

0 (4h 31m 2s):
Yeah. To step up. I mean, it's a real human being, a real human being that you can help. Yeah. So every surgery, even if it's the same exact surgery, is there a lot of variability between that surgery and a different person?

5 (4h 31m 15s):
Yeah, a fair bit. I mean, a good example for us is the, the angle of the skull relative to the normal plane o of the body, axis of the skull over hand knob is pretty wide variation. I mean, some people have really flat skulls and some people have really steeply angled skulls over that area, And that has, you know, consequences for how their head can be fixed in, in, in sort of the frame that we use and how the robot has to approach the skull. And yeah, people's, people's bodies are built as differently as, you know, the people you see walking down the street as as much variability in body shape and size as you see there.

5 (4h 32m 3s):
We see in brain anatomy and skull anatomy, there are some people who we've had to kind of exclude from our trial for having skulls that are too thick or too thin or scalp that's too thick or too thin. I think, you know, we have like the middle 97% or so of people, but you can't account for all human anatomy variability.

0 (4h 32m 30s):
How much like mus and messes there because I, you know, taking biology classes, the diagrams are always really clean and crisp. Neuroscience, the pictures of neurons are always really nice and very Yeah. But whenever I look at pictures of like real brains, they're all, i, I don't know what is going on. Yeah. So how much are biological systems in reality? Like how hard is it to figure out what's going on?

5 (4h 32m 59s):
Not too bad once you really get used to this, you know, that's where experience and and skill and education really come into play is if you stare at a thousand brains, it becomes easier to kind of mentally peel back the, say for instance, blood vessels that are obscuring the sci and gyre, you know, kind of the wrinkle pattern of the surface of the brain. Occasionally when you're, when you're first starting to do this and you open the skull, it doesn't match what you thought you were gonna see based on the MRI and with more experience, you, you learn to kind of peel back that layer of blood vessels and see the underlying pattern of wrinkles in the brain and use that as a landmark for where you are.

0 (4h 33m 52s):
The wrinkles are a landmark. So like, yeah,

5 (4h 33m 54s):
So I was describing hand knob earlier. That's a pattern of the wrinkles in the brain. It's sort of this sort of Greek letter, omega shaped area of the brain.

0 (4h 34m 4s):
So, you could recognize the hand knob area. Like if, if I show you a thousand brains and give you like one minute with each, you'd be like, yep, that's that. Sure. And so there is some uniqueness to that area of the brain, like in terms of the geometry, the topology of the thing. Yeah. Where is it about in the,

5 (4h 34m 24s):
It's So you have this strip of brain running down the top Yep. Called the primary motor area. And I'm sure you've seen this picture of the homunculus laid over the surface of the brain. The weird little guy with huge lips and giant hands. That guy sort of lays with his legs up at the top of the brain and, and face arm areas farther down and, and then some kind of mouth, lip tongue areas farther down. And so the hand is right in there. And then the areas that control speech, at least on the, on the left side of the brain in most people are, are just below that.

5 (4h 35m 5s):
And so any muscle that you voluntarily move in your body, the vast majority of that references that strip or those intentions come from that strip of brain. And the, the wrinkle for hand knob is right in the middle of that

0 (4h 35m 23s):
And vision is back here. Back. Yep. Also on close to the surface,

5 (4h 35m 28s):
Vision's a little deeper. And So, you know, this gets to your question about how deep can you get to do vision. We can't just do the surface of the brain. We have to be able to go in, not, not as deep as we have to go for DBS, but maybe a centimeter deeper than we're used to for hand insertions. And so that's, you know, work in progress. That's a new set of challenges to overcome.

0 (4h 35m 56s):
By the way, you mentioned the Utah, right? And I just saw a picture of that And, that thing looks terrifying. Yeah. Bad nails. It's, it's because it's rigid. And then if you look at the threads, they're flexible. What can you say that's interesting to you about the flexible, that kind of approach of the, the flexible threads to, to deliver the electrodes next to the neurons?

5 (4h 36m 18s):
Yeah, I mean the, the goal there comes from experience. I mean, we stand on the shoulders of people that made Utah rays and, and used Utah rays for decades before we ever even came along. Neuralink arose partly this approach to technology arose out of a need recognized after Utah rays would fail routinely because the rigid electrodes, those spikes that are literally hammered using an air hammer into the brain, those spikes generate a bad immune response that encapsulates the, the electrode spikes in scar tissue essentially.

5 (4h 37m 4s):
And so one of the projects that was being worked on in, in the Anderson lab at Caltech when I got there, was to see if you could use chemotherapy to prevent the formation of scar. It's like, you know, things are pretty bad when you're jamming a bed of nails into the brain and then treating that with chemotherapy to try to prevent scar tissue. It's like, you know, maybe we've gotten off track here, guys. Maybe there's a fundamental redesign necessary. And so neural lynxs approach of using highly flexible tiny electrodes avoids a lot of the bleeding, avoids a lot of the immune response that ends up happening when rigid electrodes are pounded into the brain.

5 (4h 37m 48s):
And so what we see is our electrode longevity and functionality and the, and the health of the brain tissue immediately surrounding the electrode is excellent. I mean, it goes on for, for years now in, in our animal models,

0 (4h 38m 3s):
What do most people not understand about the biology of the brain? We, we will mention the vasculature. That's really interesting.

5 (4h 38m 10s):
I think the most interesting maybe underappreciated fact is that it really does control almost everything. I mean, don don't know. For out of the blue example, imagine you, you want a lever on fertility, you wanna be able to turn fertility on and off. I mean it, there are legitimate targets in the brain itself to modulate fertility, say blood pressure. You wanna modulate blood pressure. There are legitimate targets in the brain for doing that. Things that aren't immediately obvious as brain problems are potentially solvable in the brain.

5 (4h 38m 54s):
And so I think it's an under-explored area for primary treatments of all, of all the things that bother people.

0 (4h 39m 5s):
That's a really fascinating way to look at it. Like there's a lot of conditions we might think have nothing to do with the brain, but they might just be symptoms of something that actually started in the brain. The actual source of the problem. The, the primary source is the, is something in the

5 (4h 39m 19s):
Brain. Yeah. Not, not always. I mean, you know, their kidney disease is real, but there are levers you can pull in the brain that affect all of the, all of these systems.

0 (4h 39m 29s):
There's knobs Yeah. On off switches and knobs in the brain. Yeah. From which this all or originates. Yeah. Would you have a Neuralink chip implanted in your brain?

5 (4h 39m 43s):
Yeah, I think use case right now is use a mouse. Right. I can already do that. And so there's no value proposition on safety grounds alone. Sure. I'll do it tomorrow.

0 (4h 39m 59s):
You know, you say the use case of the mouse because after like researching all this and part of it is just watching no and have so much fun if you can get that bits per second look really high with a mouse, like being able to interact. Because if, if you think about the, the way the on the smartphone, the way you swipe that was transformational. Yeah. How we interact with the thing. It's subtle. You don't realize it But you able to touch a phone and to scroll with your finger. That's like, that changed everything that people were Sure you need a keyboard to type And that there's a lot of HCI aspects to that that changed how we interact with computers.

0 (4h 40m 42s):
So there could be a certain rate of speed with the mouse that would change everything. Yeah. It's like you might be able to just click around a screen extremely fast And that if it, I, I can't see myself getting a Neuralink for much more rapid interaction with the digital devices.

5 (4h 41m 3s):
Yeah. I think recording speech intentions from the brain might, might change things as well. You know, the value proposition for the average person, a keyboard is a pretty clunky human interface requires a lot of training. It's, you know, highly variable in the maximum performance that the average person can, can achieve. I think taking that out of the equation and just having a natural, you know, word to computer interface might change things for a lot of people.

0 (4h 41m 40s):
It'd be hilarious if that is the reason people do it. Even if you have speech to text, that's extremely accurate. It currently isn't. Right. But, It say gotten super accurate. It'd be hilarious if people went for Neuralink. Just So you avoid the embarrassing aspect of speaking, like looking like a douche bag speaking to your phone in public, which is a real, like that's a real constraint. Yeah.

5 (4h 42m 3s):
I mean with a bone conducting case that can be a a, an invisible headphone say and the ability to think words into software and have it respond to you, you know, that starts to sound sort of like embedded super intelligence. You know, if you can silently ask for the Wikipedia article on any subject and have it read to you without any observable change happening in the outside world, you know, for one thing, standardized testing is obsolete.

0 (4h 42m 43s):
Yeah. If it's done well in the UX side, it could change. I don't know if it transforms society. But It really can create a kind of shift in the way we interact with di digital devices in the way that a smartphone did. Now I would just having to look into the safety of everything involved. I would, I would totally try it so it doesn't have to go to some like incredible thing where you have, it connects your vision or to some oth like it connects all over your brain. That could be like just connecting to the hand knob. You might have a lot of interesting interaction. Human computer interaction possibilities. Yeah. That's really interesting. Yeah.

5 (4h 43m 22s):
And the technology on the academic side is progressing at light speed here. I think there was a really amazing paper out of uc, Davis Sergey ST's lab that basically made a initial solve of speech decode. It was something like 125,000 words that they were getting with, you know, very high accuracy, which is

0 (4h 43m 47s):
So you are just thinking the word. Yeah. Thinking the word and you're able to get it. Yeah. Oh boy. Like you have to have the intention of speaking it. Right. So like, do that inner voice, man. I was, it's so amazing to me that you can do the intention, the signal mapping. All you have to do is just imagine yourself doing it and if, if you get the feedback that it actually worked, you can get really good at that. Like your brain will first of all adjust and you develop it like any other skill. Yeah. Like touch typing, you develop in that same kind of way. That is, that is really, to me, it's just really fascinating.

0 (4h 44m 27s):
Yeah. To be able to even, to play with that honestly. Like I would get a neur link just to be able to play with that. Just to play with the capacity, the capability of my mind to learn this skill. It's like learning the skill of typing and learning the skill of moving a mouse. It's another skill of moving the mouse. Not with my physical body, but with my mind.

5 (4h 44m 48s):
I can't wait to see what people do with it. I feel like we're right, we're cavemen right now. We're, we're like banging rocks with a stick and thinking that we're making music. At some point when these are more widespread, there's gonna be the equivalent of a, of a piano that, you know, someone, someone can make art with their brain in a way that we didn't even anticipate. I'm looking forward to it.

0 (4h 45m 12s):
Give it to like a teenager. Like anytime I think I'm good at something, I'll always go to like don don't know. Even even even with the, the, the bits per second of playing a video game, you realize you give it to a teenager, you given your link to a teenager, just the large number of them, the kind of stuff they get good at stuff, they're gonna get like hundreds of BS per second. Yeah. Even just with the current technology,

5 (4h 45m 38s):
Probably, probably

0 (4h 45m 40s):
Just 'cause it's also addicting how like the, the the number go up aspect of it of like improving and training. 'cause it is, it is almost like a skill and plus there's the software on the other end that adapts to you. And especially if the adapting procedure algorithm becomes better and better and better. You like learning together. Yeah.

5 (4h 45m 59s):
We're scratching the surface on that right now. There's so much more to do.

0 (4h 46m 3s):
So on the complete other side of it, you have an RFID chip. Yeah. Implanted in you. Yeah. So I hear Nice. So this is

5 (4h 46m 13s):
Little subtle thing.

0 (4h 46m 14s):
It's a passive device that you use for unlocking like a safe with top secrets. So what, what is, what do you use it for? What's the story behind it?

5 (4h 46m 24s):
I'm not the first one. There's, there's this whole community of weirdo biohackers that have done this stuff and I think one of the early use cases was storing, you know, private crypto wallet keys and, and whatever. I dabbled in that a bit and, and had some fun with it. But

0 (4h 46m 44s):
You have some Bitcoin implanted in your body somewhere. You can't tell where Yeah, yeah.

5 (4h 46m 48s):
Actually, yeah. It was, you know, the modern day equivalent of finding change in the sofa cushions after i, I put some orphan crypto on there that I thought was worthless and forgot about it for a few years. Went back and found that some community of people loved it and had propped up the value of it. And so it had gone up 50 fold. Wow. So there was a lot of change in those cushions.

0 (4h 47m 13s):
That's hilarious.

5 (4h 47m 14s):
But the, the primary use case was mostly as a, as a tech demonstrator, you know, it, it has my business card on it. You can scan that in by touching it to your phone. It opens the front door to my house, you know, whatever simple stuff.

0 (4h 47m 30s):
It's a cool step. It's a cool leap to implant something in your body. I mean, it has, perhaps that's, it's a similar leap to Neurolink because for a lot of people, that kind of notion of putting something inside your body, something electronic inside a biological system is a big leap.

5 (4h 47m 45s):
Yeah. We have a kind of a mysticism around the barrier of our skin. We're completely fine with knee replacements, hip replacements, you know, dental implants. But you know, there's a mysticism still around the inviable barrier that the skull represents. And I think that needs to be treated like any other pragmatic barrier. You know, it's, the question isn't how, how incredible is it to open the skull? The question is, you know, what benefit can we provide? So

0 (4h 48m 22s):
From all the surgeries you've done, from everything you understand the brain, how much does neuroplasticity come into play? How adaptable is the brain? For example, just even in the case of healing from surgery or adapting to the post-surgery situation?

5 (4h 48m 37s):
The answer that is sad for me and other people of my demographic is that, you know, plasticity decreases with age healing, decreases with age. Yeah. I have too much gray hair to, to be optimistic about that there are theoretical ways to increase plasticity using electrical stimulation. Nothing that is, you know, totally proven out as a robust enough mechanism to offer widely to people. But yeah, I think, I think there's cause for optimism that we might find something useful in terms of say, an implanted electrode that improves learning.

5 (4h 49m 18s):
Certainly there's been some really amazing work recently from Nicholas Schiff, Jonathan Baker, you know, and others who have a, a cohort of patients with moderate traumatic brain injury who have had electrodes placed in the deep nucleus in the brain called the central media nucleus or just near central media nucleus. And when they apply small amounts of electricity to that part of the brain, it's almost like electronic caffeine. They're able to improve people's attention and focus. They're able to improve how well people can perform a task. I think in one case, someone who was unable to work after the device was turned on, they were able to get a job.

5 (4h 50m 2s):
And that's sort of, you know, one of the holy grails for me with Neuralink and other technologies like this is from a purely utilitarian standpoint, can we, can we make people able to take care of themselves and their families economically? Again, can we make it so someone who's fully dependent and even maybe requires a lot of caregiver resources, can we put them in a position to be fully independent, taking care of themselves, giving back to their communities? I think I think that's a very compelling proposition and what motivates a lot of what I do and what a lot of the people at Neuralink are working for.

0 (4h 50m 45s):
It's just a cool possibility that if you put a neurolink in there, that the brain adapts like the, the other part of the brain adapts too. Yeah. And integrates it. The, the, the capacity of the brain to do that is really interesting. Probably unknown to do the, the degree to which you can do that But, you're now connecting an external thing to it. Especially once it's doing stimulation like the, the biological brain and the, the electronic brain outside of it working together. Like the possibilities there are really interesting. Yeah. It's still unknown but interesting. It feels like the brain is really good at adapting to whatever.

0 (4h 51m 28s):
Yeah. But of course it is a system that by itself is already like everything serves a purpose and So you don't wanna mess with it too much. Yeah.

5 (4h 51m 40s):
It's like, you know, eliminating a species from a, from an ecology, you know, you don't know what the delicate interconnections and dependencies are. The brain is certainly a, a, a delicate, complex beast. And we don't know, you know, every potential downstream consequence of, of a single change that we make.

0 (4h 52m 4s):
Do you see yourself doing So? you mentioned P one surgeries of P two, P three, P four, P five, just, well, more and more and more humans. I

5 (4h 52m 14s):
Think, you know, it's a certain kind of brittleness or, or, you know, a failure on the company's side. If we need me to do all the surgeries. I think something that I would very much like to work towards is a process that is so simple and so robust on the surgery side that literally anyone could do it. We, we want to get away from a requiring intense expertise or intense experience to, to have this successfully done and make it as, as simple and translatable as possible. I mean, I would love it if every neurosurgeon on the planet had no problem doing this.

5 (4h 52m 58s):
I think we're probably far from a regulatory environment that would allow people that aren't neurosurgeons to do this, but not impossible.

0 (4h 53m 8s):
All right, I'll sign up for that. Did you ever anthropomorphize the, the robot R one? Like do you, do you give it a name? Do you see it as like a friend as like working together with you?

5 (4h 53m 20s):
I mean, to a certain degree it's,

0 (4h 53m 22s):
Or anatomy who's gonna work the job

5 (4h 53m 26s):
To a certain degree. It's, it's, yeah, it's complex relationship.

0 (4h 53m 31s):
All the good relationships are,

5 (4h 53m 33s):
It's funny when in the middle of the surgery, there's a part of it where I stand sho basically shoulder to shoulder with the robot and So, you know, if you're in the room reading the body language, you know, that's, it's my brother in arms there we're, we're working together on the same problem. Yeah. I'm not threatened by it.

0 (4h 53m 55s):
Keep telling yourself that. Yeah. That's how have all the surgeries that you've done over the years, the people you've helped and the, the stakes, the high stakes that you've mentioned, how, how has that changed your understanding of Life and death?

5 (4h 54m 14s):
Yeah, you know, it, it gives you a very visceral sense, and this makes sound trite. But It gives you a very visceral sense that death is inevitable. You know, on one hand, you know, you, you are, as a neurosurgeon, you're deeply involved in these like just hard to fathom tragedies, you know, young parents dying, leaving, you know, a 4-year-old behind say. And, and on the other hand, you know, it takes the sting out of it a bit because you see how just mind numbingly universal death is, there's zero chance that I'm going to avoid it.

5 (4h 55m 6s):
I know, you know, techno optimists right now and longevity buffs right now would disagree on that 0.0% estimate. But don don't see any chance that our generation is going to avoid it. Entropy is a powerful force and we are very ornate, delicate, brittle DNA machines that aren't up to the cosmic ra bombardment that we're subjected to. So on the one hand, every human that has ever lived died or will die. On the other hand, it's just one of the hardest things to imagine inflicting on anyone that you love is, is having them gone.

5 (4h 55m 56s):
I mean, I'm sure you've had friends that aren't living anymore and it's, it's hard to even think about them. And so I wish I had, you know, arrived at the point of nirvana where I, you know, death doesn't have a sting. I'm not worried about it, but I can at least say that I'm comfortable with the certainty of it. If, if not having found out how to take the, the tragedy out of it. When I think about, you know, my kids either not having me or, or me not having them or my wife,

0 (4h 56m 35s):
Maybe I have come to accepting intellectual certainty of it, but it may be the pain that comes with losing the people you love. don don't think I've come to understand the existential aspect of it. Like that this is gonna end. And I don't mean like in some trite way. I mean like, it certainly feels like it's not going to end like you live life. Like it's not going to end. Right. And the fact that this light that's shining this Consciousness is, is is going to no longer be in one moment, maybe today.

0 (4h 57m 19s):
It's like a, it, it fills me when I really am able to load all that in with Ernest Becker's terror. Like it's a real fear. I think people aren't always honest with how terrifying it is.

5 (4h 57m 33s):
Yeah.

0 (4h 57m 34s):
I think the more you are able to really think through it, the more terrifying it is. It's, it's not such a simple thing. Oh well, it's the way life is and it's, if you really can load that in, it's hard. But I think that's why the stoics did it, because it like helps you get your shit together and be like this. Well, the like, the moment, every single moment you're alive is just beautiful. Yeah. And it's terrifying that it's gonna end and it's, and it's like, like almost like you are shivering in the cold, a child helpless this kind of feeling. Yeah. And then it makes you, when you have warmth, when you have the safety, when you have the love to really appreciate it.

0 (4h 58m 19s):
I feel like sometimes in your position when you mentioned armor, just to see death, it might make you not be able to see that the, the finiteness of life because if you kept looking at that, it might break you. So it, it's good to know that you're kind of still struggling with that, that there's the, the neurosurgeon and then there's a human Yeah. And the human is still able to struggle with that and feel the, the fear of that and the pain of that. Yeah.

5 (4h 58m 52s):
You know, it definitely makes you ask the question of how long, how many times, how many of these can you see? And, and not say I can't do this anymore. But I mean, you said it well, I think it gives you an opportunity to just appreciate that you're alive today and you know, I've got, I've got three kids and an amazing wife and I'm really happy. Things are good. I get to help on a project that I think matters. I think it moves us forward. I'm a very lucky person.

0 (4h 59m 31s):
It's the early steps of a potentially gigantic leap for humanity. It's a really interesting one. And it's cool 'cause like you, you read about all this stuff in history where it's like the early days I've been reading before going to the Amazon, I would read about explorers that would go and explore even the Amazon jungle for the first time. It's just those are the early steps. Yeah. Or early steps into space. Early, early steps in any discipline in, in physical.